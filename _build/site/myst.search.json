{"version":"1","records":[{"hierarchy":{"lvl1":"Chapter 1: Introduction"},"type":"lvl1","url":"/chapter-1-intro","position":0},{"hierarchy":{"lvl1":"Chapter 1: Introduction"},"content":"Objectives of this chapter\n\nThink Spatially---the key to geospatial data visualization.\n\nThink Statistically---why this is important in doing geospatial visualization?\n\nGet to know what the components of Cartography: scales, coordinate system, typography, colors, etc.\n\nHow do we define ‘Space’ or ‘GeoSpatial’?\n\nIdentify ways of thinking and describng geospatial","type":"content","url":"/chapter-1-intro","position":1},{"hierarchy":{"lvl1":"Geovisualisation"},"type":"lvl1","url":"/sec-01-01-geovisualisation","position":0},{"hierarchy":{"lvl1":"Geovisualisation"},"content":"The comic \n\nFigure 1 is a visualization of the relationship between human proximity to cat and the intelligence of the person.\n\nVisualization is .mark[the process of representing data or information] in a graphical or pictorial form to communicate an idea, concept, or pattern more effectively.\n\n\n\nFigure 1:\n\nCat Proximity (xkcd.com/231).","type":"content","url":"/sec-01-01-geovisualisation","position":1},{"hierarchy":{"lvl1":"Geovisualisation","lvl2":"General purpose map"},"type":"lvl2","url":"/sec-01-01-geovisualisation#general-purpose-map","position":2},{"hierarchy":{"lvl1":"Geovisualisation","lvl2":"General purpose map"},"content":"General purpose map (e.g., \n\nFigure 2) is mainly for wayfinding and navigation, as it displays a wide range of geographical features such as roads, cities, rivers, and political boundaries.\n\nThis type of map aims to provide a comprehensive representation of an area, allowing users to orient themselves and plan routes efficiently (e.g., \n\nFigure 3).\n\n\n\nFigure 2:A topographic map showing the land, street networks, and boundary between Singapore and Malaysia (Johor).\n\n\n\nFigure 3:SMRT Locality map Chinese Garden Exit C, by \n\nSMRT","type":"content","url":"/sec-01-01-geovisualisation#general-purpose-map","position":3},{"hierarchy":{"lvl1":"Geovisualisation","lvl2":"Thematic map"},"type":"lvl2","url":"/sec-01-01-geovisualisation#thematic-map","position":4},{"hierarchy":{"lvl1":"Geovisualisation","lvl2":"Thematic map"},"content":"A thematic map (e.g., John Snow’s map at \n\nFigure 4 and urban movement map at \n\nFigure 5) is a visual representation of a specific theme, subject, or data attribute that emphasizes .red.bold[spatial patterns], relationships, or trends within a geographical area.\n\nThrough the use of various .red[symbols, colors, or shading], thematic maps visually illustrate the spatial arrangement and distribution of features, revealing the relationships, trends, or correlations that constitute spatial patterns.\n\nSpatial pattern encompasses the way elements are organized, positioned, or clustered in a particular space. By analyzing spatial patterns, researchers can gain valuable insights into underlying processes, trends, or correlations in diverse fields, including geography, ecology, urban planning, and epidemiology.\n\nA map is a tool for storytelling and a medium for communication.\nSpatial patterns are the information and insight we can observe from a (thematic) map.\n\n\n\nFigure 4:John Snow’s 1854 Cholera Map: the distribution of cases and water pumps. See: \n\nWikipedia for description.\n\n\n\nFigure 5:A flow map of estimated urban movement for accessing clinics. See \n\nInteractive map on FlowMap.gl","type":"content","url":"/sec-01-01-geovisualisation#thematic-map","position":5},{"hierarchy":{"lvl1":"Geovisualisation","lvl2":"Geospatial Visualization Patterns"},"type":"lvl2","url":"/sec-01-01-geovisualisation#geospatial-visualization-patterns","position":6},{"hierarchy":{"lvl1":"Geovisualisation","lvl2":"Geospatial Visualization Patterns"},"content":"","type":"content","url":"/sec-01-01-geovisualisation#geospatial-visualization-patterns","position":7},{"hierarchy":{"lvl1":"Geovisualisation","lvl3":"Point pattern","lvl2":"Geospatial Visualization Patterns"},"type":"lvl3","url":"/sec-01-01-geovisualisation#point-pattern","position":8},{"hierarchy":{"lvl1":"Geovisualisation","lvl3":"Point pattern","lvl2":"Geospatial Visualization Patterns"},"content":"\n\nFigure 6:The highest and lowest price of 10 yo, 4-room HDB flat in 2023.","type":"content","url":"/sec-01-01-geovisualisation#point-pattern","position":9},{"hierarchy":{"lvl1":"Geovisualisation","lvl3":"Areal pattern","lvl2":"Geospatial Visualization Patterns"},"type":"lvl3","url":"/sec-01-01-geovisualisation#areal-pattern","position":10},{"hierarchy":{"lvl1":"Geovisualisation","lvl3":"Areal pattern","lvl2":"Geospatial Visualization Patterns"},"content":"\n\nFigure 7:Education level by Planning Area.","type":"content","url":"/sec-01-01-geovisualisation#areal-pattern","position":11},{"hierarchy":{"lvl1":"Geovisualisation","lvl3":"Statistical pattern","lvl2":"Geospatial Visualization Patterns"},"type":"lvl3","url":"/sec-01-01-geovisualisation#statistical-pattern","position":12},{"hierarchy":{"lvl1":"Geovisualisation","lvl3":"Statistical pattern","lvl2":"Geospatial Visualization Patterns"},"content":"\n\nFigure 8:Subzone-to-subzone daily flow ridership.","type":"content","url":"/sec-01-01-geovisualisation#statistical-pattern","position":13},{"hierarchy":{"lvl1":"Why visualization?"},"type":"lvl1","url":"/sec-01-02-visualization","position":0},{"hierarchy":{"lvl1":"Why visualization?"},"content":"In \n\nFigure 1, on the left is the mapped flow of people between towns in Singapore, while the right shows the key flow structure---the information---that was analyzed from the data in the left.\n\n\n\nFigure 1:Data vs. Information","type":"content","url":"/sec-01-02-visualization","position":1},{"hierarchy":{"lvl1":"Why visualization?","lvl2":"From Data to Information, then Insights"},"type":"lvl2","url":"/sec-01-02-visualization#from-data-to-information-then-insights","position":2},{"hierarchy":{"lvl1":"Why visualization?","lvl2":"From Data to Information, then Insights"},"content":"Data: Raw facts, figures, or observations collected and recorded] in various forms, such as text, numbers, or images. Data is the basic building block for understanding and analyzing phenomena or trends.\n\nInformation: Organized, structured, and processed data that provides context and meaning, making it useful and relevant to specific users or situations. Information helps answer questions and guide decision-making.\n\nInsights: Deep, meaningful conclusions and understanding derived from analyzing and interpreting information. Insights uncover patterns, trends, or cause-and-effect relationships, enabling informed decisions and new perspectives.\n\n\n\nFigure 2:Data, Information, Insights.\n\nGeovisualisation is a series of explorations and analyses, that includes using various techniques and methods, e.g., thematic mapping, exploratory spatial data analysis, to uncover the underlying patterns, to get better understanding of geographical phenomena.\n\n\n\nFigure 3:MacEachren’s cartographic cube.","type":"content","url":"/sec-01-02-visualization#from-data-to-information-then-insights","position":3},{"hierarchy":{"lvl1":"Why visualization?","lvl2":"The Key Steps of Data Visualisation: OTAS"},"type":"lvl2","url":"/sec-01-02-visualization#the-key-steps-of-data-visualisation-otas","position":4},{"hierarchy":{"lvl1":"Why visualization?","lvl2":"The Key Steps of Data Visualisation: OTAS"},"content":"Observe\n\nThink\n\nAssess\n\nShow\n\n\n\nFigure 4:OTAS.","type":"content","url":"/sec-01-02-visualization#the-key-steps-of-data-visualisation-otas","position":5},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Observe","lvl2":"The Key Steps of Data Visualisation: OTAS"},"type":"lvl3","url":"/sec-01-02-visualization#observe","position":6},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Observe","lvl2":"The Key Steps of Data Visualisation: OTAS"},"content":"What can be SEEN?\n\nEnsure you understand the metadata.\n\nLook into the data.\n\nGet your hand dirty: Create relevant plots or maps using the data.\n\nwhatever plots/maps that you can think of, sky is the limit\n\nLook at those plots and maps...\n\nDivergent thinking, brainstorming","type":"content","url":"/sec-01-02-visualization#observe","position":7},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Think","lvl2":"The Key Steps of Data Visualisation: OTAS"},"type":"lvl3","url":"/sec-01-02-visualization#think","position":8},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Think","lvl2":"The Key Steps of Data Visualisation: OTAS"},"content":"What are the CAUSES?\n\nHow does it look?\n\nAre there any familiar or expected patterns? (that you may have seen somewhere before)\n\nIs there anything looks unusual and strange? (something that really stands out)\n\nIs there anything wrong?\n\nAre there any unexpected patterns? (something beyond your expectation)\n\nunexpected patterns are usually the interesting one, if they are real\n\ncounter-intuitive\n\nWhat could be the possible reasons behind these patterns?\n\nExpanding and synthesizing from the brainstorming step","type":"content","url":"/sec-01-02-visualization#think","position":9},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Assess","lvl2":"The Key Steps of Data Visualisation: OTAS"},"type":"lvl3","url":"/sec-01-02-visualization#assess","position":10},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Assess","lvl2":"The Key Steps of Data Visualisation: OTAS"},"content":"How to VERIFY them?\n\nReview and (re)evaluate your initial ideas or thoughts, even if they seem immature, unconventional, or funny.\n\nTest your hypotheses or thoughts to ensure their validity.\n\nDouble-check for any possible (stupid) mistakes made during\n\ndata processing,\n\ncalculation,\n\nunit transformation,\n\nmap projection, or\n\nvisualization.\n\nLiterature review for confirmation/contrasting the findings.\n\nConvergent thinking, rigourously evaluating every idea","type":"content","url":"/sec-01-02-visualization#assess","position":11},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Show","lvl2":"The Key Steps of Data Visualisation: OTAS"},"type":"lvl3","url":"/sec-01-02-visualization#show","position":12},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Show","lvl2":"The Key Steps of Data Visualisation: OTAS"},"content":"How to VISUALISE them?\n\n(Re)Drawing the plots & maps\n\nThink about the layouts\n\npotrait, landscape\n\ncombining multiple subplots\n\nsequences\n\ncolours\n\ntext font family, size, and positions\n\nShow it to people\n\nCommunicate based on it\n\nGetting feedbacks","type":"content","url":"/sec-01-02-visualization#show","position":13},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"OTAS Flow","lvl2":"The Key Steps of Data Visualisation: OTAS"},"type":"lvl3","url":"/sec-01-02-visualization#otas-flow","position":14},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"OTAS Flow","lvl2":"The Key Steps of Data Visualisation: OTAS"},"content":"\n\nFigure 5:OTAS workflow.","type":"content","url":"/sec-01-02-visualization#otas-flow","position":15},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Summary","lvl2":"The Key Steps of Data Visualisation: OTAS"},"type":"lvl3","url":"/sec-01-02-visualization#summary","position":16},{"hierarchy":{"lvl1":"Why visualization?","lvl3":"Summary","lvl2":"The Key Steps of Data Visualisation: OTAS"},"content":"There is no strict rules for doing data visualisation\n\nThe four OTAS steps are just a quick guideline for the “visual thinking process”\n\nObserve: divergent thinking & brainstorming\n\nThink: extending & synthesing\n\nAssess: convergent thinking & double checking\n\nShow: presentation\n\nSome people skip the Think and Assess steps and jump from drawing initial plots/maps step to the last showing/communicating step.\n\nTheir results could be bias, not comprehensively capture the thoughts","type":"content","url":"/sec-01-02-visualization#summary","position":17},{"hierarchy":{"lvl1":"Statistical Thinking"},"type":"lvl1","url":"/sec-01-03-statistical-thinking","position":0},{"hierarchy":{"lvl1":"Statistical Thinking"},"content":"","type":"content","url":"/sec-01-03-statistical-thinking","position":1},{"hierarchy":{"lvl1":"Statistical Thinking","lvl2":"What is statistics?"},"type":"lvl2","url":"/sec-01-03-statistical-thinking#what-is-statistics","position":2},{"hierarchy":{"lvl1":"Statistical Thinking","lvl2":"What is statistics?"},"content":"From data to information.\n\nThe two main types of statistics:\n\nDescriptive Statistics is about how we describe data. This branch focuses on summarizing and describing the main features of data, such as mean, median, standard deviation, and correlation. Descriptive statistics helps visualize and interpret data through graphical methods like histograms, scatter plots, box plots, and maps.\n\nInferential Statistics is about what we can learn from the data. This branch involves drawing conclusions about a population based on a sample by using probability theory. Inferential statistics allows us to make predictions, test hypotheses, and evaluate the reliability of conclusions. Some common methods in inferential statistics include regression analysis, hypothesis testing, and confidence intervals.","type":"content","url":"/sec-01-03-statistical-thinking#what-is-statistics","position":3},{"hierarchy":{"lvl1":"Statistical Thinking","lvl2":"Descriptive Statistics"},"type":"lvl2","url":"/sec-01-03-statistical-thinking#descriptive-statistics","position":4},{"hierarchy":{"lvl1":"Statistical Thinking","lvl2":"Descriptive Statistics"},"content":"The three types of measures in descriptive statistics\n\nMeasures of Central Tendency: These measures provide an indication of the “center” or “middle” of a dataset. They include: mean, median, mode.\n\nMeasures of Spread (Variability): These measures describe how spread out or dispersed the data is. They include: range, variance, standard deviation.\n\nMeasures of Shape: These measures help characterize the shape or distribution of the data, including: skewness, kurtosis.","type":"content","url":"/sec-01-03-statistical-thinking#descriptive-statistics","position":5},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Measures of Central Tendency","lvl2":"Descriptive Statistics"},"type":"lvl3","url":"/sec-01-03-statistical-thinking#measures-of-central-tendency","position":6},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Measures of Central Tendency","lvl2":"Descriptive Statistics"},"content":"help us understand the central or ‘average’ values in a dataset.\n\n\n\nFigure 1:The means of the three IRIS species.","type":"content","url":"/sec-01-03-statistical-thinking#measures-of-central-tendency","position":7},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Measures of Spread","lvl2":"Descriptive Statistics"},"type":"lvl3","url":"/sec-01-03-statistical-thinking#measures-of-spread","position":8},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Measures of Spread","lvl2":"Descriptive Statistics"},"content":"(variability) describe how the data is spread or dispersed around the central values.\n\n\n\nFigure 2:The spread of the three IRIS species.","type":"content","url":"/sec-01-03-statistical-thinking#measures-of-spread","position":9},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Measures of Shape","lvl2":"Descriptive Statistics"},"type":"lvl3","url":"/sec-01-03-statistical-thinking#measures-of-shape","position":10},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Measures of Shape","lvl2":"Descriptive Statistics"},"content":"describe the shape of the distribution, which could be steep/flat, skewed, or non-normal.\n\n\n\nFigure 3:The skewness and kurtosis of the three IRIS species.","type":"content","url":"/sec-01-03-statistical-thinking#measures-of-shape","position":11},{"hierarchy":{"lvl1":"Statistical Thinking","lvl2":"Inferential Statistics"},"type":"lvl2","url":"/sec-01-03-statistical-thinking#inferential-statistics","position":12},{"hierarchy":{"lvl1":"Statistical Thinking","lvl2":"Inferential Statistics"},"content":"Analysis of Relationship:\nHow one variable is related to another? How a series of independent variables could be related to one of the dependent variables?\n\nAnalysis of Differences:\nAre them significantly different?\n\nAnalysis of Confidence:\nHow confident are we about the sampling result?","type":"content","url":"/sec-01-03-statistical-thinking#inferential-statistics","position":13},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Analysis of Relationship","lvl2":"Inferential Statistics"},"type":"lvl3","url":"/sec-01-03-statistical-thinking#analysis-of-relationship","position":14},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Analysis of Relationship","lvl2":"Inferential Statistics"},"content":"Assessing the strength and direction of associations between variables. Examples include correlation (Pearson’s r for parametric data and Spearman’s rho for non-parametric data), and regression analysis (linear, multiple, and logistic regression). These output could further be used for further analysis and predictions.\n\n\n\nFigure 4:The relationships between petal length and petal weight for the three IRIS species.","type":"content","url":"/sec-01-03-statistical-thinking#analysis-of-relationship","position":15},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Analysis of Differences","lvl2":"Inferential Statistics"},"type":"lvl3","url":"/sec-01-03-statistical-thinking#analysis-of-differences","position":16},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Analysis of Differences","lvl2":"Inferential Statistics"},"content":"Evaluating whether observed differences between groups or conditions are statistically significant. Hypothesis testing forms the foundation for these measures. Parametric tests, such as t-tests and ANOVA, are used when data meets certain assumptions (e.g., normality). Non-parametric tests, such as Mann-Whitney U test, Wilcoxon signed-rank test, and Kruskal-Wallis test, are used when assumptions are violated or with non-normal data.\n\n\n\nFigure 5:The differences in petal length between the three species.","type":"content","url":"/sec-01-03-statistical-thinking#analysis-of-differences","position":17},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Analysis of Confidence","lvl2":"Inferential Statistics"},"type":"lvl3","url":"/sec-01-03-statistical-thinking#analysis-of-confidence","position":18},{"hierarchy":{"lvl1":"Statistical Thinking","lvl3":"Analysis of Confidence","lvl2":"Inferential Statistics"},"content":"Provide insights into the reliability and generalizability of statistical findings. Estimation involves calculating point estimates and confidence intervals to infer .red[population] parameters. Sampling distributions and standard errors help quantify the variability of sample statistics. Statistical power and effect size measures ensure that studies have adequate sample sizes and detect meaningful effects.\n\n\n\nFigure 6:The confidence interval (CI) of the actual population mean could fall within the 95% CI.","type":"content","url":"/sec-01-03-statistical-thinking#analysis-of-confidence","position":19},{"hierarchy":{"lvl1":"Statistical Thinking","lvl2":"Summary"},"type":"lvl2","url":"/sec-01-03-statistical-thinking#summary","position":20},{"hierarchy":{"lvl1":"Statistical Thinking","lvl2":"Summary"},"content":"Thinking Statistically while doing Geospatial Visualization\n\nMeasures of Central Tendency & Spreads: Spatial Aggregation---\nWhat is the median resale price of HDB flats in each district?\n\nMeasures of Shape: Data Categorization---\nWhich data breaking scheme is more appropriate for mapping the variable?\nIs data transformation needed?\n\nAnalysis of Relationship: Spatial Interaction---\nIs mental wellness related to the distribution of greenery?\nCan Socio-Economic Status be explained or predicted by the distribution of various types of POIs and property prices?\n\nAnalysis of Differences: Spatial Patterns---\nAre there significant clusters of crime cases in the study area?\nAre the spatial patterns of university-level and secondary-school-level residences different from each other?\n\nAnalysis of Confidence: Samples vs. Population---\nIs the sample data representative of the population?\n\nThese are some of the key concerns when we are reading/mapping a spatial pattern.","type":"content","url":"/sec-01-03-statistical-thinking#summary","position":21},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography"},"type":"lvl1","url":"/sec-01-04-geospatial-thinking","position":0},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography"},"content":"","type":"content","url":"/sec-01-04-geospatial-thinking","position":1},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl2":"How People See ‘Space’ and ‘Spatial’"},"type":"lvl2","url":"/sec-01-04-geospatial-thinking#how-people-see-space-and-spatial","position":2},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl2":"How People See ‘Space’ and ‘Spatial’"},"content":"From Oxford Learners Dictionaries: about \n\n‘Space’\n\nSpace noun\n\nuncountable - the area outside the earth’s atmosphere where all the other planets and stars are\n\ncountable - an area or a place that is empty\n\nuncountable - an amount of an area or of a place that is empty or that is available for use\n\ncountable, uncountable - a place, especially a room or a building, that can be used for a particular purpose\n\nFrom Oxford Learners Dictionaries: about \n\n‘Spatial’ and \n\n‘Geospatial’\n\nSpatial adjective\nrelating to space and the position, size, shape, etc. of things in it\n\nGeospatial adjective, only before noun\nrelating to information that is associated with a particular location","type":"content","url":"/sec-01-04-geospatial-thinking#how-people-see-space-and-spatial","position":3},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl2":"How AI See ‘Space’ and ‘Spatial’"},"type":"lvl2","url":"/sec-01-04-geospatial-thinking#how-ai-see-space-and-spatial","position":4},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl2":"How AI See ‘Space’ and ‘Spatial’"},"content":"generated and modified based on \n\nPi.ai’s response\n\nSpatial refers to anything related to space, including the location, size, shape, and orientation of objects or elements within a given area or environment. It’s a broad term that’s used in many different fields and contexts, such as geography, architecture, interior design, and psychology.\n\nSome examples of spatial concepts include:\n\nSpatial awareness/perception: This refers to an individual’s ability to understand and navigate their surroundings, including the ability to perceive and judge distances, directions, and relationships between objects.\n\nSpatial reasoning: This involves understanding and reasoning about spatial relationships between objects, such as their relative positions, distances, and orientations.\n\nSpatial planning: This involves the organization and layout of physical spaces, such as the design of buildings, cities, or public spaces, to maximize functionality, efficiency, and aesthetics.\n\nSpatial data: This includes any information or datasets that relate to the location, shape, or other spatial characteristics of objects or features, such as maps, satellite images, or GPS coordinates.\n\nIn general, .redspatial refers to anything that involves the arrangement or characteristics of objects or elements within a physical space.\n\nSo, what is Space, Spatial, and Geospatial?\n\nSpace is a two- or three-dimensional physical realm that encompasses and contextualizes the location of objects and beings within it.\n\nSpatial-[some object] is the information related to the positional or geographical aspects and relationships of a specific object.\n\nGeospatial: space and spatial can refer to any ‘space’ and ‘spatial’; to differentiate and specifying geographical space, we use the term geospatial.\n\nHere, the two terms spatial and geospatial can be used interchangeably, both refer to the space in geographical context.","type":"content","url":"/sec-01-04-geospatial-thinking#how-ai-see-space-and-spatial","position":5},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"type":"lvl2","url":"/sec-01-04-geospatial-thinking#how-geographers-see-space-and-spatial","position":6},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"content":"","type":"content","url":"/sec-01-04-geospatial-thinking#how-geographers-see-space-and-spatial","position":7},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"The space–place (‘splatial’) Framework","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"type":"lvl3","url":"/sec-01-04-geospatial-thinking#the-space-place-splatial-framework","position":8},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"The space–place (‘splatial’) Framework","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"content":"Adapted from \n\nUnderstanding the New Human Dynamics in Smart Spaces and Places: Toward a Splatial Framework\n\n\n\nThe splatial framework.","type":"content","url":"/sec-01-04-geospatial-thinking#the-space-place-splatial-framework","position":9},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"Absolute Space","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"type":"lvl3","url":"/sec-01-04-geospatial-thinking#absolute-space","position":10},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"Absolute Space","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"content":"Absolute space is about the location itself---where are the studying object?\n\n\n\nAbsolute Space. The red-X marker shows where the current location is.","type":"content","url":"/sec-01-04-geospatial-thinking#absolute-space","position":11},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"Relative Space","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"type":"lvl3","url":"/sec-01-04-geospatial-thinking#relative-space","position":12},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"Relative Space","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"content":"Relative space is about the nearby area---relative to the current target/space.\n\n\n\nRelative Space. The buffer zone shows the neighborhood of current location.","type":"content","url":"/sec-01-04-geospatial-thinking#relative-space","position":13},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"Relational Space","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"type":"lvl3","url":"/sec-01-04-geospatial-thinking#relational-space","position":14},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"Relational Space","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"content":"Relational space is about the connectivity and the structure of connections---how connected are them?\n\n\n\nRelational Space. The links show the connections between spatial units. Those connected to the current location are highlighted in blue.","type":"content","url":"/sec-01-04-geospatial-thinking#relational-space","position":15},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"Mental Space","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"type":"lvl3","url":"/sec-01-04-geospatial-thinking#mental-space","position":16},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl3":"Mental Space","lvl2":"How Geographers See ‘Space’ and ‘Spatial’"},"content":"Mental space is about how people think about the location.\n\nIn modelling, we can go beyond ‘mental’, and makes it any type of attribute.\n\n\n\nMental Space. The size of point shows the familiarity of a person who stay at the current location.","type":"content","url":"/sec-01-04-geospatial-thinking#mental-space","position":17},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl2":"Summary"},"type":"lvl2","url":"/sec-01-04-geospatial-thinking#summary","position":18},{"hierarchy":{"lvl1":"GeoSpatial Thinking: Describing Space in Geography","lvl2":"Summary"},"content":"In general, what does space means?\n\nouter space\n\na physical location/place/area that is empty, i.e., a gap\n\na physical location/venue serves a particular urban function/purpose.\n\nHow geographers see ‘space’?\nThe 4 types/levels of space:\n\nAbsolute Space: the locations (coordinates)\n\nRelative Space: the nearby area (buffer, search radius)\n\nRelational Space: the connections & topological structure\n\nMental Space: how people think about the space, a dimension beyond physical space\n\nAs a geographer / geospatial data analyst, what is ‘spatial information’?\n\ndata related to the 4 types of space\n\nwhere is it?\n\nwhat is found next to it?\n\nwhat is connected to it?\n\nhow people describe it?\n\nattributes data (statistical, non-spatial) that attached to the space, e.g.,\n\nthe size (capacity)\n\nthe type (urban functions)\n\nthe crowdedness\n\nthe ranking\n\nthe demographic structure\n\netc.","type":"content","url":"/sec-01-04-geospatial-thinking#summary","position":19},{"hierarchy":{"lvl1":"Chapter 2: Data and Spatial Data"},"type":"lvl1","url":"/chapter-2-spatial-data","position":0},{"hierarchy":{"lvl1":"Chapter 2: Data and Spatial Data"},"content":"Objectives of this chapter\n\nTo know the basic steps of data preparation\n\nTo learn about frequency distribution and how to visualize the data based on frequency distribution\n\nTo learn about data transformation techniques and when to use it\n\nTo learn about data classification and key things to consider when classifying data\n\nTo learn data organisation and management and basic about database","type":"content","url":"/chapter-2-spatial-data","position":1},{"hierarchy":{"lvl1":"Data Preparation"},"type":"lvl1","url":"/sec-02-01-data-preparation","position":0},{"hierarchy":{"lvl1":"Data Preparation"},"content":"What do you think is the first step of data analysis?\n\nYes, it is Data Preprocessing","type":"content","url":"/sec-02-01-data-preparation","position":1},{"hierarchy":{"lvl1":"Data Preparation","lvl2":"About Data Preprocessing"},"type":"lvl2","url":"/sec-02-01-data-preparation#about-data-preprocessing","position":2},{"hierarchy":{"lvl1":"Data Preparation","lvl2":"About Data Preprocessing"},"content":"\n\nKey data preprocessing process.\n\nWhat to do after data collection\n\nIdentifying structure\n\nCleaning and Editing\n\nCoding\n\nClassification\n\nTranscription\n\nAlignment\n\nTabulation\n\nTransformation\n\nInitial analysis\n\nThe steps are not sequential.\nSometimes, some steps are done repeatedly, concurrently, and iteratively.","type":"content","url":"/sec-02-01-data-preparation#about-data-preprocessing","position":3},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Identifying structure","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#identifying-structure","position":4},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Identifying structure","lvl2":"About Data Preprocessing"},"content":"Look at the patterns\n\nWhat is/was the purpose for data collection?\n\nWhat is the design strategy of data collection?\n\nWhat is the structure/organization of the collected data?\n\nAny expectations? Counter-intuitive patterns?\n\nIs there any (expected/unexpected) relationships between variables?\n\nIs there any (expected/unexpected) hierarchies?\n\nIs there any (expected/unexpected) groupings?","type":"content","url":"/sec-02-01-data-preparation#identifying-structure","position":5},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Data Cleaning & Editing","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#data-cleaning-editing","position":6},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Data Cleaning & Editing","lvl2":"About Data Preprocessing"},"content":"Remove errors.\n\nRemove inconsistencies.\n\nResolve duplicate entries.\n\nWhat to do with missing values (default values, inputation, interpolation, deletion)?\n\nWhat to do with outliers?\n\nVerify accuracy of individual data points.\n\nEnsure data is complete and consistent.\n\nUse manual editing or automated data validation techniques.\n\nCorrect typos or formatting issues.\n\nDocumenting: write down the steps you took.","type":"content","url":"/sec-02-01-data-preparation#data-cleaning-editing","position":7},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Coding","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#coding","position":8},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Coding","lvl2":"About Data Preprocessing"},"content":"Assign codes to qualitative data (e.g., survey responses), e.g.,\n\nyes/no, true/false to 1 and 0 (or 1 and 2)\n\nmale/female to 1 and 0 (or 1 and 2)\n\nordered data, e.g., Very disagree, slightly disagree, neutral, slightly agree, very agree, to numbers (-2 to 2, or 0 to 4), etc.\n\ncategorical data, e.g., land use, land cover, urban functional zones, house types, to numbers (nominal).\n\nCreate new variables based on existing ones, e.g.,\n\ncalculating age from year of birth,\n\n5 yo age groups from age,\n\nincome levels from gross income,\n\nmeasuring differences (differences of magnitude vs. magnitude of differences).\n\nUse consistent coding schemes across various data sources.\n\n*Documenting: write down the code definitions and rules. *","type":"content","url":"/sec-02-01-data-preparation#coding","position":9},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Classification","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#classification","position":10},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Classification","lvl2":"About Data Preprocessing"},"content":"Organize data into predefined categories or classes.\n\nDefine classification criteria or rules:\n\nat what level of household income could be considered as ‘high’/‘medium’/‘low’ income\n\nhow many times a month can be considered high frequency\n\nApply classification methods consistently:\n\nnatural break, head-tail break, quantiles, etc.\n\nEvaluate classification validity, accuracy and consistency.\n\nDocumenting: write down the classification method and your reason.","type":"content","url":"/sec-02-01-data-preparation#classification","position":11},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Transcription","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#transcription","position":12},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Transcription","lvl2":"About Data Preprocessing"},"content":"(mainly for qualitative data collection approach)\n\nConvert audio to text using speech-to-text software.\n\nTranscribe video content to text format.\n\nExtract text from images using OCR (Optical Character Recognition).\n\nPerform manual or automated transcription as needed.","type":"content","url":"/sec-02-01-data-preparation#transcription","position":13},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Alignment","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#alignment","position":14},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Alignment","lvl2":"About Data Preprocessing"},"content":"Standardize formats, naming conventions, spatial scales, and units of measurement.\n\nEnsure compatibility between different data sources.\n\nMake sure the projections and anchor points are same.\n\nHandle inconsistencies in data representation or encoding.\n\nDocumenting: write down data alignment decisions and procedures.","type":"content","url":"/sec-02-01-data-preparation#alignment","position":15},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Tabulation","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#tabulation","position":16},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Tabulation","lvl2":"About Data Preprocessing"},"content":"Summarize data into tables or cross-tabulations.\n\nCreate join-able tables:\n\nunique identifiers/keys for every person/location\n\nsplit tables for participants’ background, participants’ perspective on XXX, participants’ performance\n\nFacilitate exploratory data analysis (EDA) and reporting.\n\nCreate pivot tables or aggregated data views.\n\nPresent data in a clear and concise format.","type":"content","url":"/sec-02-01-data-preparation#tabulation","position":17},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Transformation","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#transformation","position":18},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Transformation","lvl2":"About Data Preprocessing"},"content":"Apply appropriate transformations\n\nAddress skewness, non-linearity, or differing scales.\n\nPerform tests as needed (statistics assumptions for further analyses, etc.).\n\nNormalize or standardize data as needed.\n\nMonitor impact on data distribution and relationships.\n\nDocumenting: write down the steps and reasons.","type":"content","url":"/sec-02-01-data-preparation#transformation","position":19},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Initial analysis","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#initial-analysis","position":20},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Initial analysis","lvl2":"About Data Preprocessing"},"content":"Perform exploratory data analysis (EDA) to gain insights.\n\nIdentify trends, patterns, or relationships in the data.\n\nCheck assumptions for further analysis or modeling.\n\nGenerate visualizations (e.g., histograms, scatter plots) to support EDA.","type":"content","url":"/sec-02-01-data-preparation#initial-analysis","position":21},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Summary","lvl2":"About Data Preprocessing"},"type":"lvl3","url":"/sec-02-01-data-preparation#summary","position":22},{"hierarchy":{"lvl1":"Data Preparation","lvl3":"Summary","lvl2":"About Data Preprocessing"},"content":"Identifying structure: Looking for patterns\n\nCleaning and Editing: Identifying and resolving issues\n\nCoding: Assigning values and meanings\n\nClassification: Grouping and categorizing data\n\nTranscription: Extracting relevant information\n\nAlignment: Standardizing data formats\n\nTabulation: Creating a structured view of data\n\nTransformation: Manipulating data for analysis\n\nInitial analysis: Exploring patterns and trends\n\n\n\nMacEachren’s cartographic cube. In the exploring steps (lower left corner).","type":"content","url":"/sec-02-01-data-preparation#summary","position":23},{"hierarchy":{"lvl1":"Frequency Distribution"},"type":"lvl1","url":"/sec-02-02-frequency-distribution","position":0},{"hierarchy":{"lvl1":"Frequency Distribution"},"content":"Analyses start by viewing data. So, how to ‘view’ the data?\n\nTable 1:A slice of HDB data table.\n\nStreet\n\nFlat Type\n\nFloor Area (sqm)\n\nResale Age\n\nResale Price\n\nANG MO KIO AVE 10\n\n2 ROOM\n\n44\n\n44\n\n267000\n\nANG MO KIO AVE 3\n\n2 ROOM\n\n49\n\n46\n\n300000\n\nANG MO KIO AVE 3\n\n2 ROOM\n\n44\n\n45\n\n280000\n\nANG MO KIO AVE 3\n\n2 ROOM\n\n44\n\n45\n\n282000\n\nANG MO KIO AVE 4\n\n2 ROOM\n\n45\n\n37\n\n289800\n\n...\n\n...\n\n...\n\n...\n\n...\n\nUnderstanding frequency distribution\nA frequency distribution is a representation, usually in the form of a table or graph, that illustrates the number of occurrences (frequency) of each unique value or range of values within a given dataset. This visual or tabular summary of data distribution allows us to understand the spread, shape, and central tendency of the data, providing initial understanding of the underlying patterns and structures in the dataset.\n\nExamples of frequency distribution\n\nAnd the measures of central tendency and spread.\n\n(a): Bar chart (for discrete variable)\n(b): Histogram (for continuous variable)\n\n\n\nThe frequency distribution of resale transactions by: (a) flat type and (b) resale price.","type":"content","url":"/sec-02-02-frequency-distribution","position":1},{"hierarchy":{"lvl1":"Frequency Distribution","lvl2":"Frequency Distribution and Density Function"},"type":"lvl2","url":"/sec-02-02-frequency-distribution#frequency-distribution-and-density-function","position":2},{"hierarchy":{"lvl1":"Frequency Distribution","lvl2":"Frequency Distribution and Density Function"},"content":"Understanding PDF and CDF\n\nProbability Density Function (PDF):\n\nA mathematical function representing the relative likelihood of observing a continuous random variable in a specific range of values.\n\nPDFs have non-negative values, and their total area under the curve equals.\n\nDifferent PDF shapes correspond to various probability distributions (e.g., normal, exponential).\n\nCumulative Distribution Function (CDF):\n\nCalculates the cumulative probability of a random variable being less than or equal to a given value.\n\nThe CDF value at a point x corresponds to the area under the PDF curve to the left of x.\n\nCDFs are useful for assessing probabilities of events within a specific range.\n\nThe PDF and CDF are complementary tools in probability and statistics, providing insights into the distribution and likely outcomes of continuous random variables. PDFs offer a detailed view of relative likelihoods, while CDFs show the accumulated probabilities over a range of values. Together, they enable a comprehensive understanding of data distributions and facilitate various statistical analyses.\n\n\n\nThe (a) histogram, (b) PDF, and (c) CDF. In CDF, the x-axis value (167) that correspond to the y (density) value of 0.4 means that all the smaller values (x<167) contains 40% of the data points.\n\nThe PDF here is estimated from an empirical data series using Kernel Density Estimation (aka KDE).\n\nIf Y-axis shows count, then it should be a histogram, and if it shows ‘density’, then is should be either PDF or CDF.","type":"content","url":"/sec-02-02-frequency-distribution#frequency-distribution-and-density-function","position":3},{"hierarchy":{"lvl1":"Frequency Distribution","lvl2":"Interpreting Frequency Distributions"},"type":"lvl2","url":"/sec-02-02-frequency-distribution#interpreting-frequency-distributions","position":4},{"hierarchy":{"lvl1":"Frequency Distribution","lvl2":"Interpreting Frequency Distributions"},"content":"Measure of Central Tendency\n\nGravitational center: mean, aka arithmetic mean\n\nMiddle value: median\n\nMost frequent value: mode\n\nMeasure of Spread\n\nRange and inter-quartile range\n\nStandard deviation and variance\n\nMeasure of Shape\n\nSymmetry: Mirrored between left and right of central line\n\nSkewness: Has a long tail on right (positive skew) or left (negative skew)\n\nModality: Number of peaks\n\nKurtosis: Steepness of peak compared to a normal distribution\n\nwhat are the other ‘mean’ besides ‘arithmetic mean’?\n\nSymmetry\n\n\n\nSymmetrical shapes.\n\nAsymmetry\n\n\n\nAsymmetrical shapes.\n\nModality .square[Various modality shapes.]\n\n\n\nKurtosis .square[Various Kurtosis shapes.]","type":"content","url":"/sec-02-02-frequency-distribution#interpreting-frequency-distributions","position":5},{"hierarchy":{"lvl1":"Frequency Distribution","lvl3":"Common Types of Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl3","url":"/sec-02-02-frequency-distribution#common-types-of-frequency-distributions","position":6},{"hierarchy":{"lvl1":"Frequency Distribution","lvl3":"Common Types of Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"\n\nThree common types of distribution.","type":"content","url":"/sec-02-02-frequency-distribution#common-types-of-frequency-distributions","position":7},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Normal Distribution","lvl3":"Common Types of Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#normal-distribution","position":8},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Normal Distribution","lvl3":"Common Types of Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"The normal distribution, also known as the Gaussian distribution or the “bell curve,” is often used to model continuous variables in various fields. It is particularly useful in statistics because of the Central Limit Theorem, which states that the distribution of sample means approaches a normal distribution as the sample size increases. The normal distribution has applications in many areas, such as finance, psychology, and engineering.\n\nMany real-world phenomena, such as heights, IQ scores, and measurement errors, tend to follow a normal distribution. As a result, the normal distribution plays a central role in statistics and is used as a basis for many statistical tests and analyses.\n\nThe normal distribution is defined by two parameters---the mean (\\mu) and standard deviation (\\sigma).\n\n\n\nNormal Distribution with various paramters (\\mu and \\sigma).","type":"content","url":"/sec-02-02-frequency-distribution#normal-distribution","position":9},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Poisson Distribution","lvl3":"Common Types of Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#poisson-distribution","position":10},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Poisson Distribution","lvl3":"Common Types of Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"The Poisson distribution is used to model discrete count data, such as the number of occurrences of a particular event within a specific time interval or spatial area. It is often applied to scenarios where events happen at a certain average rate, and each event is independent of the others. It has applications in various fields, such as telecommunications, insurance, and biology.\n\nThe Poisson distribution is ideal for modeling count data involving rare events. In many real-world situations, count data often represent occurrences of rare events.\n\nThe Poisson distribution is characterized by a single parameter, lambda (λ), which represents the average rate of events over a given time interval or a specific area.\n\n\n\nPoisson Distribution with various paramters (\\lambda).","type":"content","url":"/sec-02-02-frequency-distribution#poisson-distribution","position":11},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Binomial Distribution","lvl3":"Common Types of Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#binomial-distribution","position":12},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Binomial Distribution","lvl3":"Common Types of Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"The binomial distribution is also used for discrete data, specifically for modeling the number of successes in a fixed number of independent trials. Each trial has only two possible outcomes (e.g., success or failure, true or false), and the probability of success remains the same across all trials. It is frequently applied in areas such as quality control, marketing research, and opinion polls.\n\nThe binomial distribution provides a straightforward way to calculate the probability of observing a specific number of successful outcomes in a fixed number of trials. This makes it easy to understand and communicate the results of analyses using binomial distributions.\n\nThe binomial distribution involves two parameters:\nnumber of trials and the probability of success (or being one of the two options).\n\n\n\nBinomial Distribution with various paramters. Number of trials is fixed at 10.","type":"content","url":"/sec-02-02-frequency-distribution#binomial-distribution","position":13},{"hierarchy":{"lvl1":"Frequency Distribution","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl3","url":"/sec-02-02-frequency-distribution#visualizing-frequency-distributions","position":14},{"hierarchy":{"lvl1":"Frequency Distribution","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"","type":"content","url":"/sec-02-02-frequency-distribution#visualizing-frequency-distributions","position":15},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Histogram","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#histogram","position":16},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Histogram","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"\n\nHistogram of resale prices, differentiated by flat types.","type":"content","url":"/sec-02-02-frequency-distribution#histogram","position":17},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"PDF plot","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#pdf-plot","position":18},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"PDF plot","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"\n\nPDF of resale prices, differentiated by flat types.","type":"content","url":"/sec-02-02-frequency-distribution#pdf-plot","position":19},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"CDF plot","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#cdf-plot","position":20},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"CDF plot","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"\n\nCDF of resale prices, differentiated by flat types.","type":"content","url":"/sec-02-02-frequency-distribution#cdf-plot","position":21},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Box plot","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#box-plot","position":22},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Box plot","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"\n\nBox plot of resale prices, differentiated by flat types.","type":"content","url":"/sec-02-02-frequency-distribution#box-plot","position":23},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Boxen plot","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#boxen-plot","position":24},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Boxen plot","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"\n\nBoxen plot of resale prices, differentiated by flat types.","type":"content","url":"/sec-02-02-frequency-distribution#boxen-plot","position":25},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Joint grid plot for 2-variables","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"type":"lvl4","url":"/sec-02-02-frequency-distribution#joint-grid-plot-for-2-variables","position":26},{"hierarchy":{"lvl1":"Frequency Distribution","lvl4":"Joint grid plot for 2-variables","lvl3":"Visualizing Frequency Distributions","lvl2":"Interpreting Frequency Distributions"},"content":"\n\nJoint grid (scatter plot and PDF) of floor area vs. resale prices, differentiated by flat types.","type":"content","url":"/sec-02-02-frequency-distribution#joint-grid-plot-for-2-variables","position":27},{"hierarchy":{"lvl1":"Data Transformation"},"type":"lvl1","url":"/sec-02-03-data-transformation","position":0},{"hierarchy":{"lvl1":"Data Transformation"},"content":"What is Data Transformation\n\nDefinition:\nData transformation is the process of converting data from one form or scale to another to improve analysis and interpretation.\n\nPurpose:\n\nTo meet the assumptions of statistical tests,\n\nhandle the scale of data range differences,\n\nenhance the performance of machine learning models,\n\netc.\n\nImportance:\nProper data transformation can significantly affect the quality of insights derived from data analysis and modeling.","type":"content","url":"/sec-02-03-data-transformation","position":1},{"hierarchy":{"lvl1":"Data Transformation","lvl2":"Common data transformation techniques"},"type":"lvl2","url":"/sec-02-03-data-transformation#common-data-transformation-techniques","position":2},{"hierarchy":{"lvl1":"Data Transformation","lvl2":"Common data transformation techniques"},"content":"Min-Max Scaling\n\nStandardization\n\nLog transformation\n\nBox-Cox transformation\n\nRanking data transformation","type":"content","url":"/sec-02-03-data-transformation#common-data-transformation-techniques","position":3},{"hierarchy":{"lvl1":"Data Transformation","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"type":"lvl3","url":"/sec-02-03-data-transformation#min-max-scaling","position":4},{"hierarchy":{"lvl1":"Data Transformation","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"content":"Definition and purpose:\nMin-max scaling is a popular data normalization technique that transforms features to fall within a specific range, typically between 0 and 1.\n\nEquation:X'=\\frac{X-a}{b-a} \\times (b' - a') + a'\n\nWhere:\n\nX' is the scaled value of the feature X.\n\nX is the original value of the feature.\n\na is the minimum value of the feature across all samples.\n\nb is the maximum value of the feature across all samples.\n\na' & b' is the new minimum and maximum values, respectively, for the target range.\n\nWhen to use:\nNormalizing data to a specific range and preserving original shape.","type":"content","url":"/sec-02-03-data-transformation#min-max-scaling","position":5},{"hierarchy":{"lvl1":"Data Transformation","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"type":"lvl3","url":"/sec-02-03-data-transformation#min-max-scaling-1","position":6},{"hierarchy":{"lvl1":"Data Transformation","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"content":"\n\nThe histogram (top) and PDF (bottom) of the average subzone resale price before (left) and after (right) min-max scaling.\n\nAdvantages:\n\nSimple,\n\neasy to understand,\n\npreserves shape.\n\nDisadvantages:\n\nSensitive to outliers,\n\nless robust.","type":"content","url":"/sec-02-03-data-transformation#min-max-scaling-1","position":7},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Standardization","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"type":"lvl4","url":"/sec-02-03-data-transformation#standardization","position":8},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Standardization","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"content":"Definition and purpose:\nStandardization (aka Z-score normalization) is a data transformation technique that scales features to have zero mean and unit variance. Its purpose is to make different features comparable by transforming them to a common scale.\n\nEquation:X' = \\frac{X - \\mu}{\\sigma}\n\nWhere:\n\nX is the original feature value.\n\n\\mu is the mean of the feature values.\n\n\\sigma is the standard deviation of the feature values.\n\n.When to use:\n\nWhen working with features measured on different scales (e.g., age, income, and temperature).\n\nWhen using machine learning algorithms that are sensitive to feature scales, such as linear discriminant analysis, logistic regression, or principal component analysis.\n\n\n\nThe histogram (top) and PDF (bottom) of the average subzone resale price before (left) and after (right) standardization.\n\n\n\nThe PDF (top) of the average subzone resale price of 3 rooms and 5 rooms HDB flat before (left) and after (right) standardization. The two scatter plots at the bottom show the relationship between 3 and 5 room HDB flat.\n\nAdvantages:\n\nUnit variance and zero mean\n\nDimensionless (unitless)\n\nRobust to outliers\n\n(potentially) Reduces multicollinearity.\n\nDisadvantages:\n\nRemoved original scale and unit\n\nSensitive to new data\n\nNot suitable for non-normal/non-linear data\n\n(potentially) Not suitable for data crossing zero","type":"content","url":"/sec-02-03-data-transformation#standardization","position":9},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Log Transformation","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"type":"lvl4","url":"/sec-02-03-data-transformation#log-transformation","position":10},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Log Transformation","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"content":"Definition and Purpose:\nLog transformation is a data transformation technique that applies the natural logarithm to the original data.\nIt helps to reduce skewness in the data and stabilize variance for statistical analysis or modeling.\n\nEquation:X_{\\text{log}} = \\log(X)\n\nWhere:\n\ncould use various base for the log, common options include 2, 10, or e (natural log)\n\nWhen to Use:\n\nWhen the data is positively skewed or has a wide range of values.\n\nWhen the relationship between two variables can be better modeled using a logarithmic scale.\n\n\n\nThe before (left) and after (right) log-transformed of resale prices.\n\n\n\nThe before (top) and after (bottom) log-transformed of ridership (arrival passsenger).\n\nAdvantages\n\nReduces skewness in data.\n\nHelps stabilize variance.\n\nCan improve linearity in relationships between variables.\n\nDisadvantages\n\nDistorts the original scale of data, making interpretation more challenging.\n\nCannot be applied to negative values or zero.\n\nThe choice of logarithm base (e, 2, 10) may affect results and interpretation.","type":"content","url":"/sec-02-03-data-transformation#log-transformation","position":11},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Box-Cox","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"type":"lvl4","url":"/sec-02-03-data-transformation#box-cox","position":12},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Box-Cox","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"content":"Definition and Purpose:\nBox-Cox transformation is a power transformation technique that can stabilize variance and make data more normally distributed.\nIt is a family of transformations that includes the logarithmic (\\lambda=0) and square root (\\lambda=0.5) transformations as special cases.\n\nEquation:X_{\\text{box-cox}}(\\lambda) = \\frac{X^\\lambda - 1}{\\lambda} \\quad \\text{if} \\quad \\lambda \\neq 0X_{\\text{box-cox}}(\\lambda) = \\log(X) \\quad \\text{if} \\quad \\lambda = 0\n\nWhen to Use:\n\nWhen the data is not normally distributed or has varying degrees of skewness or kurtosis.\n\nWhen trying to linearize relationships between variables or equalize variances across groups.\n\n\n\nHistogram of Box-Cox transformed values, with \\lambda set to: 0, 0.25, 0.5, 1, 2, 3.\n\nAdvantages\n\nCan handle various degrees of skewness and kurtosis.\n\nProvides flexibility to choose the best transformation based on data characteristics.\n\nIncludes logarithmic and square root transformations as special cases.\n\nDisadvantages\n\nRequires estimating the optimal lambda parameter, which can be time-consuming.\n\nLoses some interpretability due to data transformation.\n\nMay not always provide a significant improvement in data normality.\n\nHow to determine which \\lambda is the best?","type":"content","url":"/sec-02-03-data-transformation#box-cox","position":13},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Ranking Data Transformation","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"type":"lvl4","url":"/sec-02-03-data-transformation#ranking-data-transformation","position":14},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Ranking Data Transformation","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"content":"Definition and Purpose:\nRanking data transformation replaces original values with their corresponding ranks, preserving the order or hierarchy of the data.\nIt can help in data visualization, feature engineering, or non-parametric statistical tests.\n\nHow it works:\nThere is no explicit equation for ranking data transformation. The process involves sorting the values and assigning ranks based on their positions in the sorted list. In case of ties, you can use methods like average, min, or max ranking.\n\nWhen to Use:\nWhen working with ordinal data or categorical data that can be ordered.\nWhen performing non-parametric statistical tests that require ranked data.\n\n\n\nThe relationship between the ranks and the original data, and the frequency distribution of the ranks.\n\nWhat is the expected frequency distribution? Why is it not exactly the same as the expected distribution?\n\nAdvantages\n\nSimplifies data interpretation by focusing on relative positions.\n\nCan mitigate the impact of outliers.\n\nSuitable for non-parametric statistical tests.\n\nDisadvantages\n\nLoses information about the original magnitude, scale, and internal variation of data.\n\nSensitive to ties in data, especially when using certain ranking methods.\n\nMay not be appropriate for all types of statistical analyses or machine learning algorithms.","type":"content","url":"/sec-02-03-data-transformation#ranking-data-transformation","position":15},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Other Techniques","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"type":"lvl4","url":"/sec-02-03-data-transformation#other-techniques","position":16},{"hierarchy":{"lvl1":"Data Transformation","lvl4":"Other Techniques","lvl3":"Min-Max Scaling","lvl2":"Common data transformation techniques"},"content":"Sigmoid function,\n\nYeo-Johnson transformation,\n\netc.","type":"content","url":"/sec-02-03-data-transformation#other-techniques","position":17},{"hierarchy":{"lvl1":"Data Transformation","lvl3":"Choosing the Right Technique","lvl2":"Common data transformation techniques"},"type":"lvl3","url":"/sec-02-03-data-transformation#choosing-the-right-technique","position":18},{"hierarchy":{"lvl1":"Data Transformation","lvl3":"Choosing the Right Technique","lvl2":"Common data transformation techniques"},"content":"A simple guide\n\nAssess data quality and characteristics:\nExamine your dataset for issues like missing values, outliers, non-linearity, and non-normal distributions. Identifying these challenges will inform the choice of transformation technique.\n\nUnderstand variable types:\nDetermine whether your variables are categorical or numerical. This will help you choose appropriate transformation methods, as some techniques are designed specifically for certain variable types.\n\nEvaluate the goals of your analysis:\nConsider the objectives of your data analysis and the specific requirements of your chosen modeling technique. Different transformations can address particular challenges or better align with specific analysis goals.\n\nInvestigate common transformation techniques:\nExplore various methods like logarithmic, square root, Box-Cox, or Z-score (standardization) transformations for numerical data, and one-hot encoding or ordinal encoding for categorical data.\n\nCompare the pros and cons:\nWeight the advantages and disadvantages of different techniques, considering factors like interpretability, ease of implementation, and potential impact on model performance.\n\nIterate and validate:\nTest multiple transformation techniques and evaluate their effects on your data and model performance. This will help you identify the most effective approach for your specific situation.\n\nConsult resources and domain experts (expert in GIS):\nLeverage the knowledge of experienced professionals, peer-reviewed literature, and other credible sources to inform your decision-making process.","type":"content","url":"/sec-02-03-data-transformation#choosing-the-right-technique","position":19},{"hierarchy":{"lvl1":"Data Classification"},"type":"lvl1","url":"/sec-02-04-data-classification","position":0},{"hierarchy":{"lvl1":"Data Classification"},"content":"","type":"content","url":"/sec-02-04-data-classification","position":1},{"hierarchy":{"lvl1":"Data Classification","lvl2":"Definition of Numerical Data Classification"},"type":"lvl2","url":"/sec-02-04-data-classification#definition-of-numerical-data-classification","position":2},{"hierarchy":{"lvl1":"Data Classification","lvl2":"Definition of Numerical Data Classification"},"content":"Numerical Data Classification is a method of categorizing or grouping numerical data into different classes or bins based on specific criteria or algorithms. This approach helps simplify data analysis, visualization, and interpretation by transforming continuous numerical values into discrete categories or intervals.\n\nThe number of breaks:\n\nfor visualization purpose, the common preferred number of breaks is \\leq 7,\n\ncommon numbers of breaks in practice is: 4--5,\n\nfollow the requirement of the analysis method or domain knowledge.\n\nSeveral common classification methods include:\n\nEqual Interval\n\nQuantile Breaks\n\nStandard Deviation\n\nNatural Breaks\n\nHead-tail Breaks","type":"content","url":"/sec-02-04-data-classification#definition-of-numerical-data-classification","position":3},{"hierarchy":{"lvl1":"Data Classification","lvl2":"Data Classification Approaches"},"type":"lvl2","url":"/sec-02-04-data-classification#data-classification-approaches","position":4},{"hierarchy":{"lvl1":"Data Classification","lvl2":"Data Classification Approaches"},"content":"","type":"content","url":"/sec-02-04-data-classification#data-classification-approaches","position":5},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Equal Interval","lvl2":"Data Classification Approaches"},"type":"lvl3","url":"/sec-02-04-data-classification#equal-interval","position":6},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Equal Interval","lvl2":"Data Classification Approaches"},"content":"This classification method involves dividing the range of the data into equal-sized intervals or classes. The class boundaries are determined by dividing the difference between the maximum and minimum values by the number of desired classes. This method is simple and easy to understand but may result in classes with significantly different numbers of observations or misrepresentation of the data distribution.\n\n\n\nThe breaks and the number of records in each class for Equal Interval.","type":"content","url":"/sec-02-04-data-classification#equal-interval","position":7},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Quantile Breaks","lvl2":"Data Classification Approaches"},"type":"lvl3","url":"/sec-02-04-data-classification#quantile-breaks","position":8},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Quantile Breaks","lvl2":"Data Classification Approaches"},"content":"Quantile classification is based on the statistical distribution of the data, dividing the data into classes with an equal number of observations. Each class represents a quantile, such as quartiles (4 classes), quintiles (5 classes), deciles (10 classes), or other user-specified quantiles. This method ensures that each class has an equal frequency of values.\n\n\n\nThe breaks and the number of records in each class for Quantiles.","type":"content","url":"/sec-02-04-data-classification#quantile-breaks","position":9},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Standard Deviation","lvl2":"Data Classification Approaches"},"type":"lvl3","url":"/sec-02-04-data-classification#standard-deviation","position":10},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Standard Deviation","lvl2":"Data Classification Approaches"},"content":"Standard Deviation classification divides the data into classes based on the number of standard deviations from the mean. This method is helpful for data that follow a normal or near-normal distribution, as it takes into account the dispersion and variability of the data.\n\n\n\nThe breaks and the number of records in each class for standard deviation.","type":"content","url":"/sec-02-04-data-classification#standard-deviation","position":11},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Natural Breaks","lvl2":"Data Classification Approaches"},"type":"lvl3","url":"/sec-02-04-data-classification#natural-breaks","position":12},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Natural Breaks","lvl2":"Data Classification Approaches"},"content":"Natural Breaks classification is a data-driven method that seeks to minimize the within-class variance and maximize the between-class variance. It identifies break points or class boundaries by grouping similar values together while keeping dissimilar values in different classes. This method is widely used in geographic information systems (GIS) and spatial data analysis.\n\n\n\nThe breaks and the number of records in each class for Natural Breaks.","type":"content","url":"/sec-02-04-data-classification#natural-breaks","position":13},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Head-tail Breaks","lvl2":"Data Classification Approaches"},"type":"lvl3","url":"/sec-02-04-data-classification#head-tail-breaks","position":14},{"hierarchy":{"lvl1":"Data Classification","lvl3":"Head-tail Breaks","lvl2":"Data Classification Approaches"},"content":"Head/Tail Breaks is a data classification method introduced to categorize data with heavy-tailed distributions. This method offers an alternative to traditional classification schemes by focusing on the inherent hierarchy within the data.\nThe Head/Tail Breaks method uses the mean or average to divide a dataset into small and large values recursively. It starts by calculating the first mean (m1) of the entire dataset and then calculates the second mean (m2) for values greater than m1. This process continues until the notion of “far more small things than large ones” no longer holds.\n\nSee \n\nHead/Tail Breaks: A New Classification Scheme for Data with a Heavy-Tailed Distribution for more details.\n\n\n\nThe breaks and the number of records in each class for Head/Tail Breaks.","type":"content","url":"/sec-02-04-data-classification#head-tail-breaks","position":15},{"hierarchy":{"lvl1":"Data Classification","lvl2":"Summary"},"type":"lvl2","url":"/sec-02-04-data-classification#summary","position":16},{"hierarchy":{"lvl1":"Data Classification","lvl2":"Summary"},"content":"Choosing an optimal data classification scheme is essential for effectively summarizing and analyzing numerical data. The selection depends on the data’s characteristics, the analysis objectives, and the desired level of detail. See a list here from \n\nmapclassify for many other approaches.\nExperiment with different methods and assess their effectiveness in achieving your analytical goals. The optimal scheme should provide meaningful distinctions between classes, maintain simplicity, and facilitate accurate data interpretation.\n\nWhile Natural Breaks is the default option in many GIS software, it is not always the most suitable option for the data. Sometime, manually breaking the data is also recommended.\n\nEqual Interval: This simple method divides the data range into equal-sized intervals. It is straightforward and easy to understand but may result in classes with significantly different numbers of observations.\n\nQuantile Breaks: This method divides data into classes with an equal number of observations based on statistical distribution. It is useful when you require a specific number of classes or a balanced representation of the data.\n\nStandard Deviation: This method classifies data based on the number of standard deviations from the mean. It is helpful when data follows a normal or near-normal distribution and accounts for data dispersion and variability.\n\nNatural Breaks: This data-driven method minimizes within-class variance and maximizes between-class variance. It is widely used in geographic information systems (GIS) and spatial data analysis. Jenks’ natural breaks are suitable for datasets with uneven distributions or when you need to emphasize the differences between groups.\n\nHead/Tail Breaks: Introduced by Jiang (2013), this recursive method focuses on capturing the inherent hierarchy within heavy-tailed data. It provides an alternative to traditional schemes and is particularly suitable for data with a heavy-tailed distribution.","type":"content","url":"/sec-02-04-data-classification#summary","position":17},{"hierarchy":{"lvl1":"Spatial Database"},"type":"lvl1","url":"/sec-02-05-spatial-database","position":0},{"hierarchy":{"lvl1":"Spatial Database"},"content":"","type":"content","url":"/sec-02-05-spatial-database","position":1},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"Why (do we need to talk about) (Spatial) Database"},"type":"lvl2","url":"/sec-02-05-spatial-database#why-do-we-need-to-talk-about-spatial-database","position":2},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"Why (do we need to talk about) (Spatial) Database"},"content":"Data Management and Organization:\nSpatial databases play a crucial role in managing, storing, and querying large volumes of geospatial data. A solid understanding of spatial databases helps geovisualization professionals effectively organize and access data, ensuring efficient workflows and accurate analysis.\n\nData Retrieval and Query Performance:\nGeovisualization often involves working with complex spatial queries and data retrieval tasks. By discussing spatial databases, students can learn how to optimize these queries and improve performance, resulting in faster and more efficient data retrieval for visualization purposes.\n\nData Quality and Consistency:\nSpatial databases provide tools and techniques for maintaining data quality, consistency, and integrity. This knowledge is vital for geovisualization professionals, as data quality directly impacts the accuracy and reliability of their visualizations.\n\nData Analysis and Modeling:\nSpatial databases support various geospatial analysis and modeling techniques, such as spatial statistics, spatial interpolation, and geostatistics. A strong foundation in spatial databases allows geovisualization professionals to leverage these advanced methods and create more informative visualizations.","type":"content","url":"/sec-02-05-spatial-database#why-do-we-need-to-talk-about-spatial-database","position":3},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"About Data Management"},"type":"lvl2","url":"/sec-02-05-spatial-database#about-data-management","position":4},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"About Data Management"},"content":"","type":"content","url":"/sec-02-05-spatial-database#about-data-management","position":5},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"How do you manage your photos?","lvl2":"About Data Management"},"type":"lvl3","url":"/sec-02-05-spatial-database#how-do-you-manage-your-photos","position":6},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"How do you manage your photos?","lvl2":"About Data Management"},"content":"Most cellphones take nice photos​\n\nTaking 3 photos a day will give you ~1,000 photos a year​\n\nTaking a 5-day vacation would give you 200 photos​\n\nWays to managing photos​\n\nLeave them on the phone?​\n\nOrganize them into folders?​\n\nUpload them to some cloud services?​\n\nWhich method is the best?​\n\n\n\nFigure 1:Sultan Mosque, Singapore. Photo by \n\nCharles Postiaux on \n\nUnsplash\n\nManaging photos is very similar to the way of managing data, and vice versa.\n\n\n\nThe photo management.","type":"content","url":"/sec-02-05-spatial-database#how-do-you-manage-your-photos","position":7},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"Data Management"},"type":"lvl2","url":"/sec-02-05-spatial-database#data-management","position":8},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"Data Management"},"content":"","type":"content","url":"/sec-02-05-spatial-database#data-management","position":9},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Definition (Oracle)","lvl2":"Data Management"},"type":"lvl3","url":"/sec-02-05-spatial-database#definition-oracle","position":10},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Definition (Oracle)","lvl2":"Data Management"},"content":"Data management is the practice of collecting, keeping, and using data securely, efficiently, and cost-effectively.\n\nhelp people, organizations, and connected things\n\noptimize the use of data within the bounds of policy and regulation\n\n(use data to) enable data-driven decision-makings and take actions that maximize the benefit to the organisation","type":"content","url":"/sec-02-05-spatial-database#definition-oracle","position":11},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Database Operations - CRUD","lvl2":"Data Management"},"type":"lvl3","url":"/sec-02-05-spatial-database#database-operations-crud","position":12},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Database Operations - CRUD","lvl2":"Data Management"},"content":"__C__reate: The Create operation is used to add new records (or rows) to a database table.\n\n__R__ead: The Read operation is used to retrieve or fetch existing records from a database table.\n\n__U__pdate: The Update operation is used to modify existing records in a database table.\n\n__D__elete: The Delete operation is used to remove existing records from a database table.","type":"content","url":"/sec-02-05-spatial-database#database-operations-crud","position":13},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"What is Database and Spatial Database","lvl2":"Data Management"},"type":"lvl3","url":"/sec-02-05-spatial-database#what-is-database-and-spatial-database","position":14},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"What is Database and Spatial Database","lvl2":"Data Management"},"content":"Database: an integrated set of data on a particular subject, which is often used to store, and organize data\n\nSpatial (or Geographic) database: database containing geographic data of a particular subject for a particular area\n\n\n\nSpatial Database","type":"content","url":"/sec-02-05-spatial-database#what-is-database-and-spatial-database","position":15},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Characteristics of (spatial) database","lvl2":"Data Management"},"type":"lvl3","url":"/sec-02-05-spatial-database#characteristics-of-spatial-database","position":16},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Characteristics of (spatial) database","lvl2":"Data Management"},"content":"Data is under centralized control\n\nCan guarantee data sharing among different users and applications\n\nDifferent from file management in which files are dispersed\n\nData are independent\n\nDatabase is independent of the application systems, and thus can be called by various application systems\n\nData redundancy is small\n\nAvoid repetitive data storage\n\nImprove data usage efficiency\n\nDatabase has complex data model structure\n\nThe complex data model structure is used for data organization and data management\n\nVital difference from file management\n\nDatabase has the function of data protection\n\nA password and permission for access must be set\n\nclass: left, middle","type":"content","url":"/sec-02-05-spatial-database#characteristics-of-spatial-database","position":17},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Database Management Systems (DBMS)","lvl2":"Data Management"},"type":"lvl3","url":"/sec-02-05-spatial-database#database-management-systems-dbms","position":18},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Database Management Systems (DBMS)","lvl2":"Data Management"},"content":"A system to perform database operations on tables\n\nCRUD (Create, Read, Update, Delete)\n\nproviding a systematic way to store, organize, retrieve, and manipulate data.\n\nIt ensures data consistency, integrity, and security while enabling efficient access and data sharing among multiple users or applications.\n\nA DBMS supports various database models and provides features like backup, recovery, and performance optimization for effective data management.\n\nBasic and key characteristics of DBMS:\n\nPersistence across failures --- maintain a consistent system after failures – software, hardware, network failures, etc.\n\nConcurrent access to data\n\nScalability to search on very large datasets (which do not fit inside main memories of computers)\n\nEfficiency","type":"content","url":"/sec-02-05-spatial-database#database-management-systems-dbms","position":19},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"DBMS clients","lvl2":"Data Management"},"type":"lvl3","url":"/sec-02-05-spatial-database#dbms-clients","position":20},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"DBMS clients","lvl2":"Data Management"},"content":"an interface between users and the DBMS\n\nallow users to connect, access, and interact with the database\n\na software package that enables people to build and manipulate a database\n\nExamples:\n\nMySQL Workbench,\n\npgAdmin\n\nSQL Developer\n\nMicrosoft Access (dBase file)\n\ndBeaver","type":"content","url":"/sec-02-05-spatial-database#dbms-clients","position":21},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"Relational Database"},"type":"lvl2","url":"/sec-02-05-spatial-database#relational-database","position":22},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"Relational Database"},"content":"It is a collection of tables, also called relations\n\nThe tables are connected to each other by keys\n\nA primary key: represents one or more attributes whose values can uniquely identify a record in a table\n\nA foreign key: is one or more attributes that refer to a primary key in another table","type":"content","url":"/sec-02-05-spatial-database#relational-database","position":23},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Primary key, Foreign key, Composite key","lvl2":"Relational Database"},"type":"lvl3","url":"/sec-02-05-spatial-database#primary-key-foreign-key-composite-key","position":24},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Primary key, Foreign key, Composite key","lvl2":"Relational Database"},"content":"Typically, one column, the primary key contains the unique ID (identifier) of the described things, e.g., student IDs, social security numbers\n\nThis primary key column can exist in other tables to establish a relation, i.e., the foreign key\n\nA composite key is typically generated by combining the values of two or more columns in a table,\ne.g., student ID + course ID\n\n\n\nThe keys in Relational Database.","type":"content","url":"/sec-02-05-spatial-database#primary-key-foreign-key-composite-key","position":25},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Logical relation types","lvl2":"Relational Database"},"type":"lvl3","url":"/sec-02-05-spatial-database#logical-relation-types","position":26},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Logical relation types","lvl2":"Relational Database"},"content":"One-to-one\n\n\nOne-to-many\n\n\nMany-to-one\n\n\nMany-to-many\n","type":"content","url":"/sec-02-05-spatial-database#logical-relation-types","position":27},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"One-to-one ","lvl3":"Logical relation types","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#one-to-one","position":28},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"One-to-one ","lvl3":"Logical relation types","lvl2":"Relational Database"},"content":"Every entity on the left can connect to one and only one entity on the right.\n\n\n\nOne-to-one demo.","type":"content","url":"/sec-02-05-spatial-database#one-to-one","position":29},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"One-to-many ","lvl3":"Logical relation types","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#one-to-many","position":30},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"One-to-many ","lvl3":"Logical relation types","lvl2":"Relational Database"},"content":"Every entity on the left can connect to multiple entities on the right.\nEvery entity on the right can connect to one and only one entity on the left.\n\n\n\nOne-to-many demo.","type":"content","url":"/sec-02-05-spatial-database#one-to-many","position":31},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Many-to-one ","lvl3":"Logical relation types","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#many-to-one","position":32},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Many-to-one ","lvl3":"Logical relation types","lvl2":"Relational Database"},"content":"Every entity on the left can connect to one and only one entity on the right.\nEvery entity on the right can connect to multiple entities on the left.\n\n\n\nMany-to-one demo.","type":"content","url":"/sec-02-05-spatial-database#many-to-one","position":33},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Many-to-many ","lvl3":"Logical relation types","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#many-to-many","position":34},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Many-to-many ","lvl3":"Logical relation types","lvl2":"Relational Database"},"content":"Every entity on the left can connect to multiple entities on the right.\nEvery entity on the right can connect to multiple entities on the left​.\n\n\n\nMany-to-many demo.\n\n\n\nA database for food order & delivery system.","type":"content","url":"/sec-02-05-spatial-database#many-to-many","position":35},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Advantages of Relational Database","lvl2":"Relational Database"},"type":"lvl3","url":"/sec-02-05-spatial-database#advantages-of-relational-database","position":36},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Advantages of Relational Database","lvl2":"Relational Database"},"content":"Each table in the database can be prepared, maintained, and edited separately from other tables\n\nThis is important as more (GIS) data are being recorded and added\n\nThe tables can remain separate until a query or an analysis requires that attribute data from different tables be linked (joined) together, which is favorable to both data management and data processing.","type":"content","url":"/sec-02-05-spatial-database#advantages-of-relational-database","position":37},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Normalization: Preparing a relational database","lvl2":"Relational Database"},"type":"lvl3","url":"/sec-02-05-spatial-database#normalization-preparing-a-relational-database","position":38},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Normalization: Preparing a relational database","lvl2":"Relational Database"},"content":"Normalization is the process of decomposition, taking a table with all the attribute data, and breaking it down into small tables while maintaining the necessary linkages between them.\n\nObjectives of normalization:\n\nTo avoid redundant data\n\nTo ensure that attribute data in separate tables can be maintained and updated separately and can be linked whenever necessary\n\nTo facilitate a distributed database","type":"content","url":"/sec-02-05-spatial-database#normalization-preparing-a-relational-database","position":39},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"type":"lvl3","url":"/sec-02-05-spatial-database#demonstration-of-database-normalisation","position":40},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"content":"\n\nA demo table, before normalisation.","type":"content","url":"/sec-02-05-spatial-database#demonstration-of-database-normalisation","position":41},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Step 0: Observation on the unnormalized table","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#step-0-observation-on-the-unnormalized-table","position":42},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Step 0: Observation on the unnormalized table","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"content":"Database Normalization is mainly to separate information from different types of entities to separated tables.\n\n\n\nFirst step is to observe the composition and structure of the database: how many and what are the different ‘entity’ or ‘object’ in the table.","type":"content","url":"/sec-02-05-spatial-database#step-0-observation-on-the-unnormalized-table","position":43},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Step 1: Fill Missing Values","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#step-1-fill-missing-values","position":44},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Step 1: Fill Missing Values","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"content":"Step 1 fills the empty cells, and each cell has one value.\nBut the problem of data redundancy has increased.\n\n\n\nThe original data may organised in an ordered way such that the repeated values are skipped if it is same as the one before.","type":"content","url":"/sec-02-05-spatial-database#step-1-fill-missing-values","position":45},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Step 2: Table Decomposition","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#step-2-table-decomposition","position":46},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Step 2: Table Decomposition","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"content":"\n\nDecopmose the table. Still, there are one table with two types of ‘object’.","type":"content","url":"/sec-02-05-spatial-database#step-2-table-decomposition","position":47},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Step 3: Table Decomposition again","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#step-3-table-decomposition-again","position":48},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Step 3: Table Decomposition again","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"content":"\n\nKeep decompose the table again, until every table only represent a single type of object.","type":"content","url":"/sec-02-05-spatial-database#step-3-table-decomposition-again","position":49},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Done Normalisation","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#done-normalisation","position":50},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Done Normalisation","lvl3":"Demonstration of database normalisation","lvl2":"Relational Database"},"content":"\n\nFinalise the table decomposition and the normalisation is complete.","type":"content","url":"/sec-02-05-spatial-database#done-normalisation","position":51},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Table join and relate","lvl2":"Relational Database"},"type":"lvl3","url":"/sec-02-05-spatial-database#table-join-and-relate","position":52},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Table join and relate","lvl2":"Relational Database"},"content":"Since now the tables are separated and represent a single object, how to ‘combine’ them again for other data operation and usage? Table join and relate are the two frequently used database operation in GIS.","type":"content","url":"/sec-02-05-spatial-database#table-join-and-relate","position":53},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Table join","lvl3":"Table join and relate","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#table-join","position":54},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Table join","lvl3":"Table join and relate","lvl2":"Relational Database"},"content":"A join operation brings together two tables by using a common field or a primary key and a foreign key.\n\n","type":"content","url":"/sec-02-05-spatial-database#table-join","position":55},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Table relate","lvl3":"Table join and relate","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#table-relate","position":56},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Table relate","lvl3":"Table join and relate","lvl2":"Relational Database"},"content":"A relate operation temporarily connects two tables but keeps the tables physically separate\n\nDoes not append the data from one table to another\n\nThree or more tables can be simultaneously connected\n\nSupport all relationships\n\n].column[\n\n","type":"content","url":"/sec-02-05-spatial-database#table-relate","position":57},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Comparison of Join and Relate","lvl2":"Relational Database"},"type":"lvl3","url":"/sec-02-05-spatial-database#comparison-of-join-and-relate","position":58},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Comparison of Join and Relate","lvl2":"Relational Database"},"content":"","type":"content","url":"/sec-02-05-spatial-database#comparison-of-join-and-relate","position":59},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Join","lvl3":"Comparison of Join and Relate","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#join","position":60},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Join","lvl3":"Comparison of Join and Relate","lvl2":"Relational Database"},"content":"Combines data from two tables into a single table or layer.\n\nMost often used for one-to-one or many-to-one relationships.\n\nRequires a common field in both tables.\n\nCreates a static connection between tables (updates are not synchronized).\n\nAppended columns are editable, but changes won’t reflect in the original table.","type":"content","url":"/sec-02-05-spatial-database#join","position":61},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Relate","lvl3":"Comparison of Join and Relate","lvl2":"Relational Database"},"type":"lvl4","url":"/sec-02-05-spatial-database#relate","position":62},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Relate","lvl3":"Comparison of Join and Relate","lvl2":"Relational Database"},"content":"Establishes a temporary, dynamic connection between two tables or layers without physically combining them.\n\nAllows for one-to-one, one-to-many, and many-to-many relationships.\n\nRequires a common field in both tables.\n\nProvides real-time access to related data (updates are reflected when accessing related information).\n\nAllows for editing related data, but changes in the target table won’t be synchronized back to the original related table.","type":"content","url":"/sec-02-05-spatial-database#relate","position":63},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl2","url":"/sec-02-05-spatial-database#the-special-of-spatial-in-spatial-database","position":64},{"hierarchy":{"lvl1":"Spatial Database","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"\n\nWhat about ‘spatial’ in spatial database? The location, proximity, and direction in Google Map.\n\nLocation:\nSpatial databases store and manage data with a geographical component, allowing users to associate locations with other attributes for enhanced analysis and visualization.​\n\nProximity:\nSpatial databases enable proximity analysis, facilitating the identification of nearby features, calculation of distances, and exploration of spatial relationships between various data points.​\n\nDirection:\nWith spatial databases, direction-based queries and navigation-based queries, enabling route planning, shortest path calculations, and network analysis to optimize movement and travel within spatial data contexts.​\n\nSpatial is indeed special!","type":"content","url":"/sec-02-05-spatial-database#the-special-of-spatial-in-spatial-database","position":65},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Spatial join","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl3","url":"/sec-02-05-spatial-database#spatial-join","position":66},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Spatial join","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"A spatial join uses a spatial relationship to join two sets of spatial features and their attribute data.\n\nIn \n\nFigure 19:\n\n(left) Join a school to a county in which the school is located\n\n(center) Join a highway to a forest area by which the highway is intersected​\n\n(right) Join a villages to a fault line which the village is closest to\n\n\n\nFigure 19:‘Merging’ (join/relate) table by spatial relationships.","type":"content","url":"/sec-02-05-spatial-database#spatial-join","position":67},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Example of spatial database","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl3","url":"/sec-02-05-spatial-database#example-of-spatial-database","position":68},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Example of spatial database","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"PostgreSQL + PostGIS\n\nMysql + Spatial Extension\n\nSQLite + SpatiaLite\n\nDuckDB + Spatial Extension\n\nMongoDB\n\nCrateDB","type":"content","url":"/sec-02-05-spatial-database#example-of-spatial-database","position":69},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Spatial Indexing","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl3","url":"/sec-02-05-spatial-database#spatial-indexing","position":70},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Spatial Indexing","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"Operationaly, what is the addition of SPATIAL to the database?\n\nSpatial indexing is a crucial and arguably the main component of a spatial database because it’s essential for efficiently querying large datasets of geographic or geometric data.\n\nKD-Tree, QuadTree\n\nR-Tree\n\n\n\nImage source: \n\nWikipedia: R-tree","type":"content","url":"/sec-02-05-spatial-database#spatial-indexing","position":71},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl3","url":"/sec-02-05-spatial-database#example-of-spatial-query-postgis","position":72},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"","type":"content","url":"/sec-02-05-spatial-database#example-of-spatial-query-postgis","position":73},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Create table","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl4","url":"/sec-02-05-spatial-database#create-table","position":74},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Create table","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"CREATE TABLE public.cities (\n    id serial PRIMARY KEY,\n    name VARCHAR(255),\n    population INT,\n    geom GEOMETRY(Point, 4326) -- Point geometry, SRID 4326 (WGS 84 geographic coordinate system)\n);","type":"content","url":"/sec-02-05-spatial-database#create-table","position":75},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Insert data rows (point)","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl4","url":"/sec-02-05-spatial-database#insert-data-rows-point","position":76},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Insert data rows (point)","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"INSERT INTO public.cities (name, population, geom) VALUES\n('London', 8982000, ST_SetSRID(ST_MakePoint(-0.1278, 51.5074), 4326)),\n('Paris', 2141000, ST_SetSRID(ST_MakePoint(2.3522, 48.8566), 4326)),\n('New York', 8419000, ST_SetSRID(ST_MakePoint(-74.0060, 40.7128), 4326));","type":"content","url":"/sec-02-05-spatial-database#insert-data-rows-point","position":77},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl3","url":"/sec-02-05-spatial-database#example-of-spatial-query-postgis-1","position":78},{"hierarchy":{"lvl1":"Spatial Database","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"","type":"content","url":"/sec-02-05-spatial-database#example-of-spatial-query-postgis-1","position":79},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Finding cities within a search distance from a point","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl4","url":"/sec-02-05-spatial-database#finding-cities-within-a-search-distance-from-a-point","position":80},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Finding cities within a search distance from a point","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"    SELECT name\n    FROM public.cities\n    WHERE ST_DWithin(\n        geom::geography,\n        ST_SetSRID(ST_MakePoint(-0.1278, 51.5074), 4326)::geography,\n        100000 -- distance in meters\n    );","type":"content","url":"/sec-02-05-spatial-database#finding-cities-within-a-search-distance-from-a-point","position":81},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Spatial Joins","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl4","url":"/sec-02-05-spatial-database#spatial-joins","position":82},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Spatial Joins","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"-- Assuming another table 'countries' with a 'geom' column (Polygon)\nSELECT c.name AS city_name, co.name AS country_name\nFROM public.cities AS c, public.countries AS co\nWHERE ST_Contains(co.geom, c.geom);","type":"content","url":"/sec-02-05-spatial-database#spatial-joins","position":83},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Do calculation (area)","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"type":"lvl4","url":"/sec-02-05-spatial-database#do-calculation-area","position":84},{"hierarchy":{"lvl1":"Spatial Database","lvl4":"Do calculation (area)","lvl3":"Example of spatial query (PostGIS)","lvl2":"The Special of ‘Spatial’ in ‘Spatial Database’"},"content":"    SELECT ST_Area(ST_GeomFromText('POLYGON((0 0, 0 1, 1 1, 1 0, 0 0))', 4326));","type":"content","url":"/sec-02-05-spatial-database#do-calculation-area","position":85},{"hierarchy":{"lvl1":"Chapter 3: Statistical Pattern"},"type":"lvl1","url":"/chapter-3-stat-pattern","position":0},{"hierarchy":{"lvl1":"Chapter 3: Statistical Pattern"},"content":"Objectives of this chapter\n\nTo know how to measure and visualize differences\n\nTo learn t-test and when to use it\n\nTo learn ANOVA and when to use it\n\nTo learn non-parametric tests and when to use them","type":"content","url":"/chapter-3-stat-pattern","position":1},{"hierarchy":{"lvl1":"The Hypothesis Testing"},"type":"lvl1","url":"/sec-03-01-hypothesis-testing","position":0},{"hierarchy":{"lvl1":"The Hypothesis Testing"},"content":"What is the first step of getting your hands dirty?\n\nTable 1:Iris dataset.\n\nID\n\nVariety\n\nSepal Length\n\nSepal Width\n\nPetal Length\n\nPetal Width\n\n0\n\nSetosa\n\n5.1\n\n3.5\n\n1.4\n\n0.2\n\n1\n\nSetosa\n\n4.9\n\n3\n\n1.4\n\n0.2\n\n2\n\nSetosa\n\n4.7\n\n3.2\n\n1.3\n\n0.2\n\n3\n\nSetosa\n\n4.6\n\n3.1\n\n1.5\n\n0.2\n\n4\n\nSetosa\n\n5\n\n3.6\n\n1.4\n\n0.2\n\n..\n\n...\n\n...\n\n...\n\n...\n\n...\n\nFirst Step: Draw the frequency distribution.\n\nBelow is an example of Iris’ petal length from week 1, when we talked about the analysis of differences.\n\nThe frequency distributions were drawn separately for different species of Iris, which provided a visual comparison between the three species.\n\nAre them different?\n\n\n\nThe differences in petal length between the three species.","type":"content","url":"/sec-03-01-hypothesis-testing","position":1},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"Define Differences"},"type":"lvl2","url":"/sec-03-01-hypothesis-testing#define-differences","position":2},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"Define Differences"},"content":"In statistics, “difference” typically refers to the extent to which two or more groups, samples, or observations differ from one another. This can be quantified and assessed through various statistical measures and analyses, depending on the nature of the data and research questions.\n\nGroups: by genders, by years, by types\n\nData point in groups: individual participant, transaction, bus stop, district\n\n\n\nHow to determine if they are different or not so different?","type":"content","url":"/sec-03-01-hypothesis-testing#define-differences","position":3},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl3":"Spotting The Differences","lvl2":"Define Differences"},"type":"lvl3","url":"/sec-03-01-hypothesis-testing#spotting-the-differences","position":4},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl3":"Spotting The Differences","lvl2":"Define Differences"},"content":"\n\nThe differences in the 4 variables between species.","type":"content","url":"/sec-03-01-hypothesis-testing#spotting-the-differences","position":5},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"Hypothesis Testing"},"type":"lvl2","url":"/sec-03-01-hypothesis-testing#hypothesis-testing","position":6},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"Hypothesis Testing"},"content":"Hypothesis testing is a statistical method used to evaluate claims or assertions about a population parameter by analyzing sample data.\n\nThe goal is to determine if the observed differences between groups or samples are statistically significant or merely due to chance.","type":"content","url":"/sec-03-01-hypothesis-testing#hypothesis-testing","position":7},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl3":"What does it means by ‘due to chance’?","lvl2":"Hypothesis Testing"},"type":"lvl3","url":"/sec-03-01-hypothesis-testing#what-does-it-means-by-due-to-chance","position":8},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl3":"What does it means by ‘due to chance’?","lvl2":"Hypothesis Testing"},"content":"In another chapter, we talked about Normal Distribution, and why ‘Normal’ is ‘Normal’.\n\nWhen we get a set of samples, the samples’ distribution tend to form a bell-shape, i.e., high at the middle (the central tendency), and dropped from middle to both sides (the spread).\nBut why?\n\n\n\nThe Normal Distribution.\n\nThe variance, or spread, of a dataset can result from various factors, including random processes, natural variation, or systematic differences. Despite this variability, data points often cluster around a central value due to underlying patterns or tendencies within the population.\n\nIn other words, values that fall at positive or negative distances from the mean may be influenced by random factors or chance. This also applies when we draw a value and obtain an extreme value far from the center---such values can occur due to randomness or chance.\n\nEverything can happen by chance---so when we see one value that is away from the sample mean, it does not promise to be ‘different’ from the distribution.\n\n\n\nFigure 5:A data point compared to the distribution.\n\nLet’s say we have a class of students, and their height values are measured and which shows a normal distribution (\n\nFigure 5), i.e., mean=170, std=10.\n\nAt this point, you can view these students as a set of sample, sampling from the population (the university).\nThe university’s students height should (or can be assumed to) form a normal distribution.\n\nNow, you get a student from the next door, and his height is 135. Deos it means this person is different from the currect class?\n\nStrategy for measuring difference of an individual data point from a distribution\n\nCalculate how far this data point is from the average of the distribution.\n\nHow many standard deviation it is from the distribution’s mean? (the z-score that use mean and std)\n\nHow many deviance (MAD) it is from the distribution’s median? (use median and MAD)","type":"content","url":"/sec-03-01-hypothesis-testing#what-does-it-means-by-due-to-chance","position":9},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"Comparison of two distributions"},"type":"lvl2","url":"/sec-03-01-hypothesis-testing#comparison-of-two-distributions","position":10},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"Comparison of two distributions"},"content":"\n\nThe distributions of two groups of students.\n\nNext, get a series of students’ height from next door, perhaps the same number of students as the first class and which generate a distribution (another normal distribution).\n\nThen, how to compare them?\n\nCentral values and spread\nCentral values can be represented by measures of central tendency, such as the mean, median, or mode. In many situations, particularly when data follow a normal distribution, the combination of central tendency and spread can provide a helpful summary of the overall distribution and its characteristics.\n\nShape and other measurements\nAssume to be normal distribution\n\nStrategy for comparison\n\nCompare the mean between the two distributions\n\nCompare the spread of the two distributions","type":"content","url":"/sec-03-01-hypothesis-testing#comparison-of-two-distributions","position":11},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl3":"Key Concepts","lvl2":"Comparison of two distributions"},"type":"lvl3","url":"/sec-03-01-hypothesis-testing#key-concepts","position":12},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl3":"Key Concepts","lvl2":"Comparison of two distributions"},"content":"Hypothesis testing is a crucial tool in statistical inference and helps researchers make data-driven decisions about the relationships or differences between variables.\n\nNull Hypothesis (\\text{H}_0):\n\nA statement that assumes no significant difference between the variables.\n\nThe goal of hypothesis testing is to gather evidence to reject the null hypothesis.\n\nEssentially, the null hypothesis reflects the idea of “no effect” or “no difference.”\n\nAlternative Hypothesis (\\text{H}_1 or \\text{H}_a):\n\nA statement that assumes a significant difference between the variables.\n\nThis is the hypothesis we aim to support when rejecting the null hypothesis.\n\nThe alternative hypothesis is basically about “has effect” or “has difference.”\n\nTest Statistic:\n\nA value calculated from the sample data to assess the likelihood of obtaining the observed results under the assumption that the null hypothesis is true.\n\nDepending on the assumptions that fit the situation, the tests for assessing the differences are T-test, ANOVA, and their non-parametric alternatives.\n\nSignificance Level (\\alpha):\n\nThe threshold probability for rejecting the null hypothesis, often set at 0.05 or 0.01.\n\nIt represents the probability threshold of incorrectly rejecting the null hypothesis when it is true (Type I error). (The risk that we are willing to take.)\n\np-value:\n\nThe probability of obtaining the observed results (or more extreme results) under the assumption that the null hypothesis is true.\n\nA small p-value indicates that the observed results are unlikely to occur by chance alone, providing evidence to reject the null hypothesis.\n\nThe risk of being wrong to reject \\text{H}_0\n\nStatistical Significance:\n\nWhen the p-value is less than the chosen significance level (\\alpha), we reject the null hypothesis and conclude that the results are statistically significant, supporting the alternative hypothesis (\\text{H}_1).\n\nOtherwise, we fail to reject it.","type":"content","url":"/sec-03-01-hypothesis-testing#key-concepts","position":13},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl3":"About Type 1 and Type 2 errors","lvl2":"Comparison of two distributions"},"type":"lvl3","url":"/sec-03-01-hypothesis-testing#about-type-1-and-type-2-errors","position":14},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl3":"About Type 1 and Type 2 errors","lvl2":"Comparison of two distributions"},"content":"\n\nType 1 and type 2 errors. \n\nTable from Wikipedia","type":"content","url":"/sec-03-01-hypothesis-testing#about-type-1-and-type-2-errors","position":15},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"Hypothesis for Testing the Differences"},"type":"lvl2","url":"/sec-03-01-hypothesis-testing#hypothesis-for-testing-the-differences","position":16},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"Hypothesis for Testing the Differences"},"content":"The null hypothesis reflects the idea of “no effect” or “no difference.”\n\nHypothesis for testing differences between two means:\\begin{align}\n\\text{H}_0 &: \\mu_0 = \\mu_1 \\\\\\\\\n\\text{H}_1 &: \\mu_0 \\neq \\mu_1\n\\end{align}\n\nHypothesis for testing differences between more than two means:\\begin{align}\n\\text{H}_0 &: \\mu_0 = \\mu_1 = \\mu_2 = ... = \\mu_i  \\\\\\\\\n\\text{H}_1 &: \\text{at least 2 of the }\\mu_i\\text{ are different}\n\\end{align}\n\nNull hypothesis is something that we DO NOT NEED to prove, because it cannot be proven anyway.\n\nThe null hypothesis is assumed to be true until the data provide sufficient evidence against it.\n\nWe can only gather evidence to reject the null hypothesis, not to confirm or prove it.\n\nFailing to reject the null hypothesis doesn’t necessarily mean it’s true; it simply indicates that there’s insufficient evidence to support the alternative hypothesis.","type":"content","url":"/sec-03-01-hypothesis-testing#hypothesis-for-testing-the-differences","position":17},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"For Spatial Patterns Detection"},"type":"lvl2","url":"/sec-03-01-hypothesis-testing#for-spatial-patterns-detection","position":18},{"hierarchy":{"lvl1":"The Hypothesis Testing","lvl2":"For Spatial Patterns Detection"},"content":"Is the spatial pattern different from a random pattern?\n\nnull hypothesis: no difference\n\nIs there any significant clusters?\n\nnull hypothesis: no clustering effect","type":"content","url":"/sec-03-01-hypothesis-testing#for-spatial-patterns-detection","position":19},{"hierarchy":{"lvl1":"The T-test"},"type":"lvl1","url":"/sec-03-02-t-test","position":0},{"hierarchy":{"lvl1":"The T-test"},"content":"","type":"content","url":"/sec-03-02-t-test","position":1},{"hierarchy":{"lvl1":"The T-test","lvl2":"Assumptions of t-tests"},"type":"lvl2","url":"/sec-03-02-t-test#assumptions-of-t-tests","position":2},{"hierarchy":{"lvl1":"The T-test","lvl2":"Assumptions of t-tests"},"content":"To ensure the validity of the results, the t-test relies on certain assumptions:\n\n.bold[Continuous]:\nThe data (target variable) should be continuous (interval/ratio).\n\n.bold[Normality]:\nThe data should be approximately normally distributed.\n\n.bold[Independence]:\nObservations .red[within and between groups] should be independent (not influence one another).\n\n.bold[Homogeneity of variances]:\nThe variances (or standard deviations) of the groups should be approximately equal (this assumption can be relaxed for some t-tests).\n\n\n\nThe distributions of two groups of students.","type":"content","url":"/sec-03-02-t-test#assumptions-of-t-tests","position":3},{"hierarchy":{"lvl1":"The T-test","lvl2":"Two Types of ‘Groups’: Between vs. Within"},"type":"lvl2","url":"/sec-03-02-t-test#two-types-of-groups-between-vs-within","position":4},{"hierarchy":{"lvl1":"The T-test","lvl2":"Two Types of ‘Groups’: Between vs. Within"},"content":"‘Between’-Group Analysis\n\nNumber of subject groups: 2 or more\n\nNumber of target variables: 1 (for every subject)\n\nPurpose: To compare differences among distinct groups of subjects.\n\n‘Within’-Group Analysis\n\nNumber subject groups: 1\n\nNumber of target variables: 2 or more (for every subject)\n\nPurpose: To examine the differences or changes within a single group over time or under different conditions.","type":"content","url":"/sec-03-02-t-test#two-types-of-groups-between-vs-within","position":5},{"hierarchy":{"lvl1":"The T-test","lvl2":"Types of t-tests"},"type":"lvl2","url":"/sec-03-02-t-test#types-of-t-tests","position":6},{"hierarchy":{"lvl1":"The T-test","lvl2":"Types of t-tests"},"content":"There are three main types of t-tests:\n\nOne sample t-test\n\nIndependent samples t-test\n\nPaired samples t-test\n\n\n\nSource: \n\nDatatab","type":"content","url":"/sec-03-02-t-test#types-of-t-tests","position":7},{"hierarchy":{"lvl1":"The T-test","lvl3":"One sample t-test","lvl2":"Types of t-tests"},"type":"lvl3","url":"/sec-03-02-t-test#one-sample-t-test","position":8},{"hierarchy":{"lvl1":"The T-test","lvl3":"One sample t-test","lvl2":"Types of t-tests"},"content":"Compares the mean of a single group to a known population mean.\n\nE.g., the students’ performances from one school compared to the national mean; the air polution level compared to the safety standards...\n\nEach individual or observation in the sample contributes to a single group being compared to the known population mean.\n\n\n\nSource: \n\nDatatab","type":"content","url":"/sec-03-02-t-test#one-sample-t-test","position":9},{"hierarchy":{"lvl1":"The T-test","lvl4":"An example","lvl3":"One sample t-test","lvl2":"Types of t-tests"},"type":"lvl4","url":"/sec-03-02-t-test#an-example","position":10},{"hierarchy":{"lvl1":"The T-test","lvl4":"An example","lvl3":"One sample t-test","lvl2":"Types of t-tests"},"content":"A factory claims that their light bulbs have an average lifespan of 1,000 hours. A consumer group selects a random sample of 25 bulbs and finds that the sample has an average lifespan of 985 hours with a standard deviation of 50 hours. The consumer group wants to determine whether the factory’s claim is accurate.[ 935,  969,  917,  922,  906, 1022,  984, 1023, 1042,  944,\n  982, 1054,  923, 1012,  963, 1011,  924, 1026, 1081,  932,\n 1027,  947,  994, 1016, 1069 ]\n\n\n\nThe one sample t-test example.\n\n.bold[Finding]:\nThe consumer group cannot conclude that the factory’s claim is inaccurate based on this sample. There is not enough evidence to reject the null hypothesis that the average lifespan of the light bulbs is 1,000 hours.\n\nSteps involved in the one-sample t-test:\n\nFormulate the null hypothesis (\\text{H}_0) and the alternative hypothesis (\\text{H}_1):\n\n\\text{H}_0: The average lifespan of the light bulbs is 1,000 hours (\\mu = 1,000.\n\n\\text{H}_1: The average lifespan of the light bulbs is not 1,000 hours (\\mu \\neq 1,000).\n\nCalculate the t-test statistic (t) using the formula:\n\nt = (sample mean - population mean) / (standard error of the mean)\n\nstandard error of the mean = \\text{std} / \\sqrt{n} = 50 / \\sqrt{25} = 50/5 = 10\n\nPlugging in the values: t \\approx (985 - 1,000) / 10 = -1.5\n\nDetermine the degrees of freedom (df), which is equal to\n\nthe sample size minus 1 (df = n - 1);\n\n\\text{df} = 25 - 1 = 24.\n\nUsing the t-value (-1.5) and degrees of freedom (24), find the p-value associated with the test statistic from the t-distribution table or by using statistical software:\n\nThe p-value is approximately 0.16.\n\nSince the p-value (0.16) is greater than the conventional significance level of 0.05, we fail to reject the null hypothesis.","type":"content","url":"/sec-03-02-t-test#an-example","position":11},{"hierarchy":{"lvl1":"The T-test","lvl3":"Independent samples t-test","lvl2":"Types of t-tests"},"type":"lvl3","url":"/sec-03-02-t-test#independent-samples-t-test","position":12},{"hierarchy":{"lvl1":"The T-test","lvl3":"Independent samples t-test","lvl2":"Types of t-tests"},"content":"Compares the means of two independent groups.\n\nE.g., the scores of students from two classes; the effect of treatment vs. placebo-control groups...\n\nEvery individual will only appear in only one of the two groups.\n\n\n\nSource: \n\nDatatab\n\nIn each subplot, the mean of two Iris species were compared.\n\n\n\nThe differences in petal length between the three species, with t-test results.","type":"content","url":"/sec-03-02-t-test#independent-samples-t-test","position":13},{"hierarchy":{"lvl1":"The T-test","lvl3":"Paired samples t-test","lvl2":"Types of t-tests"},"type":"lvl3","url":"/sec-03-02-t-test#paired-samples-t-test","position":14},{"hierarchy":{"lvl1":"The T-test","lvl3":"Paired samples t-test","lvl2":"Types of t-tests"},"content":"Compares the means of two related or paired groups.\n\nE.g., pre-test and post-test scores from the same group of individuals; differences between spouses or siblings...\n\nEvery individual in the pre-test group must also be present in the post-test group, or each individual in one group should have a specific counterpart in the other group.\n\n\n\nSource: \n\nDatatab\n\n\n\nThe changes of psychological indexes before and after a VR treatment. T-test and significant levels are shown at top right. \n\nHsieh et al. (2023)","type":"content","url":"/sec-03-02-t-test#paired-samples-t-test","position":15},{"hierarchy":{"lvl1":"The T-test","lvl2":"T-Test Statistic and Interpretation"},"type":"lvl2","url":"/sec-03-02-t-test#t-test-statistic-and-interpretation","position":16},{"hierarchy":{"lvl1":"The T-test","lvl2":"T-Test Statistic and Interpretation"},"content":"t-value (aka T-statistic)\n\nThe t-test calculates a t-value by dividing the difference between the group means by the standard error of the difference. A higher t-value (positive or negative) suggests a larger inter-group difference relative to the intra-group variability.\n\np-value\n\nThe t-test also provides a p-value, which represents the probability of observing a t-value at least as extreme as the one calculated, assuming the null hypothesis is true. A lower p-value indicates stronger evidence against the null hypothesis, suggesting a significant difference between the groups.\n\nDegrees of Freedom\n\nDegrees of freedom (df) are used to determine the appropriate t-distribution for calculating p-values. For independent samples t-test, df = n_1 + n_2 - 2, where n_1 and n_2 are the sample sizes of the two groups.\n\nEffect Size\n\nTo assess the practical significance of the difference between group means, effect size measures like Cohen’s d, Eta-squared, and Hedge’s g can be calculated. Cohen’s d indicates the magnitude of the difference between the groups in standard deviation units.\n\nCohen’s d:\nCohen’s d is a standardized measure of effect size, often used in comparing the means of two groups. It expresses the difference between group means in terms of standard deviations, making it a useful metric for comparing effects across different studies. The guidelines proposed by Jacob Cohen for interpreting d are:\n\nSmall effect: d = 0.2\n\nMedium effect: d = 0.5\n\nLarge effect: d = 0.8\n\nEta-squared (η²):\nEta-squared is often reported in the context of ANOVA (Analysis of Variance) tests. It describes the proportion of variance in the dependent variable that can be explained by the independent variable. Eta-squared values range from 0 to 1, with higher values indicating larger effects. Here are some general guidelines for interpreting η²:\n\nSmall effect: η² = 0.01\n\nMedium effect: η² = 0.06\n\nLarge effect: η² = 0.14\n\nHedge’s g:\nHedge’s g, like Cohen’s d, is a standardized effect size measure for comparing two group means. However, it includes a correction for bias in small samples, making it more appropriate than Cohen’s d when sample sizes are small. The interpretation guidelines for Hedge’s g are similar to Cohen’s d:\n\nSmall effect: g = 0.2\n\nMedium effect: g = 0.5\n\nLarge effect: g = 0.8\n\nCommon Language Effect Size (CLES):\nThe Common Language Effect Size (CLES) is a non-parametric effect size measure that communicates the likelihood that a randomly selected observation from one group will be greater than a randomly selected observation from another group. CLES offers a more intuitive understanding of statistical results, making it easier for researchers and non-experts to interpret the practical significance of findings.","type":"content","url":"/sec-03-02-t-test#t-test-statistic-and-interpretation","position":17},{"hierarchy":{"lvl1":"The T-test","lvl2":"Summary"},"type":"lvl2","url":"/sec-03-02-t-test#summary","position":18},{"hierarchy":{"lvl1":"The T-test","lvl2":"Summary"},"content":"The t-test is widely used in various fields to compare group means and evaluate the effectiveness of treatments, interventions, or different conditions. It serves as an essential tool for hypothesis testing and data analysis.","type":"content","url":"/sec-03-02-t-test#summary","position":19},{"hierarchy":{"lvl1":"The Analysis of Variance"},"type":"lvl1","url":"/sec-03-03-anova","position":0},{"hierarchy":{"lvl1":"The Analysis of Variance"},"content":"","type":"content","url":"/sec-03-03-anova","position":1},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"What is Analysis of Variance"},"type":"lvl2","url":"/sec-03-03-anova#what-is-analysis-of-variance","position":2},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"What is Analysis of Variance"},"content":"Definition:\nAnalysis of Variance, aka ANOVA, is a statistical method used to compare the means of more than two groups to determine whether there is a significant difference between them.\n\nThe primary purpose of ANOVA is to test the hypothesis that the means of several populations are equal. It helps determine whether any observed differences between group means are real or occurred by chance.\n\nWhen to use ANOVA:\nANOVA is used when comparing more than two group means. It is particularly useful in experimental settings where a single factor (independent variable, one-way ANOVA) is manipulated at multiple levels (e.g., low, medium, high), and the researcher wants to investigate the effect of this manipulation on the outcome (dependent variable).","type":"content","url":"/sec-03-03-anova#what-is-analysis-of-variance","position":3},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"Assumptions of ANOVA"},"type":"lvl2","url":"/sec-03-03-anova#assumptions-of-anova","position":4},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"Assumptions of ANOVA"},"content":"ANOVA is based on the following assumptions:\n\nNumeric Response: The target (dependent) variable should be continuous, either ratio or interval.\n\nNormality: The data within each group should be approximately normally distributed.\n\nEqual Variances (homoscedasticity): The variances of the populations being compared should be roughly equal.\n\nIndependence: Observations should be independent of each other. This means that the data from one subject should not influence the data from another subject.\n\nCategorical treatment or factor variables: ANOVA evaluates mean differences between one or more categorical variables (such as treatment groups), which are referred to as factors or “ways.”\n\nNote: It is essential to verify that these assumptions are met before conducting ANOVA. If assumptions are not satisfied, the validity of the F-test may be compromised. In such cases, alternative methods such as repeated measure ANOVA, Welch’s ANOVA, non-parametric tests or more robust techniques may be considered.","type":"content","url":"/sec-03-03-anova#assumptions-of-anova","position":5},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"Steps of ANOVA"},"type":"lvl2","url":"/sec-03-03-anova#steps-of-anova","position":6},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"Steps of ANOVA"},"content":"\n\nThe analysis process for t-test, ANOVA, and post-hoc test.","type":"content","url":"/sec-03-03-anova#steps-of-anova","position":7},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"Types of ANOVA"},"type":"lvl2","url":"/sec-03-03-anova#types-of-anova","position":8},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"Types of ANOVA"},"content":"Here only some commonly used types are introduced. Other types, e.g,. two-ways, three-ways, nested, Welch’s ANOVA... are not covered here since those data is less common, and the concept is similar (anyway).\n\nOne-way ANOVA\n\nbetween groups\n\nthe simplest and straighforward situation\n\nRepeated Measures ANOVA\n\nwithin group\n\nwhen the groups are not independent\n\nMixed-Design ANOVA\n\nwhen both between and within occurs","type":"content","url":"/sec-03-03-anova#types-of-anova","position":9},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"One-way ANOVA","lvl2":"Types of ANOVA"},"type":"lvl3","url":"/sec-03-03-anova#one-way-anova","position":10},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"One-way ANOVA","lvl2":"Types of ANOVA"},"content":"Concept\nOne-way ANOVA is a statistical technique used to compare the target variable’s means of three or more independent groups with a single independent variable (or factor). It helps determine whether any observed differences between group means are real or occurred by chance.\n\nExample\nTo compare the average test scores of students who received different teaching methods.\n\nHypothesis Tested in One-way ANOVA\n\nH_0: The population means of the groups being compared are equal.\nSymbolically: μ_1 = μ_2 = μ_3 = ... = μ_k, where μ_i represents the mean of the ith group, and k is the total number of groups.\n\nH_1: At least one of the group means is different from the others.\n\n\n\nThe One-way ANOVA comparing the four target variables between the three species.\n\nTable 1:The ANOVA result for the four target variables. Each row display the result from a single ANOVA.  All were significant.\n\nvariety\n\nddof1\n\nddof2\n\nF\n\np-unc\n\nnp2\n\npetal.length\n\n2\n\n147\n\n1180.16\n\n0.000\n\n0.941\n\npetal.width\n\n2\n\n147\n\n960.007\n\n0.000\n\n0.929\n\nsepal.length\n\n2\n\n147\n\n119.265\n\n0.000\n\n0.619\n\nsepal.width\n\n2\n\n147\n\n49.16\n\n0.000\n\n0.401","type":"content","url":"/sec-03-03-anova#one-way-anova","position":11},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Repeated Measures ANOVA","lvl2":"Types of ANOVA"},"type":"lvl3","url":"/sec-03-03-anova#repeated-measures-anova","position":12},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Repeated Measures ANOVA","lvl2":"Types of ANOVA"},"content":"Concept\nRepeated measures ANOVA, also known as within-subjects ANOVA, is a statistical technique used to compare means of three or more dependent groups when the same subjects are observed under various conditions or at different points in time.\n\nExample\nTo compare the reaction times of a group of participants before, during, and after receiving a treatment.\n\nHypothesis Tested in Repeated Measures ANOVA\n\nH_0: The population means of the different conditions or time points are equal.\nSymbolically: μ_1 = μ_2 = μ_3 = ... = μ_k, where μi represents the mean of the ith condition or time point, and k is the total number of conditions or time points.\n\nH_1: At least one of the population means is different from the others.\nSymbolically: There exists at least one i and j such that μ_i ≠ μ_j.\n\n\n\nThe physiological responses before, during and after two types of VR treatments.\n\n\n\nThe tables about the repeated measures and post-hoc results: (left) low decibel, (right) high decibel.","type":"content","url":"/sec-03-03-anova#repeated-measures-anova","position":13},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Mixed-Design ANOVA","lvl2":"Types of ANOVA"},"type":"lvl3","url":"/sec-03-03-anova#mixed-design-anova","position":14},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Mixed-Design ANOVA","lvl2":"Types of ANOVA"},"content":"Concept\nMixed-design ANOVA, also known as split-plot ANOVA, is a statistical method used for analyzing data from studies with both between-subjects factors and within-subjects factors. It combines features of one-way ANOVA and repeated measures ANOVA, allowing researchers to examine the effects of multiple independent variables on a dependent variable.\n\nKey Points\n\nBetween-subjects factors involve comparisons between different groups of participants, similar to one-way ANOVA.\n\nWithin-subjects factors involve comparisons within the same group of participants at different time points or under various conditions, similar to repeated measures ANOVA.\n\nMixed-design ANOVA enables researchers to assess the main effects of each factor and the potential interaction effects between factors.\n\nAssumptions\nThe assumptions of mixed-design ANOVA are similar to those of one-way and repeated measures ANOVA, including normality, homogeneity of variances, and independence. Additionally, the assumption of sphericity must be met for the within-subjects factor.\n\nUse case\nBy using mixed-design ANOVA, researchers can gain a deeper understanding of the complex relationships between multiple factors and their effects on the dependent variable. It’s a powerful tool for analyzing data from various experimental designs, particularly in fields such as psychology, medicine, and education.\n\n\n\nThe mixed ANOVA result between classes, time (pre-test vs. post-test), and the interaction between class and time.\n\n\n\nThe post-hoc test after mixed ANOVA, to observe the time effects in different condition.","type":"content","url":"/sec-03-03-anova#mixed-design-anova","position":15},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"F-test, F-distribution, and F-statistic"},"type":"lvl2","url":"/sec-03-03-anova#f-test-f-distribution-and-f-statistic","position":16},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"F-test, F-distribution, and F-statistic"},"content":"The F-test is a statistical test used in ANOVA to compare variances and determine whether there is a significant difference between group means. The F-statistic (or F-ratio) is calculated as the ratio of the between-group variance to the within-group variance:F = (\\text{Between-group variance}) / (\\text{Within-group variance})\n\nThe F-statistic reflects the extent to which the variation between groups exceeds the variation within groups.\nA higher F-value indicates a greater difference between group means relative to the variability within each group.\n\nUnder the null hypothesis that all group means are equal, the F-statistic follows an F-distribution, which is a family of continuous probability distributions characterized by two parameters: degrees of freedom for the numerator (\\text{ddof}_1) and degrees of freedom for the denominator (\\text{ddof}_2).\n\nThe F-distribution is used to determine the critical F-value for a given significance level (\\alpha) and degrees of freedom (\\text{ddof}_1 and \\text{ddof}_2). This critical value is compared with the calculated F-statistic to make a decision about the null hypothesis.","type":"content","url":"/sec-03-03-anova#f-test-f-distribution-and-f-statistic","position":17},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Making decisions in ANOVA using the F-value","lvl2":"F-test, F-distribution, and F-statistic"},"type":"lvl3","url":"/sec-03-03-anova#making-decisions-in-anova-using-the-f-value","position":18},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Making decisions in ANOVA using the F-value","lvl2":"F-test, F-distribution, and F-statistic"},"content":"To make decisions in ANOVA, the calculated F-statistic is compared to the critical F-value obtained from the F-distribution.\n\nIf the F-statistic is larger than the critical F-value, we reject the null hypothesis, concluding that at least one group mean is significantly different from the others.\n\nIf the F-statistic is smaller than the critical F-value, we fail to reject the null hypothesis, concluding that there is insufficient evidence to claim a significant difference between group means.\n\nIn practice, a p-value is often computed and compared to a predetermined significance level (\\alpha) to make this decision. If the p-value is smaller than \\alpha, the null hypothesis is rejected.","type":"content","url":"/sec-03-03-anova#making-decisions-in-anova-using-the-f-value","position":19},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"Post-hoc Tests"},"type":"lvl2","url":"/sec-03-03-anova#post-hoc-tests","position":20},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl2":"Post-hoc Tests"},"content":"","type":"content","url":"/sec-03-03-anova#post-hoc-tests","position":21},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Purpose of Post-hoc Tests","lvl2":"Post-hoc Tests"},"type":"lvl3","url":"/sec-03-03-anova#purpose-of-post-hoc-tests","position":22},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Purpose of Post-hoc Tests","lvl2":"Post-hoc Tests"},"content":"Post-hoc tests are follow-up analyses conducted after a significant overall F-test in ANOVA. Their purpose is to determine which specific group means are significantly different from one another. Since ANOVA only tells us that at least two means are different, post-hoc tests help pinpoint where those differences lie.","type":"content","url":"/sec-03-03-anova#purpose-of-post-hoc-tests","position":23},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Common post-hoc tests","lvl2":"Post-hoc Tests"},"type":"lvl3","url":"/sec-03-03-anova#common-post-hoc-tests","position":24},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Common post-hoc tests","lvl2":"Post-hoc Tests"},"content":"Tukey’s HSD Test:\n\nSimultaneously compares all possible pairs of means.\n\nControls the family-wise error rate, ensuring the overall probability of making at least one Type I error across all comparisons remains at the desired significance level.\n\nGenerally more appropriate when making multiple comparisons in an ANOVA context, as it has greater power to detect significant differences while controlling for multiple comparisons.\n\nPairwise t-tests:\n\nCompares two means at a time.\n\nPerforming multiple pairwise t-tests inflates the Type I error rate, as each test uses a fixed significance level (e.g., 0.05) without considering the number of comparisons made.\n\nWhile adjustments such as the Bonferroni correction can control for multiple comparisons, using individual t-tests becomes less powerful and more complex as the number of comparisons increases.","type":"content","url":"/sec-03-03-anova#common-post-hoc-tests","position":25},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Roadmap for choosing ANOVA and post-hoc tests","lvl2":"Post-hoc Tests"},"type":"lvl3","url":"/sec-03-03-anova#roadmap-for-choosing-anova-and-post-hoc-tests","position":26},{"hierarchy":{"lvl1":"The Analysis of Variance","lvl3":"Roadmap for choosing ANOVA and post-hoc tests","lvl2":"Post-hoc Tests"},"content":"\n\nThe roadmap for choosing ANOVA and post-hoc tests approaches. by \n\nPingouin","type":"content","url":"/sec-03-03-anova#roadmap-for-choosing-anova-and-post-hoc-tests","position":27},{"hierarchy":{"lvl1":"The Non-parametric Tests"},"type":"lvl1","url":"/sec-03-04-non-parametric","position":0},{"hierarchy":{"lvl1":"The Non-parametric Tests"},"content":"","type":"content","url":"/sec-03-04-non-parametric","position":1},{"hierarchy":{"lvl1":"The Non-parametric Tests","lvl2":"Limitations of t-tests and ANOVA"},"type":"lvl2","url":"/sec-03-04-non-parametric#limitations-of-t-tests-and-anova","position":2},{"hierarchy":{"lvl1":"The Non-parametric Tests","lvl2":"Limitations of t-tests and ANOVA"},"content":"Both t-test and ANOVA have assumptions of:\n\nnumerical responses (ratio or interval target variable)\n\nnormality (target variable)\n\nindependence (within and between groups)\n\nequal variances\n\nWhen these assumptions are violated, the validity of t-tests and ANOVA may be compromised, leading to inaccurate results.\n\nIn this case, the relevant non-parametric tests could be used.","type":"content","url":"/sec-03-04-non-parametric#limitations-of-t-tests-and-anova","position":3},{"hierarchy":{"lvl1":"The Non-parametric Tests","lvl2":"Roadmap for choosing non-parametric tests"},"type":"lvl2","url":"/sec-03-04-non-parametric#roadmap-for-choosing-non-parametric-tests","position":4},{"hierarchy":{"lvl1":"The Non-parametric Tests","lvl2":"Roadmap for choosing non-parametric tests"},"content":"\n\nThe roadmap for choosing non-parametric tests approaches. by \n\nPingouin","type":"content","url":"/sec-03-04-non-parametric#roadmap-for-choosing-non-parametric-tests","position":5},{"hierarchy":{"lvl1":"The Non-parametric Tests","lvl2":"The non-parametric alternatives"},"type":"lvl2","url":"/sec-03-04-non-parametric#the-non-parametric-alternatives","position":6},{"hierarchy":{"lvl1":"The Non-parametric Tests","lvl2":"The non-parametric alternatives"},"content":"T-test\n\nIndependent samples t-test\n\nMann-Whitney U Test\n\nPaired samples t-test\n\nWilcoxon Sign-Rank Test\n\nANOVA\n\nOne-way ANOVA\n\nKruskal-Wallis Test\n\nRepeated Measures ANOVA\n\nFriedman Test (non-binary data)\n\nCochran Test (binary data)","type":"content","url":"/sec-03-04-non-parametric#the-non-parametric-alternatives","position":7},{"hierarchy":{"lvl1":"The Non-parametric Tests","lvl2":"An example (socio-economic status in Brunei)"},"type":"lvl2","url":"/sec-03-04-non-parametric#an-example-socio-economic-status-in-brunei","position":8},{"hierarchy":{"lvl1":"The Non-parametric Tests","lvl2":"An example (socio-economic status in Brunei)"},"content":"The income levels are ordinal (ranks) data, which is not numerical, and not normally distributed. Two groups are observed in both example, i.e., gender (male: 1, female: 0) and rural (rural: 1, urban: 0).\n\n\n\n(a)by age\n\n\n\n(b)by rural\n\nFigure 2:Comparing the income level vs. gender (a) and rural/urban (b). Data source: \n\nA global dataset of 7 billion individuals with socio-economic characteristics\n\nThe income levels are ordinal (ranks) data, which is not numerical, and not normally distributed. Multiple groups are observed in both example, i.e., age group (from low to large) and rural (from low education level to high education level), thus, ANOVA’s alternatives could be used.\n\n\n\n(a)by age\n\n\n\n(b)by Education\n\nFigure 3:Comparing the income level vs. age groups (a) and education levels (b). Data source: \n\nA global dataset of 7 billion individuals with socio-economic characteristics","type":"content","url":"/sec-03-04-non-parametric#an-example-socio-economic-status-in-brunei","position":9},{"hierarchy":{"lvl1":"Summary"},"type":"lvl1","url":"/sec-03-05-summary","position":0},{"hierarchy":{"lvl1":"Summary"},"content":"Hypothesis testing is a key to quantify the differences in data.\n\nNull hypothesis are usually ‘no effects’ or ‘no differences’.\n\nT-test, ANOVA, and non-parametric tests could be used in various conditions.\n\nT-test and ANOVA were designed with some assumptions and base distribution (t-distribution and F-distribution), which are prefered if the assumptions are met.\n\nIf the assumptions are violated, the statistical estimation is compromised and the accuracy is unknown.\n\nNon-parametric tests can be used in that situation.","type":"content","url":"/sec-03-05-summary","position":1},{"hierarchy":{"lvl1":"Summary","lvl2":"How to think statistically?"},"type":"lvl2","url":"/sec-03-05-summary#how-to-think-statistically","position":2},{"hierarchy":{"lvl1":"Summary","lvl2":"How to think statistically?"},"content":"Some key points:\n\nHow to measure data quantitatively (or qualitatively)\n\nnominal, ordinal, interval, ratio\n\nbinary, numerical, categorical\n\nAre them different? Are them same?\n\ndesigning the hypothesis\n\nhow to formulate a question\n\nAre them related?\n\ncorrelation, regression (not covered)\n\nHow to test/assess the hypothesis?\n\nparametric, non-parametric\n\nthe assumptions behind each method\n\nHow to read the results (interpretation)?\n\nsignificant at what level?\n\neffect size?\n\nhow confidence are we?\n\nRelating to the big picture\n\nwhat this means in your big-aim / Reseearch Questions (RQ)\n\nhow visualisation can help linking back to your study","type":"content","url":"/sec-03-05-summary#how-to-think-statistically","position":3},{"hierarchy":{"lvl1":"Summary","lvl2":"How to use these techniques and thinking in spatial data?"},"type":"lvl2","url":"/sec-03-05-summary#how-to-use-these-techniques-and-thinking-in-spatial-data","position":4},{"hierarchy":{"lvl1":"Summary","lvl2":"How to use these techniques and thinking in spatial data?"},"content":"Table 1:A slice of HDB data table.\n\nStreet\n\nFlat Type\n\nFloor Area (sqm)\n\nResale Age\n\nResale Price\n\nANG MO KIO AVE 10\n\n2 ROOM\n\n44\n\n44\n\n267000\n\nANG MO KIO AVE 3\n\n2 ROOM\n\n49\n\n46\n\n300000\n\nANG MO KIO AVE 3\n\n2 ROOM\n\n44\n\n45\n\n280000\n\nANG MO KIO AVE 3\n\n2 ROOM\n\n44\n\n45\n\n282000\n\nANG MO KIO AVE 4\n\n2 ROOM\n\n45\n\n37\n\n289800\n\n...\n\n...\n\n...\n\n...\n\n...\n\n\n\nThe differences between flat type?\n\n\n\nThe differences between regions?\n\n\n\nThe differences between the two years?","type":"content","url":"/sec-03-05-summary#how-to-use-these-techniques-and-thinking-in-spatial-data","position":5},{"hierarchy":{"lvl1":"Summary","lvl2":"Strategies to investigate spatial data differences"},"type":"lvl2","url":"/sec-03-05-summary#strategies-to-investigate-spatial-data-differences","position":6},{"hierarchy":{"lvl1":"Summary","lvl2":"Strategies to investigate spatial data differences"},"content":"individual level comparison\n\ndirectly analyzing the data table\n\ntransactions between flat types, between regions, between time, ...\n\neach data point is considered independent from other data point\n\nuse statistical methods\n\nspatially aggregated comparison\n\naggregate the data by spatial units (subzone, planning area)\n\nthe average price for 4 rooms for every subzone, ...\n\neach spatial unit is considered independent from other spatial unit\n\nuse statistical methods\n\nconsider spatial relationship (nearby) effects\n\nspatial relationship between data points or spatial units\n\nthe prices of the same type of house unit within the neighborhood (a search distance)...\n\ndata points or spatial units are consider spatially dependent\n\nuse spatial statistic methods","type":"content","url":"/sec-03-05-summary#strategies-to-investigate-spatial-data-differences","position":7},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern"},"type":"lvl1","url":"/chapter-4-global-point-pattern","position":0},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern"},"content":"Objectives of this lecture\n\nUnderstand what is ‘.bold[Complete Spatial Randomness]’ and ‘.bold[Spatial Patterns]’\n\nTo learn how to identify Clustering Pattern\n\nGrid-based, counting: Quadrat Count Analysis\n\nDistance-based, sorting: Nearest Neighbor Analysis\n\nDistance-based, searching: Ripley’s K-function(s)\n\nMonte-Carlo Simulation","type":"content","url":"/chapter-4-global-point-pattern","position":1},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Two Types Clustering in Spatial Analysis"},"type":"lvl2","url":"/chapter-4-global-point-pattern#two-types-clustering-in-spatial-analysis","position":2},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Two Types Clustering in Spatial Analysis"},"content":"some parts of the study area that have very high concentration of point events, i.e., .red[‘clusters’]\n\nto check if this phenomenon exists in the spatial point data\n\nto identify the location of these clusters\n\nsignificant tests, CSR\n\ngroups of spatial points that are close to each other, i.e., .red[‘clusters’]\n\nidentify grouping of points with/without overlap","type":"content","url":"/chapter-4-global-point-pattern#two-types-clustering-in-spatial-analysis","position":3},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Three Major types of Point Pattern"},"type":"lvl2","url":"/chapter-4-global-point-pattern#three-major-types-of-point-pattern","position":4},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Three Major types of Point Pattern"},"content":"\n\n.red.xkcd[How to differentiate clustered from random .bold[(CSR)]?]\n\n.xkcd[CSR: Complete Spatial Randomness]\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/chapter-4-global-point-pattern#three-major-types-of-point-pattern","position":5},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Measurement strategies"},"type":"lvl2","url":"/chapter-4-global-point-pattern#measurement-strategies","position":6},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Measurement strategies"},"content":"].column[\n\nGrid-based\n\nDistance-based\n]]\n\nclass: center, middle","type":"content","url":"/chapter-4-global-point-pattern#measurement-strategies","position":7},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Measurement strategies"},"type":"lvl2","url":"/chapter-4-global-point-pattern#measurement-strategies-1","position":8},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Measurement strategies"},"content":"","type":"content","url":"/chapter-4-global-point-pattern#measurement-strategies-1","position":9},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl3":"Grid-based","lvl2":"Measurement strategies"},"type":"lvl3","url":"/chapter-4-global-point-pattern#grid-based","position":10},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl3":"Grid-based","lvl2":"Measurement strategies"},"content":"\n\nclass: center, middle","type":"content","url":"/chapter-4-global-point-pattern#grid-based","position":11},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Measurement strategies"},"type":"lvl2","url":"/chapter-4-global-point-pattern#measurement-strategies-2","position":12},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl2":"Measurement strategies"},"content":"","type":"content","url":"/chapter-4-global-point-pattern#measurement-strategies-2","position":13},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl3":"Distance-based","lvl2":"Measurement strategies"},"type":"lvl3","url":"/chapter-4-global-point-pattern#distance-based","position":14},{"hierarchy":{"lvl1":"Chapter 4: Point Pattern","lvl3":"Distance-based","lvl2":"Measurement strategies"},"content":"","type":"content","url":"/chapter-4-global-point-pattern#distance-based","position":15},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness"},"type":"lvl1","url":"/sec-04-01-complete-spatial-randomness","position":0},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness"},"content":"","type":"content","url":"/sec-04-01-complete-spatial-randomness","position":1},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"What is Spatial Point Pattern?"},"type":"lvl2","url":"/sec-04-01-complete-spatial-randomness#what-is-spatial-point-pattern","position":2},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"What is Spatial Point Pattern?"},"content":"A bunch of points that form some patterns within a specific region.\n\n\n\nJohn Snow’s Cholera Death Incident Map\n\nHow points are distributed?\n\nSome points .red[concentrated] at the middle.\n\nSome .red[outliers] are far from the cluster(s).\n\nSome empty spaces.\n\n\n\nVisually speaking, what is the patterns here in the map?","type":"content","url":"/sec-04-01-complete-spatial-randomness#what-is-spatial-point-pattern","position":3},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Key Aspects of Spatial Point Pattern"},"type":"lvl2","url":"/sec-04-01-complete-spatial-randomness#key-aspects-of-spatial-point-pattern","position":4},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Key Aspects of Spatial Point Pattern"},"content":"Spatial Point Pattern Analysis encompasses various methods and techniques that aim to:\n\nExplore the point locations: This involves exploring the absolute locations/spaces of each point---where they are located.\n\nDescribe the points distribution**: This includes analyzing whether the points are distributed randomly, in clusters, or in a regular pattern, and determining the intensity or density of points within the study area.\n\nExplore the relationship between points: This involves examining the interactions between points, such as the distance or orientation of points in relation to one another, and identifying any spatial correlation or dependence between points.\n\nIdentify the spatial compositions and structures: This focuses on determining the underlying spatial processes or factors that generate the observed point pattern and understanding the composition of different sub-patterns or structures within the overall pattern.","type":"content","url":"/sec-04-01-complete-spatial-randomness#key-aspects-of-spatial-point-pattern","position":5},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Three Major types of Point Pattern"},"type":"lvl2","url":"/sec-04-01-complete-spatial-randomness#three-major-types-of-point-pattern","position":6},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Three Major types of Point Pattern"},"content":"\n\nHow to differentiate clustered from random?","type":"content","url":"/sec-04-01-complete-spatial-randomness#three-major-types-of-point-pattern","position":7},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Complete Spatial Randomness (CSR)"},"type":"lvl2","url":"/sec-04-01-complete-spatial-randomness#complete-spatial-randomness-csr","position":8},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Complete Spatial Randomness (CSR)"},"content":"The definition of “random” distribution\n\nThe null hypothesis for identifying significant clustered pattern\n\nNot a regular distribution\n\nCan be spatially inhomogeneous, i.e., both clusters and dispersed areas exist\n\ni.e., any observed clustering or disperse patterns could be attributed to chance alone\n\nSpatial Stationarity\n\n\n\nAbout Complete Spatial Randomness","type":"content","url":"/sec-04-01-complete-spatial-randomness#complete-spatial-randomness-csr","position":9},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Spatial Stationarity"},"type":"lvl2","url":"/sec-04-01-complete-spatial-randomness#spatial-stationarity","position":10},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Spatial Stationarity"},"content":"Stationarity is a key concept in spatial statistics and geostatistics, referring to the property of a spatial process where the statistical properties remain constant across space (or time).\n\nStationarity is an important assumption in many spatial statistical methods, including Kriging, variogram analysis, and point process models. If a spatial process is not stationary, it may be necessary to apply transformations, detrending techniques, or local models to account for the spatial variability in the data before applying these methods.\n\nStationarity is a fundamental concept in spatial statistics that allows for the analysis and modeling of spatial processes under the assumption of consistent statistical properties across space (or time). Understanding the stationarity of a spatial process is crucial for selecting appropriate analysis techniques and drawing valid conclusions from the data.\n\nImagine we’re analyzing the occurrence of accidents along a particular street. If an accident happens at a specific location on the street, and there are no accidents on the remaining parts of the street, it doesn’t mean that those sections have zero probability of accidents. In the context of stationarity, we assume that the probability of accidents happening is constant across the entire street. Therefore, even if an accident occurred at one location, the probability of accidents happening on any other part of the street remains the same.\n\n\n\nStationarity on a street\n\nStationarity implies that the underlying process generating the accidents is consistent across the street, and the observed distribution of accidents can be explained by random chance rather than any specific spatial factors or variations along the street.","type":"content","url":"/sec-04-01-complete-spatial-randomness#spatial-stationarity","position":11},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl3":"Two main types of stationarity","lvl2":"Spatial Stationarity"},"type":"lvl3","url":"/sec-04-01-complete-spatial-randomness#two-main-types-of-stationarity","position":12},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl3":"Two main types of stationarity","lvl2":"Spatial Stationarity"},"content":"Strict stationarity\n\nSecond-order stationarity\n\nStrict stationarity (or strong stationarity)\n\nA spatial process is considered strictly stationary when its statistical properties, such as the mean, variance, and autocorrelation structure, do not change with location (or time). In other words, the spatial process behaves the same regardless of where (or when) it is observed. For instance, if a spatial process is strictly stationary, the probability of finding a specific value at a given location would be the same across the entire study area.\n\nSecond-order stationarity (or weak stationarity)\n\nA spatial process is considered second-order stationary when only its first and second-order moments (mean, variance, and autocorrelation) are constant across space (or time), while higher-order moments may vary. This weaker form of stationarity is often sufficient for many spatial statistical analyses.","type":"content","url":"/sec-04-01-complete-spatial-randomness#two-main-types-of-stationarity","position":13},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Testing Strategy -- CSR"},"type":"lvl2","url":"/sec-04-01-complete-spatial-randomness#testing-strategy-csr","position":14},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"Testing Strategy -- CSR"},"content":"\n\nRandom Spatial Points\n\nCSR represents a theoretical spatial distribution, and since its population parameters can be estimated accordingly, it serves as a useful basis for statistical testing and comparison with observed spatial patterns.\n\nCSR as a Baseline: Complete Spatial Randomness (CSR) represents a scenario where points are distributed randomly and independently in space. It serves as a baseline or null hypothesis for analyzing spatial point patterns.\n\nIdentifying Deviations from CSR: By comparing an observed spatial pattern to CSR, we can identify deviations that indicate potential clustering or dispersion. Significant deviations suggest that the pattern is not random and may result from underlying spatial processes or interactions.\n\nQuantifying Clustering: Comparing to CSR allows us to quantify the degree of clustering or dispersion in the observed pattern. Statistical tests and measures, such as the quadrat count, nearest neighbor analysis and Ripley’s K-function, can be used to assess the significance of clustering.","type":"content","url":"/sec-04-01-complete-spatial-randomness#testing-strategy-csr","position":15},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"How different it is compared to CSR?"},"type":"lvl2","url":"/sec-04-01-complete-spatial-randomness#how-different-it-is-compared-to-csr","position":16},{"hierarchy":{"lvl1":"Spatial Patterns and Complete Spatial Randomness","lvl2":"How different it is compared to CSR?"},"content":"\n\nHow different it is compared to CSR?\n\nIn spatial statistics, CSR is the common null hypothesis.\n\nBefore we have enough proof to claim that a pattern is clustered, we have to assume everything can happen by chance, i.e., random.\n\nIf the evidence suggests that the pattern is unlikely to have occurred by chance, only then we can reject the null hypothesis and conclude that the pattern is clustered (or dispersed).","type":"content","url":"/sec-04-01-complete-spatial-randomness#how-different-it-is-compared-to-csr","position":17},{"hierarchy":{"lvl1":"Quadrat Count Analysis"},"type":"lvl1","url":"/sec-04-02-quadrat-count-analysis","position":0},{"hierarchy":{"lvl1":"Quadrat Count Analysis"},"content":"","type":"content","url":"/sec-04-02-quadrat-count-analysis","position":1},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"What is Quadrat Count Analysis?"},"type":"lvl2","url":"/sec-04-02-quadrat-count-analysis#what-is-quadrat-count-analysis","position":2},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"What is Quadrat Count Analysis?"},"content":"Quadrat Count Analysis is a method used in spatial point pattern analysis to determine whether a pattern of points is randomly distributed, clustered, or evenly spaced. It involves dividing the study area into smaller, equal-sized areas called “quadrats” (typically square or rectangular in shape) and counting the number of points fall in each quadrat.","type":"content","url":"/sec-04-02-quadrat-count-analysis#what-is-quadrat-count-analysis","position":3},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"Calculating Quadrat Count"},"type":"lvl2","url":"/sec-04-02-quadrat-count-analysis#calculating-quadrat-count","position":4},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"Calculating Quadrat Count"},"content":"The main steps in Quadrat Count Analysis are:\n\nDivide the study area into a grid of quadrats.\n\nCount the number of points in each quadrat.\n\nCalculate the expected number of points per quadrat under the assumption of Complete Spatial Randomness (CSR).\n\nCompare the observed frequency distribution (the counts) with the expected frequency distribution (under CSR) to assess the degree of similarity or difference between them.\n\nApply statistical tests, such as the chi-squared goodness-of-fit test, to determine whether the observed frequency distribution significantly differs from the expected distribution under CSR---whether the spatial pattern exhibits randomness, clustering, or regularity.","type":"content","url":"/sec-04-02-quadrat-count-analysis#calculating-quadrat-count","position":5},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"Count the number of points in each quadrat"},"type":"lvl2","url":"/sec-04-02-quadrat-count-analysis#count-the-number-of-points-in-each-quadrat","position":6},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"Count the number of points in each quadrat"},"content":"\n\nCounting points in cells\n\nThen, how to compare?","type":"content","url":"/sec-04-02-quadrat-count-analysis#count-the-number-of-points-in-each-quadrat","position":7},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"Chi-squared test"},"type":"lvl2","url":"/sec-04-02-quadrat-count-analysis#chi-squared-test","position":8},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"Chi-squared test"},"content":"Use Chi-squared test, which is suitable for comparing frequencies.\n\nThe quadrat method partitions the study region into r rows and c columns, which define m=r\\times c non-overlapping subregions or quadrats of equal area. This method relies on the fact that, under CSR, the expected number of observations within any region of equal size is the same. Let n be the number of observed points, m the number of quadrats of equal size, and n_i the number of points in quadrat i. The expected number of points in each quadrat is N/m. The test statistic is calculated as\\chi^2 = \\sum_{i=1}^m\\frac{\\text{observed}_i - \\text{expected}}{\\text{expected}}\\text{expected} = \\frac{N}{m}\n\nWhy?\n\nA CSR would have a mean at the average with a non-zero spread (non-zero deviation).\n\nUse Chi-squared test, which is suitable for comparing the frequencies against an expected frequency or distribution.\n\nClustered example\n\nchi-squared statistic= 354.332, p-value= 2.606e-66$\n\nsignificantly different from random\n\nRandom example\n\nchi-squared statistic= 19.332, p-value= 0.199\n\nnon-significant; the distribution is not different from random\n\nRegular example\n\nchi-squared statistic= 8.332, pvalue= 0.910\n\nnon-significant; the distribution is not different from random\n\nSince the expected number of points are the average number of points---the test do not consider the spread mathematically---thus the regular example ‘is not different from random’.","type":"content","url":"/sec-04-02-quadrat-count-analysis#chi-squared-test","position":9},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"Key considerations"},"type":"lvl2","url":"/sec-04-02-quadrat-count-analysis#key-considerations","position":10},{"hierarchy":{"lvl1":"Quadrat Count Analysis","lvl2":"Key considerations"},"content":"Some key considerations in Quadrat Count Analysis include:\n\nQuadrat size: The size of the quadrats should be carefully chosen to ensure that it is appropriate for the scale of the pattern being studied.\n\nQuadrat shape: While square quadrats are common, other shapes (such as rectangular or circular) may be used depending on the specific study requirements.\n\nEdge effects: Care should be taken to account for edge effects, which occur when quadrats at the edge of the study area contain fewer points due to the smaller overlapping area.\n\nIs the analysis result sensitive to the parameter settings?\n\nQuadrat Count Analysis provides a simple and intuitive approach to analyzing spatial point patterns, but it has some limitations compared to more advanced methods, such as distance-based or density-based approaches. Nonetheless, it is a useful tool for exploratory analysis and can be helpful in understanding the general characteristics of a spatial point pattern.","type":"content","url":"/sec-04-02-quadrat-count-analysis#key-considerations","position":11},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis"},"type":"lvl1","url":"/sec-04-03-nearest-neighbor-analysis","position":0},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis"},"content":"","type":"content","url":"/sec-04-03-nearest-neighbor-analysis","position":1},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"The 2 Distance-based Approaches"},"type":"lvl2","url":"/sec-04-03-nearest-neighbor-analysis#the-2-distance-based-approaches","position":2},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"The 2 Distance-based Approaches"},"content":"\n\nEveryone look for the nearest neighbor vs. everyone draw a series of search buffer (radius).\n\nIn this section, we focus on the first approach.","type":"content","url":"/sec-04-03-nearest-neighbor-analysis#the-2-distance-based-approaches","position":3},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"4 examples of point distribution: Clustered or Random?"},"type":"lvl2","url":"/sec-04-03-nearest-neighbor-analysis#id-4-examples-of-point-distribution-clustered-or-random","position":4},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"4 examples of point distribution: Clustered or Random?"},"content":"\n\n4 types of points in North Singapore: Woodlands Regional Centre, Woodlands West, and Woodgrove, with an area of 2 \\text{km} \\times 2 \\text{km}","type":"content","url":"/sec-04-03-nearest-neighbor-analysis#id-4-examples-of-point-distribution-clustered-or-random","position":5},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"Nearest Neighbor Analysis Calculation Process: In A Nut Shell"},"type":"lvl2","url":"/sec-04-03-nearest-neighbor-analysis#nearest-neighbor-analysis-calculation-process-in-a-nut-shell","position":6},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"Nearest Neighbor Analysis Calculation Process: In A Nut Shell"},"content":"Identifying nearest neighbors for every point\n\nRecord the nearest neighbor distances\n\nCalculate the mean value\n\nobserved average nearest neighbor distance (D_O)\n\nThe average nearest neighbor distance:\n\nshort: the points are close to each other\n\nlong: the points are far from each other\n\n\n\nSearching for the nearest neighbors.\n\nHow short is short enough to be considered as “clustered”?\n\nLet’s use the Monte Carlo Simulation approach to test the difference between the observed point pattern and a large number of random patterns generated under the CSR assumption.\n\n\n\nMean nearest neighbor distances for the four examples.","type":"content","url":"/sec-04-03-nearest-neighbor-analysis#nearest-neighbor-analysis-calculation-process-in-a-nut-shell","position":7},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"Option 1: Monte Carlo Simulation"},"type":"lvl2","url":"/sec-04-03-nearest-neighbor-analysis#option-1-monte-carlo-simulation","position":8},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"Option 1: Monte Carlo Simulation"},"content":"Area size has to match the study area.\n\nArea size will affect the distance between points.\n\nThe number of points has to match the dataset.\n\nWithin the same area, more points (higher density) will lead to lower nearest neighbor distances.\n\n\n\nMonte Carlo Simulation for point pattern.","type":"content","url":"/sec-04-03-nearest-neighbor-analysis#option-1-monte-carlo-simulation","position":9},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl3":"Statistical Testing","lvl2":"Option 1: Monte Carlo Simulation"},"type":"lvl3","url":"/sec-04-03-nearest-neighbor-analysis#statistical-testing","position":10},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl3":"Statistical Testing","lvl2":"Option 1: Monte Carlo Simulation"},"content":"After simulating random for M times, we will get M measurement of mean nearest neighbor distances.\n\nThe frequency distribution of the N values would form a normal distribution.\n\nThe range where the normal distribution is located represent the “random (CSR)” under the specific area and # point setting.\n\n\n\nNormal distribution pattern for the frequency of the NNA statistics for the simulated pattern.\n\n(1) If the observed value is far from the random, we found a clear evidence that the observed pattern is different from random.\n\neither clustered or dispersed\n\n\n\nIf the oberved value is far from the normal bell shape.\n\n(2) If the observed value fall within the random range, then, we did not find any evidence to prove that the observed pattern is different from random.\n\ncannot reject the null hypothesis\n\nwe have no choice but to believe it is random\n\n\n\nIf the oberved value fall within the normal bell shape.\n\n(3) If the observed fall at the edge of the normal distribution\n\ncheck p-value and your confidence level setting.\n\np-value: the probability of being wrong to reject null hypothesis\n\nSee [ESRI “What is a z-score? What is a p-value?”(\n\nhttps://​pro​.arcgis​.com​/en​/pro​-app​/latest​/tool​-reference​/spatial​-statistics​/what​-is​-a​-z​-score​-what​-is​-a​-p​-value​.htm) for more details]\n\n\n\nIf the oberved value fall within or near to the edge of the normal bell shape.\n\nLet’s say we set the confidence level to 99%, meaning we are willing to accept a 1% risk of being wrong (incorrectly rejecting the null hypothesis, H0).\nIf the obtained p-value is 3%, which is higher than our acceptable risk, then we cannot reject H0.\n\n\n\nHow the observed mean compared with 10k CSR simulations mean results?\n\nThe grey area indicates the mean nearest neighbor distance of the 10k random pattern.","type":"content","url":"/sec-04-03-nearest-neighbor-analysis#statistical-testing","position":11},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"Option 2: Z-test approach"},"type":"lvl2","url":"/sec-04-03-nearest-neighbor-analysis#option-2-z-test-approach","position":12},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"Option 2: Z-test approach"},"content":"Z-test is another option for testing the significant levels of how observed nearest neighbor distance (\\bar{D}_O) is different from the ‘expected’ average nearest neighbor distance (\\bar{D}_E) under CSR.\n\nSee \n\nESRI for detail.\n\nThe nearest neighbor distance ratio:\\text{ANN} = \\frac{\\bar{D}_O}{\\bar{D}_E}\n\nIf the index (\\text{ANN}) is less than 1, the pattern exhibits clustering.\nIf the index is greater than 1, the trend is toward dispersion.\n\nThe expected mean distance could be calculated using the number of point (n) and the study area (A):\\bar{D}_E = \\frac{0.5}{\\sqrt{n/A}}\n\nThe z-score can then be calculated using \\bar{D}_O and \\bar{D}_E:z = \\frac{\\bar{D}_O - \\bar{D}_E}{SE}\n\nThe z-score and p-value for this statistic are sensitive to changes in the study area or changes to the Area parameter. For this reason, only compare z-score and p-value results from this statistic when the study area is fixed.\n\n\n\nZ-test and z-score. See \n\nESRI “What is a z-score? What is a p-value?” for more details.","type":"content","url":"/sec-04-03-nearest-neighbor-analysis#option-2-z-test-approach","position":13},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"Summary: Nearest Neighbor Analysis (NNA)"},"type":"lvl2","url":"/sec-04-03-nearest-neighbor-analysis#summary-nearest-neighbor-analysis-nna","position":14},{"hierarchy":{"lvl1":"Nearest Neighbor Analysis","lvl2":"Summary: Nearest Neighbor Analysis (NNA)"},"content":"This approach calculates the average distance of the nearest neighbor for every point.\n\nThe observed average nearest neighbor distance can be tested using a Monte Carlo Simulation or z-test approaches against the null hypothesis of CSR.\n\nThe NNA has an assumption that the points being measured are free to locate anywhere within the study area (for example, there are no barriers, and all cases or features are located independently of one another).","type":"content","url":"/sec-04-03-nearest-neighbor-analysis#summary-nearest-neighbor-analysis-nna","position":15},{"hierarchy":{"lvl1":"Ripley’s K-function"},"type":"lvl1","url":"/sec-04-04-ripleys-k-function","position":0},{"hierarchy":{"lvl1":"Ripley’s K-function"},"content":"","type":"content","url":"/sec-04-04-ripleys-k-function","position":1},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"The 2 Distance-based Approaches"},"type":"lvl2","url":"/sec-04-04-ripleys-k-function#the-2-distance-based-approaches","position":2},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"The 2 Distance-based Approaches"},"content":"\n\nEveryone look for the nearest neighbor vs. everyone draw a series of search buffer (radius).\n\nIn this section, we focus on the second approach.","type":"content","url":"/sec-04-04-ripleys-k-function#the-2-distance-based-approaches","position":3},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"Bus Stops Distribution"},"type":"lvl2","url":"/sec-04-04-ripleys-k-function#bus-stops-distribution","position":4},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"Bus Stops Distribution"},"content":"Take bus stops distribution for example:\n\nBus stops usually constructed in pairs, at both sides of a street.\n\nThe nearest neighbor is at a short distance (opposite of street), but the second nearest may not.\n\nIs it a “real” clustered pattern?\n\n\n\nBus Stops distribution. Is the nearest neighbor distance ‘meaningful’?","type":"content","url":"/sec-04-04-ripleys-k-function#bus-stops-distribution","position":5},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"The Search Radius Approach"},"type":"lvl2","url":"/sec-04-04-ripleys-k-function#the-search-radius-approach","position":6},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"The Search Radius Approach"},"content":"The Ripley’s K-function:\n\nGenerate a series of search radius (SR), from low to high\n\nSearch for pairs of points fall within every SR\n\nThe implication:\n\nif a lot of pairs are found within a short SR: the points are clustered at this distance.\n\n\n\nSimulation of the buffer area and counting.\n\nA common transformation of the K-function:L(d) = \\sqrt{\\frac{A \\times \\text{pairs}_d }{\\pi n(n-1)}}\\text{pairs}\\_d = \\sum\\_{i=1}^n \\sum\\_{j=1, j\\neq i}^n w\\_{ij}\n\nL(d): the k-function value at search radius d\n\n\\text{pairs}_d: the number of pairs of points with distance less than d\n\nw_{ij}: equal to 1 if non-weighted; weighting for edge-correction\n\nA: Area of study\n\nn: total number of points\n\nn(n-1): total number of all pairs\n\nMore info: \n\nESRI ArcGIS: How multi-distance spatial cluster analysis works.","type":"content","url":"/sec-04-04-ripleys-k-function#the-search-radius-approach","position":7},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"Testing for K-functions"},"type":"lvl2","url":"/sec-04-04-ripleys-k-function#testing-for-k-functions","position":8},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"Testing for K-functions"},"content":"How high is high enough to be considered as clustered?\n\nTo compare them with CSR, Monte Carlo Simulation can be used (again)\n\n\n\nThe clustered and dispersed range of K-function curve.\n\nFor demonstration: 10 random patterns are generated\n\n\n\nK-function curve of the four examples and the k-function curves of the corresponding 10 random distributions.\n\nCalculate 95% Confidence envelop. See \n\nESRI for more details.\n\n\n\nThe k-function curves and the confidence interval (Monte Carlo Simulation) for the 4 examples.","type":"content","url":"/sec-04-04-ripleys-k-function#testing-for-k-functions","position":9},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"Comparison between NNA and K-function results"},"type":"lvl2","url":"/sec-04-04-ripleys-k-function#comparison-between-nna-and-k-function-results","position":10},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"Comparison between NNA and K-function results"},"content":"\n\n(a)Nearest Neighbor Analysis\n\n\n\n(b)Ripley's K-function\n\nFigure 7:The results for the 4 examples using two methods.","type":"content","url":"/sec-04-04-ripleys-k-function#comparison-between-nna-and-k-function-results","position":11},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"Summary: Repley’s K-function"},"type":"lvl2","url":"/sec-04-04-ripleys-k-function#summary-repleys-k-function","position":12},{"hierarchy":{"lvl1":"Ripley’s K-function","lvl2":"Summary: Repley’s K-function"},"content":"Purpose\n\nRipley’s K function is a tool used to analyze spatial point patterns, helping researchers understand the spatial relationships among events or objects in a given study area.\n\nFunctionality\n\nThe K function estimates the expected number of points within a given distance from a randomly chosen point, providing insights into clustering, dispersion, or randomness in the spatial pattern.\n\nKey features\n\nThe K function can be plotted as a function of distance to visualize changes in spatial interactions at different scales.\n\nIt can be compared with theoretical models, such as complete spatial randomness (CSR), to assess deviations from expected patterns.","type":"content","url":"/sec-04-04-ripleys-k-function#summary-repleys-k-function","position":13},{"hierarchy":{"lvl1":"A Demonstration"},"type":"lvl1","url":"/sec-04-05-a-demonstration","position":0},{"hierarchy":{"lvl1":"A Demonstration"},"content":"\n\n.headnote.square.bold.x-large[Point Pattern I]\n\nclass: center, middle\nbackground-image: url(resources/w05-img/gordon_square2b.png)","type":"content","url":"/sec-04-05-a-demonstration","position":1},{"hierarchy":{"lvl1":"A Demonstration","lvl2":"Let’s do a mind travel..."},"type":"lvl2","url":"/sec-04-05-a-demonstration#lets-do-a-mind-travel","position":2},{"hierarchy":{"lvl1":"A Demonstration","lvl2":"Let’s do a mind travel..."},"content":"\n\nclass: left, middle\nbackground-image: url(resources/w05-img/gordon_square2.png)\n\n","type":"content","url":"/sec-04-05-a-demonstration#lets-do-a-mind-travel","position":3},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Gordon Square","lvl2":"Let’s do a mind travel..."},"type":"lvl3","url":"/sec-04-05-a-demonstration#gordon-square","position":4},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Gordon Square","lvl2":"Let’s do a mind travel..."},"content":"\n\n.footnote-right.red.title-font.bold[Source: \n\nGoogle Map]\n\nclass: left, middle","type":"content","url":"/sec-04-05-a-demonstration#gordon-square","position":5},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"The question","lvl2":"Let’s do a mind travel..."},"type":"lvl3","url":"/sec-04-05-a-demonstration#the-question","position":6},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"The question","lvl2":"Let’s do a mind travel..."},"content":"Can we assume people randomly find a spot to sit?\n\nCan we assume people prefer not to sit too close to strangers?\n\nIf they go with friends or colleagues, they will sit together.\n\n\n.underline[Will the process of .red[people finding comfortable spots for sitting in an open space] result in a random, clustered, or dispersed pattern?]\n\n\nAnalyze with:\n\nindividual level\n\ngroup level\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-04-05-a-demonstration#the-question","position":7},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"The dataset","lvl2":"Let’s do a mind travel..."},"type":"lvl3","url":"/sec-04-05-a-demonstration#the-dataset","position":8},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"The dataset","lvl2":"Let’s do a mind travel..."},"content":"This dataset records the location of people sitting on a grass patch in Gordon Square, London, at 3pm on a sunny afternoon.\n\nArea: 42 \\times 56 \\text{m}^2\n\nSource: \n\nR spatstat dataset\n\n.footnote-left.smaller[Baddeley et al. 2013: \n\nDOI:10​.18637​/jss​.v055​.i11]\n].column[\n\n]]\n\nclass: center, top\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/sec-04-05-a-demonstration#the-dataset","position":9},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Nearest Neighbor Analysis","lvl2":"Let’s do a mind travel..."},"type":"lvl3","url":"/sec-04-05-a-demonstration#nearest-neighbor-analysis","position":10},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Nearest Neighbor Analysis","lvl2":"Let’s do a mind travel..."},"content":"For individual, the p-value is significant with a negative z-score, indicating people tended to sit together.\n\nFor in-group, the p-value is significant, with a positive z-score, suggesting the locations of groups are dispersed.\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/sec-04-05-a-demonstration#nearest-neighbor-analysis","position":11},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Ripley’s K-function","lvl2":"Let’s do a mind travel..."},"type":"lvl3","url":"/sec-04-05-a-demonstration#ripleys-k-function","position":12},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Ripley’s K-function","lvl2":"Let’s do a mind travel..."},"content":"For individual,\n\nradius 4 m resulted in higher than random, indicating people tended to sit together at this scale.\n\nbetwen 4 m and 6 m , the observed line is near to the random, but still above the 95% CI.\n\n\nFor in-group,\n\nthe search radius less than 7 m resulted in dispersed pattern.\n\nthe search radius beyond 8 m presented random pattern.\n\n].column[\n\n]]\n\nclass: center, middle, inverse","type":"content","url":"/sec-04-05-a-demonstration#ripleys-k-function","position":13},{"hierarchy":{"lvl1":"A Demonstration","lvl2":"Closing Remarks"},"type":"lvl2","url":"/sec-04-05-a-demonstration#closing-remarks","position":14},{"hierarchy":{"lvl1":"A Demonstration","lvl2":"Closing Remarks"},"content":"\n\n.square[Considerations .dot[] Workflow .dot[] About Tests]\n\n.headnote.square.bold.x-large[Point Pattern I]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-04-05-a-demonstration#closing-remarks","position":15},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Summary","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-04-05-a-demonstration#summary","position":16},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Summary","lvl2":"Closing Remarks"},"content":"","type":"content","url":"/sec-04-05-a-demonstration#summary","position":17},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"NNA & K-function: Key Considerations, Limitations, and Directions","lvl3":"Summary","lvl2":"Closing Remarks"},"type":"lvl4","url":"/sec-04-05-a-demonstration#nna-k-function-key-considerations-limitations-and-directions","position":18},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"NNA & K-function: Key Considerations, Limitations, and Directions","lvl3":"Summary","lvl2":"Closing Remarks"},"content":".red[Sensitive to study area size and settings]\n\nEdge effect (border effect)\n\nPopulation-at-risk\n].column[\n\n.bold[Sensitive to study area size and settings]:\nCSR assume points to be scattered all around the study area. Thus, Ripley’s K function can be influenced by the size and shape of the study area. .red[Larger study areas] may result in different K function estimates compared to smaller ones, and .red[irregular shapes] can introduce biases. Additionally, the settings used for the K function analysis, such as the bandwidth or edge correction method, can impact the results. ]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-04-05-a-demonstration#nna-k-function-key-considerations-limitations-and-directions","position":19},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Summary","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-04-05-a-demonstration#summary-1","position":20},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Summary","lvl2":"Closing Remarks"},"content":"","type":"content","url":"/sec-04-05-a-demonstration#summary-1","position":21},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"NNA & K-function: Key Considerations, Limitations, and Directions","lvl3":"Summary","lvl2":"Closing Remarks"},"type":"lvl4","url":"/sec-04-05-a-demonstration#nna-k-function-key-considerations-limitations-and-directions-1","position":22},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"NNA & K-function: Key Considerations, Limitations, and Directions","lvl3":"Summary","lvl2":"Closing Remarks"},"content":"Sensitive to study area size and settings\n\n.red[Edge effect (border effect)]\n\nPopulation-at-risk\n].column[\n\n.bold[Edge effect] (border effect):\nPoints beyond the study area are ‘ignored.’ .red[Points close to the boundary of the study area may have fewer neighboring points] than those in the interior, which can bias the K function estimates. This is known as the edge effect, and it can introduce inaccuracies when studying spatial patterns. Edge correction methods are often employed to mitigate this issue. ]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-04-05-a-demonstration#nna-k-function-key-considerations-limitations-and-directions-1","position":23},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Summary","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-04-05-a-demonstration#summary-2","position":24},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Summary","lvl2":"Closing Remarks"},"content":"","type":"content","url":"/sec-04-05-a-demonstration#summary-2","position":25},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"NNA & K-function: Key Considerations, Limitations, and Directions","lvl3":"Summary","lvl2":"Closing Remarks"},"type":"lvl4","url":"/sec-04-05-a-demonstration#nna-k-function-key-considerations-limitations-and-directions-2","position":26},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"NNA & K-function: Key Considerations, Limitations, and Directions","lvl3":"Summary","lvl2":"Closing Remarks"},"content":"Sensitive to study area size and settings\n\nEdge effect (border effect)\n\n.red[Population-at-risk]\n].column[\n\n.bold[Population-at-risk]:\nRipley’s K function assumes that the underlying point process is .red[stationary and homogeneous]. If the population at risk (i.e., the underlying risk of events occurring) is not uniform across the study area, this can violate the assumptions and lead to misleading results. Incorporating information on the population at risk can help refine the analysis and improve the accuracy of the conclusions drawn from the K function. ]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-04-05-a-demonstration#nna-k-function-key-considerations-limitations-and-directions-2","position":27},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"What has been covered today","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-04-05-a-demonstration#what-has-been-covered-today","position":28},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"What has been covered today","lvl2":"Closing Remarks"},"content":"What is the workflow of analyzing spatial point pattern?\n\nGlobal Pattern: the overall pattern of the point distribution\n\nLocal Pattern: where are the clusters\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-04-05-a-demonstration#what-has-been-covered-today","position":29},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Some notes","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-04-05-a-demonstration#some-notes","position":30},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"Some notes","lvl2":"Closing Remarks"},"content":"].column[\nThe three methods explore the spatial pattern with different angle:\n\nQuadrat count: the number of points fall in equal size quadrats\n\nNNA: how near/far the nearest neighbor is\n\nK-function: how many other points could be found for a specific search radius\n\nThe latter two methods can be extended:\n\nNNA: to k-order nearest neighbor (see: .smaller[\n\nCrimeStat III])\n\nK-function: weighted K-function (see: .smaller[\n\nArcGIS Pro])\n\nThings to considered:\n\n.red[Edge effect]: the near border areas could be underestimated due to the external points. (see: .smaller[\n\nDOI:10.2307/3237072])\n\n.red[Population at risk]: a place with more population could have more events (e.g., crime/disease cases) happens by chance. (see: .smaller[\n\nSaTScan])\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-04-05-a-demonstration#some-notes","position":31},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"About Statistical Tests","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-04-05-a-demonstration#about-statistical-tests","position":32},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"About Statistical Tests","lvl2":"Closing Remarks"},"content":"].column[","type":"content","url":"/sec-04-05-a-demonstration#about-statistical-tests","position":33},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"About Tests","lvl3":"About Statistical Tests","lvl2":"Closing Remarks"},"type":"lvl4","url":"/sec-04-05-a-demonstration#about-tests","position":34},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"About Tests","lvl3":"About Statistical Tests","lvl2":"Closing Remarks"},"content":"There are so many tests. It is more important to know:\n\nThe key considerations for choosing a test:\nUnderstand the .red[assumptions, requirements, and limitations of each test], as well as .red[the nature of your data] and .red[research questions], to select the most appropriate test.\n\nKnowing these can help you to choose the appropriate test(s).\n\nWhat you’re testing and why:\nBe clear to yourself about the null and alternative hypotheses, .red[the rationale behind them], and .red[the implications of your results].\n\nAre you testing against CSR? Why?\n\nExplicitly communicate your approach:\nyou have to explicitly tell your readers what, why, and how.\n\nDon’t let your readers guess.\n\n.xkcd[No single test is suitable for all situations, and it’s impossible to memorize every test.]\nInstead, focus on developing a strong foundation in statistical concepts and .red[knowing where to find] relevant information when selecting the appropriate test for your specific needs.\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-04-05-a-demonstration#about-tests","position":35},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"About Statistical Tests","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-04-05-a-demonstration#about-statistical-tests-1","position":36},{"hierarchy":{"lvl1":"A Demonstration","lvl3":"About Statistical Tests","lvl2":"Closing Remarks"},"content":"].column[","type":"content","url":"/sec-04-05-a-demonstration#about-statistical-tests-1","position":37},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"About p-value","lvl3":"About Statistical Tests","lvl2":"Closing Remarks"},"type":"lvl4","url":"/sec-04-05-a-demonstration#about-p-value","position":38},{"hierarchy":{"lvl1":"A Demonstration","lvl4":"About p-value","lvl3":"About Statistical Tests","lvl2":"Closing Remarks"},"content":"p-value can only tell you how much risk you need to take if you reject H0.\n\nthe common practice is to check if p-value < \\alpha, and common alpha values are:\n\n0.05 for 95% confidence,\n\n0.01 for 99% confidence, and\n\n0.001 for 99.9% confidence.\n\nIf p-value is less than the pre-determined \\alpha, then it is significantly different.\n\nThat’s how far you can get with p-value---.red[don’t over-interpret the p-value].\n\nComparing p-values can be problematic, because they may be calculated from different settings, e.g., sample size.\n\n]]","type":"content","url":"/sec-04-05-a-demonstration#about-p-value","position":39},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern"},"type":"lvl1","url":"/chapter-5-local-point-pattern","position":0},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern"},"content":"\n\n.square[Global Pattern .dot[] Local Pattern]\n\n.headnote.square.bold.x-large[Point Pattern II]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/chapter-5-local-point-pattern","position":1},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"What have we learnt previous weeks?"},"type":"lvl2","url":"/chapter-5-local-point-pattern#what-have-we-learnt-previous-weeks","position":2},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"What have we learnt previous weeks?"},"content":"].column[\n\nPoint Patterns\n\nComplete Spatial Randomness\n\nMethods for differentiating various types of point patterns:\n\nclustered,\n\nrandom,\n\ndispersed\n\nThe main purpose and testing hypothesis is:\n.bold[Does the entire/overall pattern of point data present some sort of\n.red[non-random] pattern?]\n.xkcd.red[It does not answer .bold[WHERE] the pattern occurs.]\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/chapter-5-local-point-pattern#what-have-we-learnt-previous-weeks","position":3},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Global Analysis"},"type":"lvl2","url":"/chapter-5-local-point-pattern#global-analysis","position":4},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Global Analysis"},"content":"].column[\n\n.bold[Terminology]: The term ‘.red[GLOBAL]’ refers to the .red[scale of analysis], which encompasses the .red[entire study area], rather than implying an .red[analysis at the Earth’s scale].\n\n.bold[Holistic perspective]: Global analysis provides an .red[overall view] of the spatial patterns or trends across the entire study area, enabling a comprehensive understanding of the phenomena under investigation.\n\nIs the crime incidences clustered within the study area?\n\n.bold[Spatial autocorrelation]: Global analysis can detect global spatial autocorrelation, a measure of .red[how similar or dissimilar the values] of a given attribute .red[are in nearby locations].\n\nDo places with more crime incidences near to other places with more crime incidences?\n\n.bold[Spatial heterogeneity]: It helps identify global spatial heterogeneity, or .red[the variation of a given attribute across the study area], providing insights into the distribution patterns of the phenomena.\n\nIs the crime rate similar across the study area?\n\nIs the crime rate (non-)uniform within the study area?\n\n.bold[Modeling and prediction]: Global analysis aids .red[in developing statistical models and predictions for the entire study area] by incorporating spatial autocorrelation and heterogeneity into the analysis.\n\n.bold[Scale considerations]: The results of global analysis may depend on .red[the scale or resolution of the study area], highlighting the importance of selecting appropriate spatial scales for the analysis.\n]]\n\nclass: left, middle","type":"content","url":"/chapter-5-local-point-pattern#global-analysis","position":5},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Global Analysis"},"type":"lvl2","url":"/chapter-5-local-point-pattern#global-analysis-1","position":6},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Global Analysis"},"content":"Think of a regression model---any model. .red.xkcd[Would you focus on a single data point or a subset of data points?]\n\nIn most cases, when working with regression models, we .red[do not focus on the characteristics of a single or a few individual data points]. Instead, we pay attention to the .red[overall ‘pattern’ that emerges when considering the entire dataset]. This pattern allows us to calculate crucial components such as regression coefficients (\\beta), their significance, and relevant statistical tests like r^2, pseudo r^2, AIC, and others.\n\nBy examining the .red[collective behavior] of the data points, we can gain insights into the underlying relationships between variables, assess the model’s performance, and make informed predictions or decisions based on the model’s output. In other words, .red[a ‘global’ understanding] of the entire dataset.\n\nclass: center, middle\n\n.red.square[Is it clustered? not-clustered? random?]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/chapter-5-local-point-pattern#global-analysis-1","position":7},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Local Analysis"},"type":"lvl2","url":"/chapter-5-local-point-pattern#local-analysis","position":8},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Local Analysis"},"content":"As geographers, we are not satisfied with the global understanding, we also want to know .red[‘where’].\n\n].column[","type":"content","url":"/chapter-5-local-point-pattern#local-analysis","position":9},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl3":"What is Local Analysis","lvl2":"Local Analysis"},"type":"lvl3","url":"/chapter-5-local-point-pattern#what-is-local-analysis","position":10},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl3":"What is Local Analysis","lvl2":"Local Analysis"},"content":".bold[Local pattern]: Local analysis focuses on .red[identifying patterns or trends within specific local areas or neighborhoods] in the study region.\n\n.bold[Spatial Heterogeneity]: It explores spatial variations by examining how a given attribute behaves differently across various locations in the study area.\n\n.bold[Identification of location]: Local analysis is crucial for understanding the nuances of spatial data and identifying specific regions that require targeted interventions or further investigation.\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/chapter-5-local-point-pattern#what-is-local-analysis","position":11},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Local Analysis"},"type":"lvl2","url":"/chapter-5-local-point-pattern#local-analysis-1","position":12},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Local Analysis"},"content":"].column[","type":"content","url":"/chapter-5-local-point-pattern#local-analysis-1","position":13},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl3":"Key aspects of local analysis include:","lvl2":"Local Analysis"},"type":"lvl3","url":"/chapter-5-local-point-pattern#key-aspects-of-local-analysis-include","position":14},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl3":"Key aspects of local analysis include:","lvl2":"Local Analysis"},"content":".bold[Detection of local clusters]: Identifying regions with high or low concentrations of a given attribute, also known as hot spots and cold spots, respectively.\n\n.bold[Local spatial autocorrelation]: Evaluating how similar or dissimilar the values of a given attribute are in nearby locations within specific local areas.\n\n.bold[Scale-dependent patterns]: Investigating how local patterns change with different spatial scales or resolutions.\n\n.bold[Finer details]: Local analysis complements global analysis by providing insights into the finer details of spatial patterns and helping to develop more targeted strategies and solutions for different parts of the study area.\n]]\n\nclass: left, middle","type":"content","url":"/chapter-5-local-point-pattern#key-aspects-of-local-analysis-include","position":15},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Local Analysis"},"type":"lvl2","url":"/chapter-5-local-point-pattern#local-analysis-2","position":16},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Local Analysis"},"content":"The aim of local analysis in geospatial visualization and statistics is .red[to identify local patterns and spatial variations] by examining how a given attribute .red[behaves differently across various locations] in the study area. This includes understanding the interaction between nearby spatial units and .red[detecting clusters or hot spots] where the concentration of the attribute is .red[significantly] high or low compared to the surrounding areas.\n\n.red[.bold[Local] Spatial Analysis is to answer the question of .bold[WHERE are the clusters]?]\n\n.red[.bold[Global] Spatial Analysis is about the question of .bold[WHAT is the pattern]?]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/chapter-5-local-point-pattern#local-analysis-2","position":17},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Local Analysis - HOW?"},"type":"lvl2","url":"/chapter-5-local-point-pattern#local-analysis-how","position":18},{"hierarchy":{"lvl1":"Global Pattern and Local Pattern","lvl2":"Local Analysis - HOW?"},"content":"].column[\nCommon methods for Local Spatial Analysis include:\n\nLocal Indicators of Spatial Association (LISA)\n\nLocal Moran’s I\n\nLocal Geary’s C\n\nLocal Getis-Ord Gi*\n\nKernel Density Estimation\n]]","type":"content","url":"/chapter-5-local-point-pattern#local-analysis-how","position":19},{"hierarchy":{"lvl1":"Kernel Density Estimation"},"type":"lvl1","url":"/sec-05-01-kernel-density-estimation","position":0},{"hierarchy":{"lvl1":"Kernel Density Estimation"},"content":"\n\n.square[KDE .dot[] Properties .dot[] How .dot[]  Kernel Function .dot[] Bandwidth .dot[] Advanced]\n\n.headnote.square.bold.x-large[Point Pattern II]\n\nclass: left, middle","type":"content","url":"/sec-05-01-kernel-density-estimation","position":1},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Kernel Density Estimation - the conceptual definition"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#kernel-density-estimation-the-conceptual-definition","position":2},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Kernel Density Estimation - the conceptual definition"},"content":"Kernel Density Estimation (KDE) is a .red[non-parametric technique] for estimating the probability density function---.red[the kernel function]---of a continuous variable. KDE is widely used in various fields, such as statistical analysis, machine learning, and data visualization. The main idea behind KDE is .red[to represent the underlying probability distribution] of a dataset by summing up the influence of individual data points.\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#kernel-density-estimation-the-conceptual-definition","position":3},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Kernel Density Estimation - key properties"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#kernel-density-estimation-key-properties","position":4},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Kernel Density Estimation - key properties"},"content":"].column[\n\n.bold[Non-parametric approach]: KDE does not assume a specific underlying distribution for the data, making it suitable for various types of data distributions.\n\n.bold[Smoothing technique]: KDE applies a kernel function (e.g., a Gaussian or Epanechnikov kernel) to smooth the input data, resulting in a continuous density estimate.\n\n.bold[Bandwidth selection]: A crucial aspect of KDE is choosing an appropriate bandwidth or smoothing parameter, which controls the degree of smoothing applied to the data. Optimal bandwidth selection methods, such as cross-validation or plug-in methods, help to balance bias and variance in the density estimate.\n\n.bold[Multivariate extension]: KDE can be extended to handle multivariate (multi-dimensions) data, providing a way to visualize and analyze the relationships between multiple variables in a dataset.\n]]\n\nclass: left, middle","type":"content","url":"/sec-05-01-kernel-density-estimation#kernel-density-estimation-key-properties","position":5},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Probability Density Function"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#probability-density-function","position":6},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Probability Density Function"},"content":"\n\nA probability density function (PDF) represents the distribution of a continuous random variable, depicting the likelihood of observing values in a given range.\n\nPDFs provide a comprehensive understanding of the underlying data distribution, including its central tendency, variability, and shape.\n\nThey are essential for various data analysis tasks, such as data visualization, outlier detection, and statistical inference.\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#probability-density-function","position":7},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Limitations of Parametric Density Estimation Approaches"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#limitations-of-parametric-density-estimation-approaches","position":8},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Limitations of Parametric Density Estimation Approaches"},"content":"].column[\n\nParametric density estimation methods assume that the data follows a specific probability distribution, such as the normal (Gaussian) or exponential distribution.\n\nThese methods estimate the distribution parameters (e.g., mean, variance) to characterize the data and make further inferences.\n\nHowever, the performance of parametric methods .red[heavily relies on the correctness of the assumed distribution, which may not always hold true for real-world datasets].\n\nIncorrect distribution assumptions can lead to biased results and misinterpretations of the data.\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#limitations-of-parametric-density-estimation-approaches","position":9},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"The Need for a Flexible and Data-Driven Approach like KDE"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#the-need-for-a-flexible-and-data-driven-approach-like-kde","position":10},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"The Need for a Flexible and Data-Driven Approach like KDE"},"content":"].column[\n\nKDE is a non-parametric method for estimating probability density functions directly from the data.\n\nKDE does not require strong assumptions about the underlying distribution of the data, making it more flexible and adaptable to various data types and scenarios.\n\nKDE’s data-driven approach allows it to capture complex and irregular features in the data distribution, which may be missed by parametric methods.\n\nBy avoiding distribution assumptions, KDE helps mitigate the risk of obtaining misleading results due to incorrect assumptions.\n\nThis flexibility and data-driven nature make KDE an attractive choice for a wide range of data analysis tasks, particularly when the underlying distribution is unknown or complex.\n\n.xkcd[In simple words, KDE is a data-driven way to approximate the PDF of data.]\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#the-need-for-a-flexible-and-data-driven-approach-like-kde","position":11},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Definition of Kernel Functions and their properties"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#definition-of-kernel-functions-and-their-properties","position":12},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Definition of Kernel Functions and their properties"},"content":"].column[\nA kernel function is a mathematical function used in KDE .red[to assign weights to data points based on their distances from a location of interest].\n\nKernel functions are characterized by several properties:\n\n.bold[Symmetry]: The kernel function should be symmetric around the origin, ensuring equal weighting for points equidistant from the location of interest.\n\n.bold[Non-negativity]: The kernel function should yield non-negative weights, preventing the occurrence of negative density values.\n\n.bold[Integration to 1]: The kernel function should integrate to 1 over its domain, ensuring that the total density estimated across the entire range of the data sums to 1.\n]]\n\nclass: left, middle\n.split-50[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#definition-of-kernel-functions-and-their-properties","position":13},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"How KDE works"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#how-kde-works","position":14},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"How KDE works"},"content":"Approach one (from point to space):\n\nFor every data point, draw a kernel, i.e., the red dashed lines in left figure.\n\nStack the kernels if they overlapped, i.e., the blue solid line.\n\nApproach two (from space to point):\n\nFor every space unit (x-axis), draw a kernel.\n\nIdentify data points that fall within the kernel range.\n\nMeasure the distance from data point to the space unit.\n\nConvert the distance to weight using kernel function.\n\nSum the weight through all identified points in step 2.\n\n].column[\n\n\nA histogram and KDE plot. .small.square[Image source: \n\nWikipedia]\n\n]]\n\nclass: center, middle\n\n.headnote.bold[How KDE works]\n\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#how-kde-works","position":15},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions","position":16},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"content":".red[Gaussian kernel]\n\nEpanechnikov/Parabolic kernel\n\nQuartic (biweight) kernel\n\nTriangular kernel\n\nUniform kernel\n].column[\n.bold[Gaussian (normal) kernel]:\nThe Gaussian kernel follows a bell-shaped curve and is widely used due to its smoothness and differentiability. Its formula is given by:K(x) = \\frac{1}{h\\times \\sqrt{2\\pi}} \\times e^{-0.5(x/h)^2}\n\n.xkcd[bandwidth (h) set as 1]\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions","position":17},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions-1","position":18},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"content":"Gaussian kernel\n\n.red[Epanechnikov/Parabolic kernel]\n\nQuartic (biweight) kernel\n\nTriangular kernel\n\nUniform kernel\n].column[\n.bold[Epanechnikov (parabolic) kernel]:\nThe Epanechnikov kernel is optimal for some statistical properties and has a compact support, meaning it assigns zero weight to points outside a specific range. Its formula is:\nK(x) =\n\\begin{cases}\n\\frac{3}{4h} \\times (1 - (x / h)^2) & \\text{if -h ≤ x ≤ h} \\\\\\\\\n0 & \\text{otherwise} \\\\\n\\end{cases}\n\n\n\n\n.xkcd[bandwidth (h) set as 1]\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions-1","position":19},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions-2","position":20},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"content":"Gaussian kernel\n\nEpanechnikov/Parabolic kernel\n\n.red[Quartic (biweight) kernel]\n\nTriangular kernel\n\nUniform kernel\n].column[\n.bold[Quartic (biweight) kernel]:\nThe Quartic kernel function is another commonly used kernel function in Kernel Density Estimation (KDE). It is defined as follows:\nK(x) =\n\\begin{cases}\n\\frac{15}{16h} \\times (1 - (x / h)^2)^2  & \\text{if -h ≤ x ≤ h} \\\\\\\\\n0 & \\text{otherwise} \\\\\n\\end{cases}\n\n\n\n\n.xkcd[bandwidth (h) set as 1]\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions-2","position":21},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions-3","position":22},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"content":"Gaussian kernel\n\nEpanechnikov/Parabolic kernel\n\nQuartic (biweight) kernel\n\n.red[Triangular kernel]\n\nUniform kernel\n].column[\n.bold[Triangular kernel]:\nThe Triangular kernel function is a simple and computationally efficient kernel that assigns weights to points based on a triangular shape. It is defined as:\nK(x) =\n\\begin{cases}\n\\frac{1 - |x/h|}{h} & \\text{if -h ≤ x ≤ h} \\\\\\\\\n0 & \\text{otherwise} \\\\\n\\end{cases}\n\n\n\n\n.xkcd[bandwidth (h) set as 1]\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions-3","position":23},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions-4","position":24},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Common Kernel Functions"},"content":"Gaussian kernel\n\nEpanechnikov/Parabolic kernel\n\nQuartic (biweight) kernel\n\nTriangular kernel\n\n.red[Uniform kernel]\n].column[\n.bold[Uniform (Tophat) kernel]:\nThe uniform kernel assigns equal weights to points within a specific range and zero weight outside that range. Its formula is:K(x) =\n\\begin{cases}\n\\frac{1}{2h} & \\text{if -h ≤ x ≤ h} \\\\\\\\\n0 & \\text{otherwise} \\\\\n\\end{cases}\n\n.xkcd[bandwidth (h) set as 1]\n]]\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#common-kernel-functions-4","position":25},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"The effect of Bandwidth"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#the-effect-of-bandwidth","position":26},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"The effect of Bandwidth"},"content":"].column[\n\n\n.square[Effect of bandwidth (h) on Kernel Function (weighting).]\n]]\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#the-effect-of-bandwidth","position":27},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"The effect of Bandwidth"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#the-effect-of-bandwidth-1","position":28},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"The effect of Bandwidth"},"content":"].column[\n\n\n.square[Effect of bandwidth (h) on 1-D KDE results.]\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#the-effect-of-bandwidth-1","position":29},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Bandwidth Selection"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#bandwidth-selection","position":30},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Bandwidth Selection"},"content":".red[Rule of Thumb]\n\nCross-Validation\n\nPlug-in Methods\n\nVisual Inspection\n].column[\n.bold[Rule of Thumb]:\n\nSilverman’s rule: For a Gaussian kernel,\n\nh \\approx 1.06 \\times \\sigma \\times n^{-1/5},\n\nwhere \\sigma is the .red[standard deviation of the data], and n is the .red[number of data points].\n\nOther heuristics exist for different kernel functions and data dimensions. These rules provide quick estimates but may not be optimal for all datasets.\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#bandwidth-selection","position":31},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Bandwidth Selection"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#bandwidth-selection-1","position":32},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Bandwidth Selection"},"content":"Rule of Thumb\n\n.red[Cross-Validation]\n\nPlug-in Methods\n\nVisual Inspection\n].column[\n.bold[Cross-Validation]:\n\nPartition the data into several training sets.\n\nApply KDE with different bandwidth values to the training set and full dataset.\n\nCalculate the error (MAE, MSE, etc.) between the estimated density and full data set density.\n\nChoose the bandwidth that minimizes the error.\n\nThis method is more computationally intensive but provides a more data-driven bandwidth selection.\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#bandwidth-selection-1","position":33},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Bandwidth Selection"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#bandwidth-selection-2","position":34},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Bandwidth Selection"},"content":"Rule of Thumb\n\nCross-Validation\n\n.red[Plug-in Methods]\n\n.red[Visual Inspection]\n].column[\n.bold[Plug-in Methods]:\n\nThese methods, such as Least Squares Cross-Validation (LSCV), directly estimate the optimal bandwidth by minimizing an approximation of the Mean Integrated Squared Error (MISE).\n\nPlug-in methods are more complex but can provide better bandwidth estimates in certain scenarios.\n\n.bold[Visual Inspection]:\n\nPlot KDE with different bandwidth values and visually inspect the resulting density estimates.\n\nChoose the bandwidth that produces a density estimate that best captures the underlying structure and trends in the data. This method is subjective and relies on human judgment.\n\n.bold[Remarks]:\n\nIn practice, you can start with a .red[rule-of-thumb] estimate, then refine it using .red[cross-validation] or .red[plug-in] methods, and finally perform .red[visual inspection] to confirm the selected bandwidth’s appropriateness.\n\nRemember that the best bandwidth may vary depending on the specific data and application.\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#bandwidth-selection-2","position":35},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Advantages of KDE"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#advantages-of-kde","position":36},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Advantages of KDE"},"content":"].column[\n\n.bold[Non-parametric]: Does not assume a specific distribution for the data.\n\n.bold[Versatile]: Works with various data types and dimensions.\n\n.bold[Flexible]: Handles complex data structures and multimodal distributions.\n\n.bold[Smoothness]: Produces smooth, continuous density estimates.\n\n.bold[Adaptive]: Bandwidth selection allows for control over smoothing.\n\n.bold[Intuitive interpretation]: Visualization of the density estimate is straightforward.\n\n.bold[Wide availability]: Implemented in many statistical software packages and libraries.\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#advantages-of-kde","position":37},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Disadvantages/ Limitations of KDE"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#disadvantages-limitations-of-kde","position":38},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Disadvantages/ Limitations of KDE"},"content":"].column[\n\n.bold[Bandwidth selection]: Can be challenging and affect the quality of the density estimate.\n\n.bold[Computational complexity]: High-dimensional data can make KDE computationally demanding.\n\n.bold[Boundary bias]: Density estimates can be biased near the boundary of the data.\n\n.bold[Curse of dimensionality]: Performance deteriorates as the dimension of the data increases.\n\n.bold[Sensitivity to outliers]: KDE can be influenced by outliers or data sparsity.\n\n.bold[Interpretation]: Understanding the shape of the density estimate can be subjective.\n\n.bold[Lack of model]: KDE does not provide a parametric model that can be used for further analysis.\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-01-kernel-density-estimation#disadvantages-limitations-of-kde","position":39},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"KDE: Visualizing Data Distribution"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#kde-visualizing-data-distribution","position":40},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"KDE: Visualizing Data Distribution"},"content":".split-50[.column[\n\n].column[\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-01-kernel-density-estimation#kde-visualizing-data-distribution","position":41},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"KDE: Visualizing Data Distribution"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#kde-visualizing-data-distribution-1","position":42},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"KDE: Visualizing Data Distribution"},"content":".split-50[.column[\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#kde-visualizing-data-distribution-1","position":43},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Advanced Topics"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#advanced-topics","position":44},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Advanced Topics"},"content":"Kernel Density Estimation (KDE) has several advanced topics that can be explored for a deeper understanding and more effective application. Here are some of these topics:\n].column[\n\nAdaptive Bandwidth Selection: This involves using .red[different bandwidths for different regions] of the data space, based on local density or other data characteristics. It can improve KDE performance for datasets with varying density and complex structures.\n\nMultivariate KDE: Extending KDE to multivariate data .red[involves selecting appropriate kernel functions and bandwidths in multiple dimensions.] Handling the curse of dimensionality and the increased computational complexity are important considerations.\n\nKernel Choice: .red[Different kernel functions] can yield different KDE results, and understanding their properties, such as order, continuity, and bias, can guide kernel selection for specific applications.\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#advanced-topics","position":45},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Advanced Topics"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#advanced-topics-1","position":46},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Advanced Topics"},"content":"Kernel Density Estimation (KDE) has several advanced topics that can be explored for a deeper understanding and more effective application. Here are some of these topics:\n].column[\n4) Density Derivatives: Estimating density derivatives (e.g., gradient, Hessian) using KDE can provide additional insights into the data, such as .red[local maxima and saddle points]. This is particularly useful in optimization and feature detection tasks.\n\nKernel Smoothing in Regression: KDE can be used for nonparametric regression by .red[locally smoothing] the data using kernel functions. Nadaraya-Watson and Local Linear Regression are examples of such methods.\n\nAdvanced KDE Algorithms: Techniques like Fast Fourier Transform (FFT) or K-D Trees can .red[speed up] KDE computations for large datasets, while advanced KDE methods like Variable Kernel Density Estimation (VKDE) or Bayesian KDE can .red[handle complex data structures and uncertainty] in the density estimates.\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-01-kernel-density-estimation#advanced-topics-1","position":47},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Summary"},"type":"lvl2","url":"/sec-05-01-kernel-density-estimation#summary","position":48},{"hierarchy":{"lvl1":"Kernel Density Estimation","lvl2":"Summary"},"content":"].column[\n\nKernel Density Estimation (KDE) is a non-parametric method to .red[estimate the probability density function] of continuous random variables.\n\nKDE works by .red[summing kernel functions centered at each data point], resulting in a smooth density estimate.\n\nKey components of KDE include selecting an .red[appropriate kernel function and bandwidth].\n\nKDE has numerous .red[applications], such as data visualization, outlier detection, and data comparison.\n\nAdvanced topics in KDE include .rd[adaptive bandwidth selection], multivariate KDE, and handling the .red[curse of dimensionality].\n]]","type":"content","url":"/sec-05-01-kernel-density-estimation#summary","position":49},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation"},"type":"lvl1","url":"/sec-05-02-spatial-kde","position":0},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation"},"content":"\n\n.square[Introduction .dot[] Example .dot[] Bandwidth .dot[] Kernel Function .dot[] Edge-effect .dot[] Advanced Techniques]\n\n.headnote.square.bold.x-large[Point Pattern II]\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-05-02-spatial-kde","position":1},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial Kernel Density Estimation"},"type":"lvl2","url":"/sec-05-02-spatial-kde#spatial-kernel-density-estimation","position":2},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial Kernel Density Estimation"},"content":"Spatial Kernel Density Estimation (Spatial KDE) is an extension of KDE for analyzing geospatial data.\n\nIt works with the same approach as KDE, i.e., selecting a Kernel Function, choosing a bandwidth, and calculate the density for every spatial sampling unit (grid cells).\n\n.xkcd[How every event points contribute to the density of each sample grid cell?]\n].column[\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-02-spatial-kde#spatial-kernel-density-estimation","position":3},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial Kernel Density Estimation"},"type":"lvl2","url":"/sec-05-02-spatial-kde#spatial-kernel-density-estimation-1","position":4},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial Kernel Density Estimation"},"content":"\n\n.footnote.small[Bailey and Gatrell 1995. Interactive Spatial Data Analysis. \n\nAnderson 2009]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-02-spatial-kde#spatial-kernel-density-estimation-1","position":5},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial Kernel Density Estimation"},"type":"lvl2","url":"/sec-05-02-spatial-kde#spatial-kernel-density-estimation-2","position":6},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial Kernel Density Estimation"},"content":".square[The sum of 2-D kernel functions. ]\n].column[\n\n\n.footnote-left.small[\n\nLevine 2013. Crimestat 4]\n]]\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/sec-05-02-spatial-kde#spatial-kernel-density-estimation-2","position":7},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial KDE vs. aggregated count by cell"},"type":"lvl2","url":"/sec-05-02-spatial-kde#spatial-kde-vs-aggregated-count-by-cell","position":8},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial KDE vs. aggregated count by cell"},"content":"When using a grid-based approach for spatial data analysis, counting points in each cell might only reveal random distribution if the grid cell size is too small (the lower figure). In such cases, the counting result is not useful in presenting the spatial pattern.\n\nDensity estimation techniques, such as spatial KDE (middle figure), can help identify the spatial structure and trends within the data. These methods can effectively highlight areas with high concentration versus low concentration, as well as capture the changing rates and other essential aspects of spatial patterns.\n].column[\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-02-spatial-kde#spatial-kde-vs-aggregated-count-by-cell","position":9},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Health care POI @ Queenstown"},"type":"lvl2","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-health-care-poi-queenstown","position":10},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Health care POI @ Queenstown"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-health-care-poi-queenstown","position":11},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Commercial POI @ Queenstown"},"type":"lvl2","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-commercial-poi-queenstown","position":12},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Commercial POI @ Queenstown"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-commercial-poi-queenstown","position":13},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Education POI @ Queenstown"},"type":"lvl2","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-education-poi-queenstown","position":14},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Education POI @ Queenstown"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-education-poi-queenstown","position":15},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Food POI @ Queenstown"},"type":"lvl2","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-food-poi-queenstown","position":16},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Food POI @ Queenstown"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-food-poi-queenstown","position":17},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Beverages POI @ Queenstown"},"type":"lvl2","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-beverages-poi-queenstown","position":18},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Beverages POI @ Queenstown"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-beverages-poi-queenstown","position":19},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Outdoor Activity POI @ Queenstown"},"type":"lvl2","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-outdoor-activity-poi-queenstown","position":20},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Example of Spatial KDE - Outdoor Activity POI @ Queenstown"},"content":"\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-02-spatial-kde#example-of-spatial-kde-outdoor-activity-poi-queenstown","position":21},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Bandwidth Selection in Spatial KDE"},"type":"lvl2","url":"/sec-05-02-spatial-kde#bandwidth-selection-in-spatial-kde","position":22},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Bandwidth Selection in Spatial KDE"},"content":"With smaller bandwidth values, the density estimates are more localized and highlight finer details of the data distribution, which could be similar to the distribution of aggregated count by cell---seems random. As the bandwidth increases, the KDE maps start to emphasize broader spatial patterns and general trends in the data. This smoother representation of density may help identify larger-scale features and regional differences while potentially .red[overlooking local variations] in the data.\n\n].column[\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-02-spatial-kde#bandwidth-selection-in-spatial-kde","position":23},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Bandwidth Selection in Spatial KDE"},"type":"lvl2","url":"/sec-05-02-spatial-kde#bandwidth-selection-in-spatial-kde-1","position":24},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Bandwidth Selection in Spatial KDE"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-02-spatial-kde#bandwidth-selection-in-spatial-kde-1","position":25},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial Kernel Functions"},"type":"lvl2","url":"/sec-05-02-spatial-kde#spatial-kernel-functions","position":26},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Spatial Kernel Functions"},"content":"(a) Gaussian\n(b) Epanechnikov\n(c) Triangular\n(d) Uniform\n\nAll kernel functions have a rounded base shape.\n].column[\n\n\n.footnote-right.small[\n\nFouedjio et al. 2017]\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-02-spatial-kde#spatial-kernel-functions","position":27},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Kernel Functions for Spatial KDE"},"type":"lvl2","url":"/sec-05-02-spatial-kde#kernel-functions-for-spatial-kde","position":28},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Kernel Functions for Spatial KDE"},"content":"\n\nExamples and differences between threee Kernel Functions using the same dataset.\n\nclass: center, middle\n\n.headnote.large.bold[Visualizing KDE]\n\n.footnote.small.square[\n\nChin 2023]\n\nclass: center, middle\n\n.headnote.large.bold[Visualizing KDE]\n\n.footnote.small.square[\n\nXia et al. 2024]\n\nclass: center, middle\n\n.headnote.large.bold[Visualizing KDE]\n\n.footnote.small.square[\n\nWheeler 2014]\n\nclass: center, middle\n\n.headnote.large.bold[Visualizing KDE]\n\n.footnote-right.small.square[\n\nYang et al. 2019]\n\nclass: center, middle\n\n.headnote.large.bold[Visualizing KDE]\n\n.footnote.small.square[\n\nKuo et al. 2012]\n\nclass: center, middle\n\n.headnote.large.bold[Visualizing KDE]\n\n.footnote.small.square[\n\nLevine 2013]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-02-spatial-kde#kernel-functions-for-spatial-kde","position":29},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Edge Effects"},"type":"lvl2","url":"/sec-05-02-spatial-kde#edge-effects","position":30},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Edge Effects"},"content":"Edge effects in KDE refer to the bias and inaccuracy in density estimates near the boundary of the study area due to the lack of data beyond the edges.\n].column[\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-02-spatial-kde#edge-effects","position":31},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Edge Effects"},"type":"lvl2","url":"/sec-05-02-spatial-kde#edge-effects-1","position":32},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Edge Effects"},"content":".bold[Methods addressing edge effects]\n].column[\n\n.bold[Reflection Method]: Mirror the data points across the boundary, creating a new set of points outside the study area. Apply KDE to this extended dataset, ensuring the density estimates near the boundary are influenced by the reflected points, reducing edge effects.\n\n.bold[Gaussian Truncation]: Truncate the Gaussian kernel function used in KDE at the boundary of the study area. This method eliminates the need to make assumptions about the data beyond the boundary, as the truncated kernel function only considers the points within the study area.\n\n.bold[Adaptive Kernel Methods]: Utilize adaptive kernel functions, where the kernel shape and bandwidth vary based on the local density of points. By adapting to the local density, these methods can help reduce edge effects and produce more accurate density estimates near the boundary.\n\n.bold[Boundary Correction Methods]: Apply boundary correction methods, such as the bias-correction method proposed by Chen and Firth (2000), which adjusts the density estimates near the boundary to compensate for edge effects.\n\n.bold[Expansion of the Study Area]: Expand the study area beyond the original boundary, ensuring that the kernel function extends beyond the actual area of interest. This approach eliminates edge effects but may introduce uncertainty in density estimates for areas without data.\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-02-spatial-kde#edge-effects-1","position":33},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Advanced Techniques and Applications"},"type":"lvl2","url":"/sec-05-02-spatial-kde#advanced-techniques-and-applications","position":34},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Advanced Techniques and Applications"},"content":".red[Dual KDE]\n\nSpace-time KDE\n\nNetwork KDE\n].column[\n\n.footnote-left.square[\n\nJansenberger & Staufer-Steinnocher 2004]\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-02-spatial-kde#advanced-techniques-and-applications","position":35},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Advanced Techniques and Applications"},"type":"lvl2","url":"/sec-05-02-spatial-kde#advanced-techniques-and-applications-1","position":36},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Advanced Techniques and Applications"},"content":"Dual KDE\n\n.red[Space-time KDE]\n\nNetwork KDE\n].column[\n\n.footnote.square[\n\nHu et al. 2018]\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-02-spatial-kde#advanced-techniques-and-applications-1","position":37},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Advanced Techniques and Applications"},"type":"lvl2","url":"/sec-05-02-spatial-kde#advanced-techniques-and-applications-2","position":38},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Advanced Techniques and Applications"},"content":"Dual KDE\n\nSpace-time KDE\n\n.red[Network KDE]\n].column[\n\n.footnote.square[\n\nTang et al. 2016]\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-02-spatial-kde#advanced-techniques-and-applications-2","position":39},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Summary"},"type":"lvl2","url":"/sec-05-02-spatial-kde#summary","position":40},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Summary"},"content":"].column[\n\n.bold[Introduction]: Spatial KDE is an extension of KDE for analyzing spatial data, focusing on patterns, trends, and density variations within a geographic context.\n\n.bold[Applications]: Spatial KDE is widely used in fields like ecology, crime analysis, epidemiology, and urban planning to identify hot spots, clusters, and spatial relationships.\n\n.bold[Spatial Adaptations]: Spatial KDE adapts traditional KDE by incorporating techniques to handle edge effects and the specific characteristics of spatial data.\n\n.bold[Kernel Functions]: Different kernel functions can be used in spatial KDE to accommodate various data distributions and spatial patterns, ensuring accurate density estimation.\n\n.bold[Bandwidth Selection]: Choosing an appropriate bandwidth for spatial KDE is crucial for accurate density estimation and pattern identification. Methods include rule-of-thumb, cross-validation, and plug-in approaches.\n\n.bold[Visualization]: Spatial KDE results are typically visualized as heatmaps, contour plots, or 3D surfaces to facilitate interpretation and communication of spatial patterns and trends.\n]]","type":"content","url":"/sec-05-02-spatial-kde#summary","position":41},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Capturing Local Point Patterns with Spatial KDE"},"type":"lvl2","url":"/sec-05-02-spatial-kde#capturing-local-point-patterns-with-spatial-kde","position":42},{"hierarchy":{"lvl1":"Spatial Kernel Density Estimation","lvl2":"Capturing Local Point Patterns with Spatial KDE"},"content":"].column[\n\nSpatial KDE is an effective method for capturing and visualizing local point patterns in spatial data.\n\nBy estimating density using a moving kernel window, spatial KDE highlights areas of high and low concentration within the study area.\n\nBandwidth selection plays a crucial role in capturing local point patterns, as it controls the level of smoothing and the size of the local neighborhood considered in the density estimate.\n\nSmaller bandwidths capture finer details and local variations, while larger bandwidths highlight broader spatial trends and regional differences.\n\nVisualizing spatial KDE results as heatmaps or contour plots allows for easy identification of hotspots, clusters, and spatial relationships within the data.\n\nSpatial KDE does not provide related statistical tests to assess the significance level of the identified patterns or differences between point patterns. Additional statistical methods may be required for a more comprehensive analysis.\n]]","type":"content","url":"/sec-05-02-spatial-kde#capturing-local-point-patterns-with-spatial-kde","position":43},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering"},"type":"lvl1","url":"/sec-05-03-spatial-clustering","position":0},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering"},"content":"\n\n.square[Clustering .dot[] 2D Space]\n\n.headnote.square.bold.x-large[Point Pattern III]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-05-03-spatial-clustering","position":1},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is Clustering"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#what-is-clustering","position":2},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is Clustering"},"content":"].column[\n\n.underline[Unsupervised] learning\n\nRequires data, but .underline[no labels]\n\nlabelled data is the ‘ground truth’\n\nsupervised learning aim to model the relationship in data (i.e., data-driven) and eventually help to predict, thus need the ‘ground truth’.\n\nFocus on .underline[detecting patterns] e.g. in\n\nGroup emails or search results\n\nCustomer shopping patterns\n\nRegions of images\n\nGeospatial Point Patterns\n\nUseful when don’t know what you’re looking for\n\nUseful when you’re not sure what patterns or groups exist in your data.\n\nHowever, you may remain don’t know what you’re looking at\n\nYou may still need to interpret and analyze the resulting clusters to understand their meaning and significance.\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-03-spatial-clustering#what-is-clustering","position":3},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Identifying breeds of dogs"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-identifying-breeds-of-dogs","position":4},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Identifying breeds of dogs"},"content":"\n\nIdentify dogs that look similar from the photos.\n\n.footnote-left.small[Source: \n\nSolving the mystery of my dog’s breed with ML]\n\nclass: center, middle","type":"content","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-identifying-breeds-of-dogs","position":5},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Identifying individual pet"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-identifying-individual-pet","position":6},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Identifying individual pet"},"content":"\n\nLooking for the same person or pet in the photo gallery.\n\n.footnote-left.small[Image Source: \n\niOS 17 Photos App Recognizes Your Pets]\n\nclass: center, middle","type":"content","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-identifying-individual-pet","position":7},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances","position":8},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"content":"\n\nThe data points.\n\nclass: center, middle","type":"content","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances","position":9},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-1","position":10},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"content":"\n\n2 big groups.\n\nclass: center, middle","type":"content","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-1","position":11},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-2","position":12},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"content":"\n\nAnother 2 big groups.\n\nclass: center, middle","type":"content","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-2","position":13},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-3","position":14},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"content":"\n\nThose on the left split into 2 small groups.\n\nclass: center, middle","type":"content","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-3","position":15},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-4","position":16},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"content":"\n\nThose on the right split into 2 small groups.\n\nclass: center, middle","type":"content","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-4","position":17},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-5","position":18},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Basic idea of clustering: Group together similar/near instances"},"content":"\n\n4 small groups.\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-03-spatial-clustering#basic-idea-of-clustering-group-together-similar-near-instances-5","position":19},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What could ‘similar’ or ‘near’ mean?"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#what-could-similar-or-near-mean","position":20},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What could ‘similar’ or ‘near’ mean?"},"content":"The two distances assume the value ranges are equal (similar) among dimensions. (Equal aspect)\n].column[\nHow to measure similarity/dissimilarity?\n\nEuclidean distance\nd_{a,b} = \\sqrt{|x_a-x_b|^2+|y_a-y_b|^2}\n\nManhattan distance\nd_{a,b} = |x_a-x_b|+|y_a-y_b|\n\nOther ways to define ‘distance’ between data points (instances)\n\nMore than 2 dimensions\n\n.square[The clustering results are .bold[highly dependent] on the similarity metric (or distance measure) chosen to evaluate the proximity between data points within the cluster analysis.]\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-03-spatial-clustering#what-could-similar-or-near-mean","position":21},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering","position":22},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"content":"].column[\n\n.bold[On Spatial Point Patterns]:\nThe 2 dimensions are X and Y\n\n.bold[On Attribute-based Spatial Clustering]:\nThe clustering is run on some attributes fields rather than its X & Y locations\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering","position":23},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering-1","position":24},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"content":"","type":"content","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering-1","position":25},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl3":"On Spatial Point Patterns","lvl2":"What is spatial clustering?"},"type":"lvl3","url":"/sec-05-03-spatial-clustering#on-spatial-point-patterns","position":26},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl3":"On Spatial Point Patterns","lvl2":"What is spatial clustering?"},"content":"].column[\n\n.bold[Animal habitats]: Analyze GPS data from animal tracking devices to identify clusters of locations where animals spend most of their time. This can help researchers better understand .red[habitat preferences and territorial behaviors].\n\n.bold[Activity spaces]: Analyze GPS data from human participants or mobile devices to .red[cluster locations where individuals spend significant amounts of time], such as home, work, or recreational areas. This can help urban planners and researchers understand human movement patterns and inform the design of more efficient and livable urban spaces.\n\n.bold[Traffic accidents]: Cluster the locations of traffic accidents in a city based on their spatial coordinates to .red[identify accident hotspots]. This information can be used to improve road safety and inform infrastructure planning.\n\n.bold[Crime hotspots]: Cluster crime incidents based on their geographical locations to identify .red[areas with high concentrations of criminal activity]. This information can be used by law enforcement agencies to allocate resources more effectively, develop targeted crime prevention strategies, and improve public safety.\n\n.bold[Cell tower coverage]: Group cell towers based on their spatial distribution to determine .red[regions with optimal coverage] and identify areas where additional towers may be needed to improve network performance.\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-03-spatial-clustering#on-spatial-point-patterns","position":27},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering-2","position":28},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"content":"","type":"content","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering-2","position":29},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl3":"On Spatial Point Patterns","lvl2":"What is spatial clustering?"},"type":"lvl3","url":"/sec-05-03-spatial-clustering#on-spatial-point-patterns-1","position":30},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl3":"On Spatial Point Patterns","lvl2":"What is spatial clustering?"},"content":"Using the GPS records of a person moving within a neighborhood to detect clusters (with noises) and identify the place where the participant had visited by follow-up interview and manual checking.\n\n.footnote-left[\n\nFeng et al. 2024.]\n].column[\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-03-spatial-clustering#on-spatial-point-patterns-1","position":31},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering-3","position":32},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"content":"","type":"content","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering-3","position":33},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl3":"On Attribute-based Spatial Clustering","lvl2":"What is spatial clustering?"},"type":"lvl3","url":"/sec-05-03-spatial-clustering#on-attribute-based-spatial-clustering","position":34},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl3":"On Attribute-based Spatial Clustering","lvl2":"What is spatial clustering?"},"content":"].column[\n\n.bold[Real estate analysis]: Use attributes such as property value, lot size, and property age to cluster homes in a neighborhood. This can help real estate agents and potential buyers identify .red[areas with similar property characteristics].\n\n.bold[Environmental monitoring]: Cluster air quality monitoring stations based on attributes like pollutant concentrations, temperature, and humidity. This can help identify .red[areas with similar air quality profiles] and inform pollution control strategies.\n\n.bold[Demographic analysis]: Group census tracts or neighborhoods based on attributes such as population density, age distribution, and income levels to identify .red[areas with similar demographics]. This information can be valuable for urban planning, social services, and targeted marketing.\n\n.bold[Urban function analysis:] Cluster POIs within a city based on their types (e.g., retail, entertainment, healthcare, education) to identify .red[areas with distinct urban functions and land use patterns]. This can help urban planners and decision-makers better understand the distribution of various amenities and services within the city and inform urban development strategies.\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-03-spatial-clustering#on-attribute-based-spatial-clustering","position":35},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering-4","position":36},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"What is spatial clustering?"},"content":"","type":"content","url":"/sec-05-03-spatial-clustering#what-is-spatial-clustering-4","position":37},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl3":"On Attribute-based Spatial Clustering","lvl2":"What is spatial clustering?"},"type":"lvl3","url":"/sec-05-03-spatial-clustering#on-attribute-based-spatial-clustering-1","position":38},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl3":"On Attribute-based Spatial Clustering","lvl2":"What is spatial clustering?"},"content":"The study run clustering on the kernel density of various GPS types and identify clusters with similar density of the different POI types.\n].column[\n\n.footnote-right[\n\nChin et al. 2023]\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-03-spatial-clustering#on-attribute-based-spatial-clustering-1","position":39},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Types of clustering methods"},"type":"lvl2","url":"/sec-05-03-spatial-clustering#types-of-clustering-methods","position":40},{"hierarchy":{"lvl1":"Clustering & Spatial Clustering","lvl2":"Types of clustering methods"},"content":"].column[\n.bold[Partitioning]:\n\n.red[Central Tendency]: focus on the ‘center’ of the clusters, e.g., k-means, k-medoids\n\n.red[Density-based]: focus on the ‘density’ of the data points, e.g., DBSCAN\n\n.bold[Hierarchical Clustering]\n\n.red[Agglomerative] (bottom-up): Starts with each point as a separate cluster, then merges pairs of clusters until all points are in a single cluster.\n\n.red[Divisive] (top-down): Starts with all points in one cluster and recursively splits clusters until each point is in its own cluster.\n]]","type":"content","url":"/sec-05-03-spatial-clustering#types-of-clustering-methods","position":41},{"hierarchy":{"lvl1":"k-means clustering"},"type":"lvl1","url":"/sec-05-04-k-means-clustering","position":0},{"hierarchy":{"lvl1":"k-means clustering"},"content":"\n\n.square[Steps .dot[] The k .dot[] Applications ]\n\n.headnote.square.bold.x-large[Point Pattern III]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering","position":1},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"What is k-means Clustering?"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#what-is-k-means-clustering","position":2},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"What is k-means Clustering?"},"content":"].column[\n\n.bold[Definition]:\nk-means is an unsupervised machine learning algorithm used for clustering data points into .red[k distinct, non-overlapping groups] based on their similarities and differences.\n\n.bold[Objective]:\nThe main goal of k-means is to minimize the within-cluster sum of squares (WCSS), which represents the .red[total squared distance (euclidean distance) between data points and their nearest cluster centroid].\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#what-is-k-means-clustering","position":3},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process","position":4},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"content":"].column[\n\n.bold[Choose k]: Select the number of clusters (k) to generate.\n\n.bold[Initialize centroids]: Randomly select k initial centroids from the dataset or use other initialization methods like k-means++.\n\n.bold[Assign points to clusters]: Assign each data point to the cluster with the nearest centroid.\n\n.bold[Update centroids]: Recalculate the centroid positions by taking the mean of all data points belonging to each cluster.\n\n.bold[Repeat]: Repeat steps 3 and 4 until convergence, i.e., no further changes in cluster assignments or centroid positions occur.\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process","position":5},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process-1","position":6},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"content":".red.bold[The data point]\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process-1","position":7},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process-2","position":8},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"content":".red.bold[The Steps]\n\nInitialize with random centroids\n\nGet the nearest neighbors, and calculate the new mean centers\n\nMove the centers to the mean centers\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process-2","position":9},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process-3","position":10},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"content":".red.bold[The Steps]\n\nRe-calculate distance and find nearest neighbors\n\nRe-Calculate new mean centers and move\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process-3","position":11},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process-4","position":12},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering Steps & Process"},"content":".red.bold[The Steps]\n\nThe location of new and previous centers overlapped. Hence, stops.\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-steps-process-4","position":13},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters","position":14},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters","position":15},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-1","position":16},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-1","position":17},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-2","position":18},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-2","position":19},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-3","position":20},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":".xkcd[Note how the blue mean center moved.]\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-3","position":21},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-4","position":22},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-4","position":23},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-5","position":24},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-5","position":25},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-6","position":26},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-6","position":27},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-7","position":28},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-7","position":29},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-8","position":30},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-8","position":31},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-9","position":32},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-9","position":33},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-10","position":34},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-10","position":35},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-11","position":36},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-11","position":37},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-12","position":38},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-12","position":39},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-13","position":40},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-13","position":41},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-14","position":42},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-14","position":43},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-15","position":44},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-15","position":45},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-16","position":46},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":"].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-16","position":47},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-17","position":48},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"k-means Clustering: Example with 7 clusters"},"content":".xkcd[There is a cluster divided into two clusters, and two (at the bottom right) clusters merged as one. ]\n\n].column[\n\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#k-means-clustering-example-with-7-clusters-17","position":49},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"Parameters and Initialization"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#parameters-and-initialization","position":50},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"Parameters and Initialization"},"content":"].column[\n\nHow do we know the number of clusters (i.e., the k in k-means)?\n\nHow to initialize mean centers’ locations?\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#parameters-and-initialization","position":51},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How to select k"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#how-to-select-k","position":52},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How to select k"},"content":" .square[[Wikipedia](https://en.wikipedia.org/wiki/File:DataClustering_ElbowCriterion.JPG)] ].column[\n\n.bold[Elbow Method]: Plot the explained variation (or distortion) as a function of the number of clusters, and choose the elbow point as the number of clusters to use. The elbow point is the point of diminishing returns, where the additional gain in reducing the distortion starts to decrease significantly as more clusters are added. For the final iteration (i), the explained variation (EV^i) can be calculated by the distance between each point (k) and the cluster they were assigned (C_j^i).D_{j}^i = \\sum (|x_k - \\mu_j^i|^2)\n\nwhere {x_{k} \\in C_j^i}D^i = ∑_{j=1}^k D_j^iEV^i = D^0 - D^i\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#how-to-select-k","position":53},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How to select k"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#how-to-select-k-1","position":54},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How to select k"},"content":".bold[Silhouette Analysis]: Calculate the average silhouette score (Si) for different values of k and choose the value that yields the highest score. The silhouette score measures the cohesiveness of datapoints within a cluster compared to their closeness to datapoints in other clusters, with values closer to 1 indicating well-defined clusters.\n\n].column[Si = (b_i - a_i) / \\text{max}(a_i, b_i)\n\na_i is the average distance between point i and all other points in its own cluster:a_i = \\sum \\frac{(d(x_i, x_j))}{|C_i|}\n\nwhere, x_j ∈ C_i\n\nb_i is the lowest average distance between point i and all points in any other cluster:b_i = \\text{min} ∑ \\frac{(d(x_i, x_j))}{|C_j|}\n\nwhere, x_j ∈ C_j and j\\neq i\n\nNote that the Silhouette Coefficient ranges between -1 and 1, with higher values indicating better clustering.\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#how-to-select-k-1","position":55},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How to select k"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#how-to-select-k-2","position":56},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How to select k"},"content":".bold[Silhouette Analysis]\n\n].column[\n\nWikipedia\n\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#how-to-select-k-2","position":57},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How to select k"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#how-to-select-k-3","position":58},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How to select k"},"content":"].column[\n\n.bold[Gap Statistic]: Compare the total within-cluster variation for different values of k and choose the value that maximizes the gap statistic, which is the difference between the observed and expected within-cluster variation.\n\n.bold[Domain Knowledge]: Rely on your knowledge of the dataset and the problem domain to choose a value for k that makes sense in the context of your analysis.\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-04-k-means-clustering#how-to-select-k-3","position":59},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How set the initial position of the mean centers?"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#how-set-the-initial-position-of-the-mean-centers","position":60},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"How set the initial position of the mean centers?"},"content":"].column[\n\n.bold[Random Initialization]: Randomly select k points from the dataset to serve as the initial centers. This method is simple but may lead to suboptimal clusters due to its unpredictability.\n\n.bold[k-means++]: Choose the first center randomly from the dataset. Then, for each subsequent center, choose a point from the dataset with a probability proportional to its squared distance from the nearest existing center. This method tends to provide better clustering results than random initialization.\n\n.bold[Furthest Point]: Calculate the distances between all pairs of points in the dataset, then choose the two points with the largest distance as the first two centers. For each subsequent center, select the point that maximizes the minimum distance to the previously chosen centers.\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-04-k-means-clustering#how-set-the-initial-position-of-the-mean-centers","position":61},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"Properties of k-means clustering"},"type":"lvl2","url":"/sec-05-04-k-means-clustering#properties-of-k-means-clustering","position":62},{"hierarchy":{"lvl1":"k-means clustering","lvl2":"Properties of k-means clustering"},"content":"].column[\n\nGuaranteed to\tconverge in a finite number of iterations.\n\nRunning time per iteration:\n\nassign data points to closest cluster center: O(KN) time\n\nchange the cluster center to average of its assigned points: O(N)\n\nSensitive to outliers since an object with an extremely large value may substantially move a center.\n]]","type":"content","url":"/sec-05-04-k-means-clustering#properties-of-k-means-clustering","position":63},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)"},"type":"lvl1","url":"/sec-05-05-dbscan","position":0},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)"},"content":"\n\n.square[Key Concepts .dot[] Parameters .dot[] Applications]\n\n.headnote.square.bold.x-large[Point Pattern III]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-05-05-dbscan","position":1},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)"},"type":"lvl2","url":"/sec-05-05-dbscan#density-based-spatial-clustering-of-applications-with-noise-dbscan","position":2},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)"},"content":"].column[\n\nThe algorithm finds dense areas and expands these recursively to find .red[dense arbitrarily shaped clusters].\n\nTwo main parameters to DBSCAN are ‘Epsilon (ε)’ and ‘minPoints’.\n\n‘Epsilon (ε, or Eps)’ defines radius of the ‘neighborhood region’ and\n\n‘minPoints’ defines the minimum number of points that should be contained within that neighborhood to be considered as ‘high density’.\n\nThe ‘.red[density]’ refers to the number of points within Eps, which should be larger than minPoints.\n\nSince it .red[has a concept of noise], it works well even with noisy datasets.\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-05-dbscan#density-based-spatial-clustering-of-applications-with-noise-dbscan","position":3},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Arbitrary shape clusters"},"type":"lvl2","url":"/sec-05-05-dbscan#arbitrary-shape-clusters","position":4},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Arbitrary shape clusters"},"content":"\n\nclass: left, middle","type":"content","url":"/sec-05-05-dbscan#arbitrary-shape-clusters","position":5},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Key concepts"},"type":"lvl2","url":"/sec-05-05-dbscan#key-concepts","position":6},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Key concepts"},"content":".split-40[.column[\n\nminPoint = 4\n].column[\n\n.bold[Epsilon neighborhood] (Nε): set of all points within a distance ‘ε’.\n\n.bold[Core point]: A point that has at least ‘minPoint’ (including itself) points within it’s Nε.\n\n.bold[Directly Density Reachable (DDR)]: A point q is .underline[directly density reachable] from a point p if .red[p is core point] and q ∈ Nε of p.\n\n.bold[Density Reachable (DR)]: Two points are .underline[DR] if there is .red[a chain of DDR points that link] these two points.\n\n.bold[Border Point]: Point that are DDR but not a core point.\n\n.bold[Noise] : Points that could not reach to any core point through a chain of DDR points.\n\n]]\n\nclass: left, middle","type":"content","url":"/sec-05-05-dbscan#key-concepts","position":7},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Key concepts"},"type":"lvl2","url":"/sec-05-05-dbscan#key-concepts-1","position":8},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Key concepts"},"content":".split-40[.column[\n\n].column[\n\nLet p be a core point, then every point in its Epsilon neighborhood is said to be .red[directly density-reachable] from p.\n\nA point p is .red[density-reachable] from a core point q if there is a chain of points p, p1, p2, ..., pn, q.\n\nA point p is .red[density-connected] to a point q if there is a point o such that both, p and q are density-reachable from o.\n\n.bold[Clusters in DBSCAN] are groups of .red[points that are density-connected], meaning that every point within a cluster .red[must be reachable from any other point in the same cluster through a chain of directly density-reachable points], given a specified epsilon (neighborhood radius) and MinPoint (minimum number of points required to form a dense region).\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-05-dbscan#key-concepts-1","position":9},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"The cores, borders, and noises"},"type":"lvl2","url":"/sec-05-05-dbscan#the-cores-borders-and-noises","position":10},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"The cores, borders, and noises"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-05-05-dbscan#the-cores-borders-and-noises","position":11},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"The clusters"},"type":"lvl2","url":"/sec-05-05-dbscan#the-clusters","position":12},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"The clusters"},"content":"\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-05-dbscan#the-clusters","position":13},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Choosing MinPoint"},"type":"lvl2","url":"/sec-05-05-dbscan#choosing-minpoint","position":14},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Choosing MinPoint"},"content":"How many nearby points to form a ‘core’?\n\n].column[\n\n.bold[Domain knowledge]: If you have an understanding of how dense the clusters should be, use it to set MinPoint accordingly.\n\n.bold[Sensitivity analysis]: Experiment with various MinPoint values and evaluate the clustering results based on metrics such as the silhouette score, Calinski-Harabasz index, or your own domain-specific criteria.\n\n.bold[Rule of thumb]: A common rule of thumb (for starting) is to set MinPoint as twice the number of dimensions in your dataset, especially if you don’t have any domain knowledge about the expected density.\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-05-05-dbscan#choosing-minpoint","position":15},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Choosing Epsilon"},"type":"lvl2","url":"/sec-05-05-dbscan#choosing-epsilon","position":16},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Choosing Epsilon"},"content":"(search radius)\n\nHow close is close?\n\n].column[\n\n.bold[Domain knowledge]: If you have prior knowledge about the scale or density of your data, you can use it to set an appropriate value for ε.\n\n.bold[k-distance or k-nearest neighbors]: Calculate the k-distance or k-nearest neighbors for various values of k to understand how the local density changes. Choose ε to capture the desired level of density based on these calculations. .underline[(see next page)]\n\n.bold[Experimentation]: Try different values for ε and observe how the clustering results change. Visualizing the clusters can help you assess their quality.\n]]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-05-05-dbscan#choosing-epsilon","position":17},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Choosing Epsilon"},"type":"lvl2","url":"/sec-05-05-dbscan#choosing-epsilon-1","position":18},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"Choosing Epsilon"},"content":"","type":"content","url":"/sec-05-05-dbscan#choosing-epsilon-1","position":19},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl3":"k-distance or k-nearest neighbors","lvl2":"Choosing Epsilon"},"type":"lvl3","url":"/sec-05-05-dbscan#k-distance-or-k-nearest-neighbors","position":20},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl3":"k-distance or k-nearest neighbors","lvl2":"Choosing Epsilon"},"content":"].column[\n\nThe idea is that for points in a cluster, their kth nearest neighbors are at roughly the same distance.\n\nNoise points have the kth nearest neighbor at farther distance.\n\nSo, plot sorted distance of every point to its kth nearest neighbor (e.g., k=4).\n]]\n\nclass: center, middle","type":"content","url":"/sec-05-05-dbscan#k-distance-or-k-nearest-neighbors","position":21},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"A real-life application"},"type":"lvl2","url":"/sec-05-05-dbscan#a-real-life-application","position":22},{"hierarchy":{"lvl1":"Density-Based Spatial Clustering of Applications with Noise (DBSCAN)","lvl2":"A real-life application"},"content":"\n\nA Modified DBSCAN Clustering Method to Estimate Retail Center Extent. \n\nPavlis et al. 2017","type":"content","url":"/sec-05-05-dbscan#a-real-life-application","position":23},{"hierarchy":{"lvl1":"Visualising Spatial Clusters"},"type":"lvl1","url":"/sec-05-06-visualising-clusters","position":0},{"hierarchy":{"lvl1":"Visualising Spatial Clusters"},"content":"\n\n.headnote.square.bold.x-large[Point Pattern III]\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/sec-05-06-visualising-clusters","position":1},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"type":"lvl2","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters","position":2},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"content":"].column[\n\npoint colors\n\nconvex hull\n\nstandard ellipse\n\nvoronoi polygon\n\nOther\n\nbubble plot\n\nheatmap\n\ncontour map\n]]\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters","position":3},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"type":"lvl2","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters-1","position":4},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"content":".red[point colors]\n\nconvex hull\n\nstandard ellipse\n\nvoronoi polygon\n].column[\n\n]]\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters-1","position":5},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"type":"lvl2","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters-2","position":6},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"content":"point colors\n\n.red[convex hull]\n\nstandard ellipse\n\nvoronoi polygon\n].column[\n\n]]\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters-2","position":7},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"type":"lvl2","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters-3","position":8},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"content":"point colors\n\nconvex hull\n\n.red[standard ellipse]\n\nvoronoi polygon\n].column[\n\n]]\n\nclass: left, middle\n\n.split-50[.column[","type":"content","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters-3","position":9},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"type":"lvl2","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters-4","position":10},{"hierarchy":{"lvl1":"Visualising Spatial Clusters","lvl2":"Visualizing Spatial Clusters"},"content":"point colors\n\nconvex hull\n\nstandard ellipse\n\n.red[voronoi polygon]\n].column[\n\n]]","type":"content","url":"/sec-05-06-visualising-clusters#visualizing-spatial-clusters-4","position":11},{"hierarchy":{"lvl1":"Chapter 5: Areal Pattern"},"type":"lvl1","url":"/chapter-6-areal-pattern","position":0},{"hierarchy":{"lvl1":"Chapter 5: Areal Pattern"},"content":"Objectives of this lecture","type":"content","url":"/chapter-6-areal-pattern","position":1},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation"},"type":"lvl1","url":"/sec-06-01-spatial-autocorrelation","position":0},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation"},"content":"\n\n.square[Autocorrelation .dot[] Spatial Randomness .dot[] Spatial Autocorrelation]\n\n.headnote.square.bold.x-large[Areal Pattern I]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation","position":1},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"What is Autocorrelation"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#what-is-autocorrelation","position":2},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"What is Autocorrelation"},"content":"].column[\n\nThe ‘auto-’ in autocorrelation means .red[‘oneself’]. It is a word ‘autos’ that comes from Greek.\n\nAutocorrelation is a measure of the linear relationship .red[between values of a variable and its own nearby values]. The ‘self’-correlation here refer to the correlation within one variable itself.\n\nTwo common types of autocorrelation:\n\nTemporal: Correlation between values of a variable and its own past or future.\n\nSpatial: Correlation between values of a variable and its own neighbors.\n\nOther types of autocorrelation:\n\nNetwork: between values of a variable and the connected neighbors.\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#what-is-autocorrelation","position":3},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"What is Spatial Randomness"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#what-is-spatial-randomness","position":4},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"What is Spatial Randomness"},"content":"].column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#what-is-spatial-randomness","position":5},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl3":"The null hypothesis","lvl2":"What is Spatial Randomness"},"type":"lvl3","url":"/sec-06-01-spatial-autocorrelation#the-null-hypothesis","position":6},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl3":"The null hypothesis","lvl2":"What is Spatial Randomness"},"content":"Spatial Randomness is the absence of any pattern\n\nSpatial Randomness is not interesting\n\nif rejected, then there is evidence of spatial structure---spatially structured\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#the-null-hypothesis","position":7},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"How to interpret Spatial Randomness"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#how-to-interpret-spatial-randomness","position":8},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"How to interpret Spatial Randomness"},"content":"].column[\n\nthe observed spatial pattern .red[is equally likely] as any other spatial pattern\n\n.red[no structure]\n\nvalues at one location .red[does not depend on] values at other (neighboring) locations\n\nvalue at one location .red[does not tell you anything about] what might be at the nearby locations\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#how-to-interpret-spatial-randomness","position":9},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Operationalizing Spatial Randomness"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#operationalizing-spatial-randomness","position":10},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Operationalizing Spatial Randomness"},"content":"].column[\n\nunder spatial randomness, the location of values may be altered without affecting the information content of the data\n\nrandom permutation or reshuffling of values\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-01-spatial-autocorrelation#operationalizing-spatial-randomness","position":11},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Operationalizing Spatial Randomness"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#operationalizing-spatial-randomness-1","position":12},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Operationalizing Spatial Randomness"},"content":".split-50[.column[\n\nActual Distribution\n].column[\n\nRandom Permutation\n]]\n\n.footnote[\n\nLuc Anselin’s lecture on Spatial Autocorrelation]\n\nclass: center, middle","type":"content","url":"/sec-06-01-spatial-autocorrelation#operationalizing-spatial-randomness-1","position":13},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Random Patterns"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#random-patterns","position":14},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Random Patterns"},"content":" Permutated 3 times\n\n.xkcd[Can you spot the difference?]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#random-patterns","position":15},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Tobler’s first law of geography"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#toblers-first-law-of-geography","position":16},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Tobler’s first law of geography"},"content":".xkcd[How do you define distance?]\n].column[\n\nEverything is related to everything else, but .red.bold[near things] are more related than .red.bold[distant things].\n\nEverything depends on everything else, but closer things more so.\n\nStructures spatial dependence\n\nplaces closer to each other tend to have similar values\n\nvalues of close locations tend to correlated\n\nthe reversed: can we .red[define distance] by observing how things are correlated with each other?\n\nif observations are correlated a lot, they are ‘close’\n\nif they are not correlated, they are ‘far’\n\nImportance of distance decay\n\nDistance measure\n\nSpatial adjacency structure\n\n.red[Using some distance metrics to ‘structure’ the spatial dependence based on ‘distance decay’ characteristics.]\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#toblers-first-law-of-geography","position":17},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"What is Spatial Autocorrelation"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#what-is-spatial-autocorrelation","position":18},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"What is Spatial Autocorrelation"},"content":"].column[\n\n.bold[Rejecting the Null Hypothesis]: rejecting spatial randomness: .red[the observed spatial pattern is not the result of a random process].\n\nAn evidence of Spatial Dependence: values are autocorrelated spatially\n\nAn evidence of Spatial Heterogeneity: the underlying probability is non-stationary\n\n.bold[Positive Spatial Autocorrelation]: .red[similar] values in neighboring locations are found to be more frequent compared to spatial randomness\n\nHigh and High (HH)\n\nLow and Low (LL)\n\n.bold[Negative Spatial Autocorrelation]: .red[dissimilar] values in neighboring locations are found to be more frequent compared to spatial randomness\n\nHigh and Low (HL)\n\nLow and High (LH)\n\n]]\n\nclass: left, middle","type":"content","url":"/sec-06-01-spatial-autocorrelation#what-is-spatial-autocorrelation","position":19},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Spatial Autocorrelation: Global vs. Local"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#spatial-autocorrelation-global-vs-local","position":20},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Spatial Autocorrelation: Global vs. Local"},"content":".split-50[.column[\n.bold[Global Spatial Autocorrelation]:\n\nanalyzing clustering, compared to spatial randomness\n\nmeasures the overall degree of spatial clustering or dispersion for the entire study area.\n\nprovides a single value (e.g., Moran’s I) that summarizes the extent to which the variable exhibits a clustered, dispersed, or random pattern across the entire area.\n\nthe spatial autocorrelation of the entire study area ‘.red[as a whole]’\n].column[\n.bold[Local Spatial Autocorrelation]:\n\nidentifying clusters, compared to spatial randomness\n\ncalculate the p-value for each location for exploring the probability of becoming a local hot-spot/cold-spot\n\nprovides a map (or a series of maps) that shows where the significant hot-spots/cold-spots\n\nuse the location-based spatial autocorrelation characteristics to detect posisble clusters at .red[specific locations]\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#spatial-autocorrelation-global-vs-local","position":21},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Positive Spatial Autocorrelation"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#positive-spatial-autocorrelation","position":22},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Positive Spatial Autocorrelation"},"content":"].column[\n\nImpression of clustering\n\nClumps of similar values\n\n‘Similar’ can be both high (hot-spots) or both low (cold-spots)\n\nhigh values near to each other and\n\nlow values near to each other, at the same time\n\ndifficult to rely on human perception\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-01-spatial-autocorrelation#positive-spatial-autocorrelation","position":23},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Positive Spatial Autocorrelation"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#positive-spatial-autocorrelation-1","position":24},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Positive Spatial Autocorrelation"},"content":"\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#positive-spatial-autocorrelation-1","position":25},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Negative Spatial Autocorrelation"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#negative-spatial-autocorrelation","position":26},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Negative Spatial Autocorrelation"},"content":"].column[\n\ncheckerboard pattern\n\nhigh value is surrounded by low values\n\nlow value is surrounded by high values\n\nalternating values\n\nmore about variability\n\nhard to distinguish from spatial randomness\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-01-spatial-autocorrelation#negative-spatial-autocorrelation","position":27},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Negative Spatial Autocorrelation"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#negative-spatial-autocorrelation-1","position":28},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Negative Spatial Autocorrelation"},"content":"\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-01-spatial-autocorrelation#negative-spatial-autocorrelation-1","position":29},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Methods for testing Spatial Autocorrelation"},"type":"lvl2","url":"/sec-06-01-spatial-autocorrelation#methods-for-testing-spatial-autocorrelation","position":30},{"hierarchy":{"lvl1":"Autocorrelation & Spatial Autocorrelation","lvl2":"Methods for testing Spatial Autocorrelation"},"content":"There are several statistical methods for testing global spatial autocorrelation, which helps determine whether the observed spatial pattern in a dataset deviates significantly from a random pattern.\n].column[\n\n.bold[Moran’s I]: Perhaps the most widely used global spatial autocorrelation measure, Moran’s I statistic evaluates whether the values of a variable are spatially clustered, dispersed, or randomly distributed. Moran’s I ranges from -1 (perfect dispersion) to 1 (perfect clustering), with 0 indicating a random pattern.\n\n.bold[Geary’s C]: Similar to Moran’s I, Geary’s C measures the degree of spatial autocorrelation in a dataset. While Moran’s I focuses on the correlation between a value and its neighboring values, Geary’s C emphasizes the differences between a value and its neighbors. Geary’s C also ranges from 0 (perfect spatial autocorrelation) to 2 (perfect dispersion), with 1 indicating a random pattern.\n\n.bold[Getis-Ord Global G]: The Getis-Ord Global G statistic assesses whether the observed spatial pattern exhibits high-value clusters (hotspots) or low-value clusters (coldspots). It provides a single measure of clustering for the entire study area and can be used alongside Moran’s I or Geary’s C to gain additional insights into the data’s spatial structure.\n\n.bold[Mantel Test]: Originally developed in biology, the Mantel Test is a correlation-based approach that evaluates the relationship between two spatial distance matrices (e.g., geographical and ecological distance matrices). While not strictly a measure of spatial autocorrelation, the Mantel Test can provide valuable insights into the relationship between spatial patterns in different variables.\n]]","type":"content","url":"/sec-06-01-spatial-autocorrelation#methods-for-testing-spatial-autocorrelation","position":31},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation"},"type":"lvl1","url":"/sec-06-02-statistical-spatial-testing","position":0},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation"},"content":"\n\n.square[Test statistics .dot[] Attribute-based Similarities .dot[] Locational-based Similarities]\n\n.headnote.square.bold.x-large[Areal Pattern I]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing","position":1},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"What is a Test Statistics (recap)"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#what-is-a-test-statistics-recap","position":2},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"What is a Test Statistics (recap)"},"content":"].column[\n\na statistic is any value that summarizes characteristics of a distribution\n\na test statistics calculated from the data and compared to a reference distribution\n\nhow likely is the value if it had occurrred under the null hypothesis (spatial randomness)\n\nwhen unlikely (low p-value) the null hypothesis is rejected\n]]\n\nclass: left, middle\n.split-50[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#what-is-a-test-statistics-recap","position":3},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Testing NNA (recap)"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#testing-nna-recap","position":4},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Testing NNA (recap)"},"content":"In week 4, we talked about nearest neighbor analysis and how to test the significant levels of the NNA (index).\n\nThe main idea is same, generate a distribution of ‘spatial randomness’ by permutation (reshuffling values). Then, compare the observed value (calculated from data) to the distribution and calculate p-value (probability of being wrong to reject H0).\n\nA significant positive Moran’s I value indicates a positive spatial autocorrelation. A significant negative Moran’s I value indicates a negative spatial autocorrelation.\n].column[\n\n\n]]\n\nclass: left, middle","type":"content","url":"/sec-06-02-statistical-spatial-testing#testing-nna-recap","position":5},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Spatial Autocorrelation Statistics"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#spatial-autocorrelation-statistics","position":6},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Spatial Autocorrelation Statistics"},"content":"Spatial Autocorrelation Statistics captures both .red[attribute similarity] and .red[locational similarity]\n\n.split-50[.column[\n.bold[Attribute similarity]:\n\n.red[how close are the values]\n\nmeasurements of (dis)similarities between values\n\nsquared differences: (y_i-y_j)^2\n\nabsolute differences: |y_i-y_j|\n\n].column[\n.bold[Locational similarity]:\n\n.red[how close are the locations]\n\nrelationship of neighborhood between locations\n\ndistance-based metrics (Euclidean, Manhattan)\n\nadjacency-based spatial weights (rook, queen)\n\nnetwork-based spatial weights\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-02-statistical-spatial-testing#spatial-autocorrelation-statistics","position":7},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Adjacency-based spatial weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#adjacency-based-spatial-weights","position":8},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Adjacency-based spatial weights"},"content":"Spatial relationships based on shared border (a.k.a. rook contiguity). Links on the right show the neighborhood relationship.\n.split-50[.column[\n\n].column[\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-02-statistical-spatial-testing#adjacency-based-spatial-weights","position":9},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Adjacency-based spatial weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#adjacency-based-spatial-weights-1","position":10},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Adjacency-based spatial weights"},"content":"Spatial relationships based on shared border (a.k.a. rook contiguity). Links on the left show the neighborhood relationship and the matrix on the right shows the adjacency-matrix / neighborhood matrix.\n.split-50[.column[\n\n].column[\n$$\n\\text{W} =\\begin{bmatrix}\n0 & 1 & 0 & 1 & 1 & 0 \\\\\\\\\n1 & 0 & 0 & 1 & 1 & 0 \\\\\\\\\n0 & 0 & 0 & 0 & 1 & 1 \\\\\\\\\n1 & 1 & 0 & 0 & 1 & 0 \\\\\\\\\n1 & 1 & 1 & 1 & 0 & 0 \\\\\\\\\n0 & 0 & 1 & 0 & 0 & 0\n\\end{bmatrix}\n\n$$\n]]\n\nclass: left, middle\n.split-50[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#adjacency-based-spatial-weights-1","position":11},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Spatial Contiguity"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#spatial-contiguity","position":12},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Spatial Contiguity"},"content":"A regular grid,\n\nRook (share edge only) \n\nbishop (share point only) \n\nqueen (share edge and point) \n\nHigher levels contiguity can be done by adding second, third, etc. outer ring of neighborhoods.\n\n].column[\n\n]]\n\nclass: left, middle\n.split-50[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#spatial-contiguity","position":13},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Rook and Queen Contiguity"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#rook-and-queen-contiguity","position":14},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Rook and Queen Contiguity"},"content":"Top: Based on rook contiguity, the Chong Boon Subzone has 4 neighboring subzones.\n\nBottom: Based on queen contiguity, the same Chong Boon Subzone has 8 neighboring subzones (4 additional).\n].column[\n\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#rook-and-queen-contiguity","position":15},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Higher Order Contiguity"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#higher-order-contiguity","position":16},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Higher Order Contiguity"},"content":"Top: Second level (k=2) contiguity for rook and queen.\n\nBottom: Second level contiguity with lower level (k \\leq 2).\n\nLeft: Rook contiguity\n\nRight: Queen contiguity\n\n].column[\n\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#higher-order-contiguity","position":17},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Distance-based Weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#distance-based-weights","position":18},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Distance-based Weights"},"content":"].column[\n\na.k.a. distance-band weights\n\ndistance between points (polygon centroids, central points)\n\ncan be any function of distnace that implies .red[distance decay], e.g., inverse distance\n\nin practice, mostly based on a notion of contiguity defined by distance\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#distance-based-weights","position":19},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Distance-based Weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#distance-based-weights-1","position":20},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Distance-based Weights"},"content":"].column[\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-02-statistical-spatial-testing#distance-based-weights-1","position":21},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Distance-based Weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#distance-based-weights-2","position":22},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Distance-based Weights"},"content":"\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#distance-based-weights-2","position":23},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"k-Nearest Neighbor Weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#k-nearest-neighbor-weights","position":24},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"k-Nearest Neighbor Weights"},"content":"].column[\n\nk-nearest observations, irrespective of distance\n\nfixed isolates problem for distance bands\n\nfixed adjacent but not neighbors issue\n\nhave the same number of neighbors for all observations\n\nin practice, potential problem with\n\nties (observations at the same distance)\n\nthe area size of neighborhood can vary\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-02-statistical-spatial-testing#k-nearest-neighbor-weights","position":25},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"k-Nearest Neighbor Weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#k-nearest-neighbor-weights-1","position":26},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"k-Nearest Neighbor Weights"},"content":"\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#k-nearest-neighbor-weights-1","position":27},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Row standardization of Spatial Weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#row-standardization-of-spatial-weights","position":28},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Row standardization of Spatial Weights"},"content":"].column[\n\nthe basic spatial weight uses 1 to indicate neighbors and 0 for non-neighbors\n\nlocations with more neighbors with have more ‘1’ in the row, which will get more total ‘influences’ by all its neighbors\\text{W} =\n\\begin{bmatrix}\n0 & 1 & 0 & 1 & 1 & 0 \\\\\\\\\n1 & 0 & 0 & 1 & 1 & 0 \\\\\\\\\n0 & 0 & 0 & 0 & 1 & 1 \\\\\\\\\n1 & 1 & 0 & 0 & 1 & 0 \\\\\\\\\n1 & 1 & 1 & 1 & 0 & 0 \\\\\\\\\n0 & 0 & 1 & 0 & 0 & 0\n\\end{bmatrix}\n\n.xkcd[See the last two rows.]\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-02-statistical-spatial-testing#row-standardization-of-spatial-weights","position":29},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Row standardization of Spatial Weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#row-standardization-of-spatial-weights-1","position":30},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Row standardization of Spatial Weights"},"content":"].column[\n\nrescale weights so that for each row i: \\sum(j) w(i,j) = 1\n\nw(i,j)' = \\frac{w(i,j)}{\\sum_k w(i,k)} \n\nmakes calculation results comparable\n\nall locations will get same level of influence by all their neighbors\n\nlocations with more neighbors, each of its neighbbors will have less weights of influence to the location, such that the total weight of influence from neighbors is the same with any other location\n\nnon-symmetrical\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-02-statistical-spatial-testing#row-standardization-of-spatial-weights-1","position":31},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Row standardization of Spatial Weights"},"type":"lvl2","url":"/sec-06-02-statistical-spatial-testing#row-standardization-of-spatial-weights-2","position":32},{"hierarchy":{"lvl1":"Statistical Testing of Spatial Autocorrelation","lvl2":"Row standardization of Spatial Weights"},"content":".split-50[.column[\n$$\n\\text{W} =\\begin{bmatrix}\n0 & 1 & 0 & 1 & 1 & 0 \\\\\\\\\n1 & 0 & 0 & 1 & 1 & 0 \\\\\\\\\n0 & 0 & 0 & 0 & 1 & 1 \\\\\\\\\n1 & 1 & 0 & 0 & 1 & 0 \\\\\\\\\n1 & 1 & 1 & 1 & 0 & 0 \\\\\\\\\n0 & 0 & 1 & 0 & 0 & 0\n\\end{bmatrix}].column[\n\n\\text{W}’ =\\begin{bmatrix}\n0 & 0.333 & 0 & 0.333 & 0.333 & 0 \\\\\\\\\n0.333 & 0 & 0 & 0.333 & 0.333 & 0 \\\\\\\\\n0 & 0 & 0 & 0 & 0.5 & 0.5 \\\\\\\\\n0.333 & 0.333 & 0 & 0 & 0.333 & 0 \\\\\\\\\n0.25 & 0.25 & 0.25 & 0.25 & 0 & 0 \\\\\\\\\n0 & 0 & 1 & 0 & 0 & 0\n\\end{bmatrix}\n\n$$\n\n]]","type":"content","url":"/sec-06-02-statistical-spatial-testing#row-standardization-of-spatial-weights-2","position":33},{"hierarchy":{"lvl1":"Moran’s I"},"type":"lvl1","url":"/sec-06-03-morans-i","position":0},{"hierarchy":{"lvl1":"Moran’s I"},"content":"\n\n.square[Moran’s I .dot[] Calculation .dot[] Interpretation .dot[] Permutation ]\n\n.headnote.square.bold.x-large[Areal Pattern I]\n\nclass: center, middle","type":"content","url":"/sec-06-03-morans-i","position":1},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I main goal"},"type":"lvl3","url":"/sec-06-03-morans-i#morans-i-main-goal","position":2},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I main goal"},"content":"Moran’s I is a widely-used measure of .red[global spatial autocorrelation], developed by Australian statistician Patrick Moran. It quantifies the degree to which the values of a variable are .red[spatially correlated with their neighboring values] across an entire study area.\n\n.footnote[\n\nGlobal Moran’s I (ArcGIS)]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-03-morans-i#morans-i-main-goal","position":3},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I calculation"},"type":"lvl3","url":"/sec-06-03-morans-i#morans-i-calculation","position":4},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I calculation"},"content":"Moran’s I ranges from:\n\n-1 (indicating .red[perfect dispersion] or negative spatial autocorrelation) to\n\n+1 (indicating .red[perfect clustering] or positive spatial autocorrelation), with\n\n0 indicating a .red[random] spatial pattern (no spatial autocorrelation).\n\n].column[\nMoran’s I is defined as:\n\nWhere:\n\nN is the number of spatial units indexed by i and j;\n\nx is the variable of interest;\n\n\\bar{x} is the mean of x;\n\nw_{i,j} is the spatial weight---kind of an indicator variable, equal to 1 or the row-standardized value if i and j are neighbors, 0 otherwise;\n\nW is the sum of all w\\_{i,j}.\n\nA significant Moran’s I value suggests that the observed spatial distribution of the variable is not random, and further investigation is warranted to understand the underlying spatial relationships and processes.\n]]\n\nclass: left, middle","type":"content","url":"/sec-06-03-morans-i#morans-i-calculation","position":5},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I calculation"},"type":"lvl3","url":"/sec-06-03-morans-i#morans-i-calculation-1","position":6},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I calculation"},"content":"\n\nEach value is compared to the mean value (\\bar{x}) before the multiplying. Given the value (x_i) of a location and one of its neighbor’s value (x_j), the multiplying result:\n\nis a .red[positive value] because both are at the same direction (both higher or both lower);\n\nis a .red[negative value] if one of which is higher than the mean and the other is lower compared to mean value;\n\nwill be a .red[large value] if both the self and neighbor values are very far from the mean value;\n\nwill be a .red[small value] (near to zero) if the two values are near to mean.\n\nNote that if they are both a lot lower than the mean value, the result would also be a .red[large positive high value], indicating .red[positive spatial autocorrelation].\n\nclass: left, middle","type":"content","url":"/sec-06-03-morans-i#morans-i-calculation-1","position":7},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I: Interpretation"},"type":"lvl3","url":"/sec-06-03-morans-i#morans-i-interpretation","position":8},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I: Interpretation"},"content":".split-50[.column[\n.bold[Reading I]\n\ntheoretical mean is 1/(N-1), essentially zero for large N\n\npositive and significant: clustering of similar value\n\nNOT clustering of high or low\n\ncould be either or a combination\n\nnegative and significant: alternating values\n\npresence of spatial outliers\n\nspatial heterogeneity (checkerboard pattern)\n].column[\n.bold[Comparing the I]\n\nMoran’s I depends on spatial weights\n\nrelative magnitude for .red[same weights settings] and different variables is .red[meaningful]\n\n.red[NOT for different spatial weights]\n\nuse standardized z-value to compare\n]]\n\n.footnote.small[\n\nsee here for more details on the calculation of z-value]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-03-morans-i#morans-i-interpretation","position":9},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I: Interpretation"},"type":"lvl3","url":"/sec-06-03-morans-i#morans-i-interpretation-1","position":10},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I: Interpretation"},"content":"","type":"content","url":"/sec-06-03-morans-i#morans-i-interpretation-1","position":11},{"hierarchy":{"lvl1":"Moran’s I","lvl4":"Reading I","lvl3":"Moran’s I: Interpretation"},"type":"lvl4","url":"/sec-06-03-morans-i#reading-i","position":12},{"hierarchy":{"lvl1":"Moran’s I","lvl4":"Reading I","lvl3":"Moran’s I: Interpretation"},"content":"].column[\n\n\n]]\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-06-03-morans-i#reading-i","position":13},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I Scatter Plot: Interpretation"},"type":"lvl3","url":"/sec-06-03-morans-i#morans-i-scatter-plot-interpretation","position":14},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I Scatter Plot: Interpretation"},"content":"X-axis: the standardized crime rate of every location (town)\n\nY-axis: the average of standardized neighborhood’s crime rate (spatial-lag of the variable)\n\nMoran’s I = 0.5237 (written on top)\n\n].column[\n\n]]\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-06-03-morans-i#morans-i-scatter-plot-interpretation","position":15},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I Scatter Plot: Interpretation"},"type":"lvl3","url":"/sec-06-03-morans-i#morans-i-scatter-plot-interpretation-1","position":16},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Moran’s I Scatter Plot: Interpretation"},"content":"The 4 quadrants:\n\n.bold[upper right]: self-.red[High] - lag-.red[High] (HH), positively autocorrelated with high values, indicate potential hot-spots;\n\n.bold[lower left]: self-.red[Low] - lag-.red[Low] (LL), positively autocorrelated with low values, indicate potential cold-spots;\n\n.bold[upper left]: self-.red[Low] - lag-.red[High] (LH), negatively autocorrelated;\n\n.bold[lower right]: self-.red[High] - lag-.red[Low] (HL), negatively autocorrelated.\n\nRequired statistical testing to identify significant hot-spots and cold-spots.\n\n].column[\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-03-morans-i#morans-i-scatter-plot-interpretation-1","position":17},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Permutation Approach"},"type":"lvl3","url":"/sec-06-03-morans-i#permutation-approach","position":18},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Permutation Approach"},"content":"].column[\n\nRandom reshuffling the attributes data, without modifying the locational data\n\nrecompute Moran’s I each time\n\nreconstructing a .red[reference distribution]\n\ncompare the (original data) .red[observed value of Moran’s I] to the reference distribution\n\n.red[even a high Moran’s I value does not necessarily indicate significance.]\n\nthe ‘p-value’ is not the same as the statistical p-value, it should be called pseudo-p-value as it is calculated using a permutation approach from empirical data, rather than estimated with some solid statistical method.\n\nthe number of permutation will ‘improve’ the p-value.\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-03-morans-i#permutation-approach","position":19},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Permutation Approach"},"type":"lvl3","url":"/sec-06-03-morans-i#permutation-approach-1","position":20},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Permutation Approach"},"content":"","type":"content","url":"/sec-06-03-morans-i#permutation-approach-1","position":21},{"hierarchy":{"lvl1":"Moran’s I","lvl4":"(demo)","lvl3":"Permutation Approach"},"type":"lvl4","url":"/sec-06-03-morans-i#id-demo","position":22},{"hierarchy":{"lvl1":"Moran’s I","lvl4":"(demo)","lvl3":"Permutation Approach"},"content":"].column[\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-03-morans-i#id-demo","position":23},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"A demonstration"},"type":"lvl3","url":"/sec-06-03-morans-i#a-demonstration","position":24},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"A demonstration"},"content":"","type":"content","url":"/sec-06-03-morans-i#a-demonstration","position":25},{"hierarchy":{"lvl1":"Moran’s I","lvl4":"Moran’s Scatter plot","lvl3":"A demonstration"},"type":"lvl4","url":"/sec-06-03-morans-i#morans-scatter-plot","position":26},{"hierarchy":{"lvl1":"Moran’s I","lvl4":"Moran’s Scatter plot","lvl3":"A demonstration"},"content":"The bus ridership aggregated by incoming flow, during the morning peak (7am-9am) in June 2023. Spatial weights are 2 levels of Queen contiguity.\n\nMoran’s I = 0.03\n].column[\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-03-morans-i#morans-scatter-plot","position":27},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"A demonstration"},"type":"lvl3","url":"/sec-06-03-morans-i#a-demonstration-1","position":28},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"A demonstration"},"content":"999 times permutation is generated.\n].column[\n\n]]\n\nclass: center, middle, inverse","type":"content","url":"/sec-06-03-morans-i#a-demonstration-1","position":29},{"hierarchy":{"lvl1":"Moran’s I","lvl2":"Closing Remarks"},"type":"lvl2","url":"/sec-06-03-morans-i#closing-remarks","position":30},{"hierarchy":{"lvl1":"Moran’s I","lvl2":"Closing Remarks"},"content":"\n\n.square[Spatial Autocorrelation .dot[] Spatial Testing .dot[] Spatial Weights .dot[] Moran’s I ]\n\n.headnote.square.bold.x-large[Areal Pattern I]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-03-morans-i#closing-remarks","position":31},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Recap of this lecture","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-06-03-morans-i#recap-of-this-lecture","position":32},{"hierarchy":{"lvl1":"Moran’s I","lvl3":"Recap of this lecture","lvl2":"Closing Remarks"},"content":"].column[\n\nspatial randomness for areal data\n\nspatial autocorrelation\n\nspatial dependency and spatial heterogeneity\n\nattributes similarity and locational similarity\n\nspatial weights and row standardization\n\ncontiguity (rook, queen) and higher order\n\ndistance-based\n\nk-nearest neighbors\n\nMoran’s I\n\ngoals to identify positive and negative spatial autocorrelation\n\ncalculation\n\nhow to read the result\n\npermutation\n]]","type":"content","url":"/sec-06-03-morans-i#recap-of-this-lecture","position":33},{"hierarchy":{"lvl1":"Local Moran’s I"},"type":"lvl1","url":"/sec-06-04-local-moran","position":0},{"hierarchy":{"lvl1":"Local Moran’s I"},"content":"\n\n.square[Hot/Cold Spots .dot[] LISA ]\n\n.headnote.square.bold.x-large[Areal Pattern II]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran","position":1},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"What is LISA"},"type":"lvl2","url":"/sec-06-04-local-moran#what-is-lisa","position":2},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"What is LISA"},"content":"].column[\nLISA, which stands for Local Indicators of Spatial Association, is a set of statistical measures used in spatial data analysis to identify and assess local patterns of spatial autocorrelation. LISA helps detect areas with significant concentrations or disparities of a given variable, such as regions with high crime rates, low-income neighborhoods, or areas with a high prevalence of a particular disease.\n\nLISA encompasses various types of measures, including .red[Local Moran’s I, Local Geary’s C, Gi, and Gi*]. These measures build upon the concept of global spatial autocorrelation, measured by Moran’s I (for Local Moran), Geary’s C (for local Geary C), by providing location-specific insights into spatial structures, mainly on spatial clustering (hot-spots, cold-spots) and spatial outliers (neighboring with the opposite type).\n\nBy analyzing the spatial patterns and local clustering of a given variable through the different LISA measures, researchers can gain valuable insights for urban planning, public health, environmental studies, criminology, and other fields where spatial relationships and interactions play a crucial role.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#what-is-lisa","position":3},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"LISA form of global spatial autocorrelation"},"type":"lvl2","url":"/sec-06-04-local-moran#lisa-form-of-global-spatial-autocorrelation","position":4},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"LISA form of global spatial autocorrelation"},"content":"].column[\n\nDecomposable statistics\n\n\\text{global} = a . [\\sum_i \\text{component}(i)]\n\nthen \\text{local}(i) = \\text{component}(i)\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#lisa-form-of-global-spatial-autocorrelation","position":5},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"What is Local Moran’s"},"type":"lvl2","url":"/sec-06-04-local-moran#what-is-local-morans","position":6},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"What is Local Moran’s"},"content":"].column[\nLocal Moran’s I is a measure of spatial autocorrelation used in geography and geographic information science (GIS) to assess the degree of spatial clustering or dispersion of a given variable around a specific location. Developed by Anselin (1995), it is a local version of the global Moran’s I statistic, which measures the overall spatial autocorrelation in a dataset.\n\nLocal Moran’s I helps identify the extent of significant spatial clustering of similar values around a specific observation. It calculates the correlation between a value at a given location and the values at neighboring locations, highlighting areas with high or low concentrations of the variable under study. This information can be useful in various applications, such as identifying crime hotspots, determining areas with higher disease prevalence, or understanding income disparities across a region.\n\nEssentially, Local Moran’s I provides a way to evaluate spatial patterns and relationships between values at specific locations and their surroundings, offering insights into the spatial structure of the data.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#what-is-local-morans","position":7},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"The target of Local Moran"},"type":"lvl2","url":"/sec-06-04-local-moran#the-target-of-local-moran","position":8},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"The target of Local Moran"},"content":"].column[\nThe target of Local Moran is to identify two types of locations with statistical significance (through permutation):\n\n.bold[Clusters]: locations with significantly similar values (hot-spots & cold-spots)\n\n.bold[Outliers]: locations with significantly different values.\n\nPlaces with very similar but not far from the means are ignored (as non-significant).\n\n.red[Clusters]: To identify locations with .red[positive] correlation:\n\nHigh-High (HH) clusters: .red[high] value locations surrounded by .red[high] value neighbors\n\nLow-Low (LL) clusters: .red[low] value locations surrounded by .red[low] value neighbors\n\n.red[Outliers]: To identify locations with .red[negative] correlation:\n\nHigh-Low (HL) outliers: .red[high] value locations surrounded by .red[low] value neighbors\n\nLow-High (LH) outliers: .red[low] value locations surrounded by .red[high] value neighbors\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#the-target-of-local-moran","position":9},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Global Moran’s I: Formula"},"type":"lvl2","url":"/sec-06-04-local-moran#global-morans-i-formula","position":10},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Global Moran’s I: Formula"},"content":"The lower part (denominator) is a kind of standardizig process to control the range of the resulting values.\n\n].column[\\text{I}=\\frac{N}{W} \\times \\frac{\\sum\\_i^N \\sum\\_j^N w_{i,j}(x_i-\\bar{x})(x_j-\\bar{x})}{\\sum_k (x_k-\\bar{x})^2}<img src=\"resources/w08-img/morans_I_equation.png\" width=\"80%\">\n\nWhere:\n\nN is the number of spatial units indexed by i and j;\n\nx is the variable of interest;\n\n\\bar{x} is the mean of x;\n\nw_{i,j} is the spatial weight---kind of an indicator variable, equal to 1 or the row-standardized value if i and j are neighbors, 0 otherwise;\n\nW is the sum of all w\\_{i,j}.\n\nLet’s z_i = x_i - \\bar{x} (i.e., deviations from mean), then\\text{I} = \\frac{\\sum\\_i \\sum\\_j w_{i,j} \\times z_i \\times z_j}{\\sum_k z_k^2}<img src=\"resources/w09-img/morans_I_equation2.png\" width=\"60%\">\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#global-morans-i-formula","position":11},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Local Moran’s I: Formula"},"type":"lvl2","url":"/sec-06-04-local-moran#local-morans-i-formula","position":12},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Local Moran’s I: Formula"},"content":"The lower part (denominator, \\sum_k z_k^2) is a kind of standardizig process to control the range of the resulting values.\n\n].column[\\text{I} = \\frac{\\sum\\_i \\sum\\_j w_{i,j} \\times z_i \\times z_j}{\\sum_k z_k^2}<img src=\"resources/w09-img/morans_I_equation2.png\" width=\"50%\">\n\nrearrange...\\text{I} = \\frac{1}{\\sum\\_k z\\_k^2} \\times [\\sum\\_i z\\_i \\sum\\_j w\\_{i,j} \\times z\\_j]<img src=\"resources/w09-img/morans_I_equation3.png\" width=\"60%\">\n\n\\sum_k z_k^2 will not change with i, thus constant and this could be captured by the form of:\n\n\\text{global} = a . [\\sum_i \\text{component}(i)]\\text{Local I}\\_i = \\frac{1}{\\sum\\_k z\\_k^2} \\times z\\_i \\sum\\_j w\\_{i,j} \\times z\\_j<img src=\"resources/w09-img/morans_I_local_equation_2.png\" width=\"60%\">\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#local-morans-i-formula","position":13},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Technical aspects of Local Moran('s I)"},"type":"lvl2","url":"/sec-06-04-local-moran#technical-aspects-of-local-moran-s-i","position":14},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Technical aspects of Local Moran('s I)"},"content":"The first part (1 / \\sum_k z_k^2 or N / \\sum_k z_k^2) is a kind of standardizig process to control the range of the resulting values.\n].column[\n\nfor row-standardized weights\n(such that S_0 and N cancel out in Moran’s I)\n\nvariables as deviations from mean (z_i = x_i - \\bar{x}, positive means greater than mean, and negative means less than mean).\\text{Local I}\\_i = \\frac{1}{\\sum\\_k z\\_k^2} \\times z\\_i \\sum\\_j w\\_{i,j} \\times z\\_j<img src=\"resources/w09-img/morans_I_local_equation_2.png\" width=\"60%\">\n\nz_i is the deviation from mean for the current location\n\n<img src=\"resources/w09-img/lag_term.png\" width=\"15%\">\n\n$\\sum\\_j w\\_{i,j} \\times z\\_j$ is the 'lag' term, how high or low is the (location $i$'s) neighbors' overall value compared to the mean\n\nfor non-row-standardised\\text{Local I}\\_i = \\frac{N}{\\sum\\_k z\\_k^2} \\times z\\_i \\sum\\_j w\\_{i,j} \\times z\\_j\n\ntake note on the N...\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#technical-aspects-of-local-moran-s-i","position":15},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Link Local - Global: LISA"},"type":"lvl2","url":"/sec-06-04-local-moran#link-local-global-lisa","position":16},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Link Local - Global: LISA"},"content":"].column[\ntake note on the N:\\sum\\_i \\text{Local I}\\_i = \\sum\\_i \\frac{N}{\\sum\\_k z\\_k^2} \\times z\\_i \\sum\\_j w\\_{i,j} \\times z\\_j\n\n\\sum\\_i \\text{Local I}\\_i = N \\times \\frac{1}{\\sum\\_k z\\_k^2} \\times \\sum\\_i z\\_i \\sum\\_j w\\_{i,j} \\times z\\_j\n\n\\sum\\_i \\text{Local I}\\_i = N \\times \\text{Global I}\n\n\\sum_i \\text{local}_i = N . \\text{global}\n\nor \\text{global} = \\frac{\\sum_i \\text{local}_i}{N}\n\nthe global statistics is the average of local statistics\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#link-local-global-lisa","position":17},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Statistical Inference"},"type":"lvl2","url":"/sec-06-04-local-moran#statistical-inference","position":18},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Statistical Inference"},"content":"].column[\n\nanalytical and computational\n\nanalytical approximation is poor (do not use)\n\ncomputational approach is based on .red[conditional permutation]\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#statistical-inference","position":19},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Conditional Permutation"},"type":"lvl2","url":"/sec-06-04-local-moran#conditional-permutation","position":20},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Conditional Permutation"},"content":"].column[\n\nConditional upon value observed at location i\n\nhold value at i fixed, random permute remaining n-1 values and recompute local Moran’s I\n\nsince w_{i,j} leave non-neighbors to be 0, this is same as randomly pick J number of value (without replacement), J is the number of neighbors, then locate these J values on each neighbor for the local Moran calculation.\n\nrepeat many times (e.g., 999) to obtain reference distribution for location i, compare and calculate pseudo p-value\n\ncomputationally intensive:\n\nif there is N size of entity (row), and the permutation is set to 1000, then the calculation takes N * 1000.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#conditional-permutation","position":21},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation","position":22},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation","position":23},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"Local Significance Map","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#local-significance-map","position":24},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"Local Significance Map","lvl2":"Interpretation"},"content":"].column[\n\nshows locations with significant local statistic by level of significance.\n\nnot very useful for substantive interpretation\n\nuseful for observation of the confidence level\n\ndiagnostic for sensitivity of results (for example, when only significant at 0.05 but not at 0.001).\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#local-significance-map","position":25},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-1","position":26},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-1","position":27},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"An example","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#an-example","position":28},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"An example","lvl2":"Interpretation"},"content":"Take an example: the donations data (Guerry data)\n].column[\n\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#an-example","position":29},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-2","position":30},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-2","position":31},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Significance Map","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-significance-map","position":32},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Significance Map","lvl2":"Interpretation"},"content":"].column[\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#the-local-significance-map","position":33},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-3","position":34},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-3","position":35},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cluster Map","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-cluster-map","position":36},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cluster Map","lvl2":"Interpretation"},"content":"].column[\n\nshows locations with .red[significant] local spatial autocorrelation by .red[type of association]\n\nfour types (four colours):\n\nHH clusters\n\nLL clusters\n\nHL outliers\n\nLH outliers\n\nshown only for a specified significance level (sensitivity analysis)\n\n.red[but the Local Moran can only be used to identify positive or negative correlation, i.e., clusters or outliers, how to differentiate the HH from LL and HL from LH?]\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-04-local-moran#the-local-cluster-map","position":37},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-4","position":38},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-4","position":39},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cluster Map","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-cluster-map-1","position":40},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cluster Map","lvl2":"Interpretation"},"content":"\n\n.xkcd[use the quadrants]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#the-local-cluster-map-1","position":41},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-5","position":42},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-5","position":43},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cluster Map","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-cluster-map-2","position":44},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cluster Map","lvl2":"Interpretation"},"content":"].column[\n\n]]\n\nclass: left, middle\n.split-50[.column[","type":"content","url":"/sec-06-04-local-moran#the-local-cluster-map-2","position":45},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-6","position":46},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-6","position":47},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cluster Map (sensitivity analysis)","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-cluster-map-sensitivity-analysis","position":48},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cluster Map (sensitivity analysis)","lvl2":"Interpretation"},"content":"On the right,\n\ntop: p-value < 0.05\n\nbottom: p-value < 0.01\n\nThrough the changes of significance level, we can observe the changes of clusters/outliers and identify those that is more significant.\n\n].column[\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-04-local-moran#the-local-cluster-map-sensitivity-analysis","position":49},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-7","position":50},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-7","position":51},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Outliers","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-outliers","position":52},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Outliers","lvl2":"Interpretation"},"content":"\n\nThe locations of HL outliers and their neighbors.\n\nclass: center, middle","type":"content","url":"/sec-06-04-local-moran#the-local-outliers","position":53},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-8","position":54},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-8","position":55},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Outliers","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-outliers-1","position":56},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Outliers","lvl2":"Interpretation"},"content":"\n\nThe locations of LH outliers and their neighbors.\n\nclass: center, middle","type":"content","url":"/sec-06-04-local-moran#the-local-outliers-1","position":57},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-9","position":58},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-9","position":59},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Hot-spots","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-hot-spots","position":60},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Hot-spots","lvl2":"Interpretation"},"content":"\n\nThe locations of HH clusters and their neighbors.\n\nclass: center, middle","type":"content","url":"/sec-06-04-local-moran#the-local-hot-spots","position":61},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-04-local-moran#interpretation-10","position":62},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-04-local-moran#interpretation-10","position":63},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cold-spots","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-04-local-moran#the-local-cold-spots","position":64},{"hierarchy":{"lvl1":"Local Moran’s I","lvl3":"The Local Cold-spots","lvl2":"Interpretation"},"content":"\n\nThe locations of LL clusters and their neighbors.\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-04-local-moran#the-local-cold-spots","position":65},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Overview"},"type":"lvl2","url":"/sec-06-04-local-moran#overview","position":66},{"hierarchy":{"lvl1":"Local Moran’s I","lvl2":"Overview"},"content":"].column[\nLocal Moran’s I is a local measure of spatial autocorrelation used in spatial data analysis. It assesses the degree of spatial clustering or dispersion around individual locations, providing location-specific information about the presence of spatial patterns. As a member of the Local Indicators of Spatial Association (LISA) family, Local Moran’s I builds upon the global Moran’s I statistic to offer a more fine-grained understanding of spatial relationships within a dataset.\n\nFour types of spatial clusters and outliers can be identified:\n\nHigh-High (HH) clusters (hot-spots),\n\nLow-Low (LL) clusters (cold-spots),\n\nHigh-Low (HL) outliers, and\n\nLow-High (LH) outliers.\n\nLocal Moran’s I results could be observed and discussed in two linked maps, i.e., the local significance map and local cluster map. These maps can be used to visualize the spatial distribution of clusters and outliers, aiding in the interpretation and understanding of spatial patterns.\n]]","type":"content","url":"/sec-06-04-local-moran#overview","position":67},{"hierarchy":{"lvl1":"Geary’s C and Local Geary"},"type":"lvl1","url":"/sec-06-05-gearys-c-and-local-c","position":0},{"hierarchy":{"lvl1":"Geary’s C and Local Geary"},"content":"\n\n.square[Geary’s C .dot[] Local Geary]\n\n.headnote.square.bold.x-large[Areal Pattern II]\n\nclass: left, middle\n.split-60[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c","position":1},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Spatial Autocorrelation metrics and their Local versions"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#spatial-autocorrelation-metrics-and-their-local-versions","position":2},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Spatial Autocorrelation metrics and their Local versions"},"content":"].column[\n\nMoran’s I and Local Moran’s I\n\n.red[Geary’s C and Local Geary’s C]\n\nGeneral G statistics, Gi, and Gi*\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#spatial-autocorrelation-metrics-and-their-local-versions","position":3},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Geary’s C"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#gearys-c","position":4},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Geary’s C"},"content":"The lower part (denominator) is a kind of standardizig process to control the range of the resulting values.\n\n].column[\nGeary’s C is a global measure of spatial autocorrelation used in spatial data analysis to determine the overall degree of spatial dependency in a dataset. It quantifies the degree to which values in a dataset are similar to or different from neighboring values, considering the entire study area. Unlike  Moran’s I, Geary’s C focuses on .red.bold[the distance between value of a location and its neighbors] rather than their distances to the mean value.C = \\frac{(N-1)\\sum\\_i\\sum\\_j w\\_{ij}(x\\_i-x\\_j)^{2}}{2S\\_0\\sum\\_i(x\\_i-\\bar{x})^{2}}<img src=\"resources/w09-img/geary_c_equation.png\" width=\"80%\">\n\nIn this equation:\n\nN is the number of observations.\n\nw_{ij} is the spatial weight matrix, representing the spatial relationships between observations i and j.\n\nx_{k} are the observed values of the variable at location k.\n\nS_{0} is the sum of all spatial weights.\n\n\\bar{x} is the mean of the observed values.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#gearys-c","position":5},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Local Geary’s C"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#local-gearys-c","position":6},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Local Geary’s C"},"content":"The lower part (denominator) is a kind of standardizig process to control the range of the resulting values.\n\n].column[\nAnd the Local Gearyc\\_i = \\frac{\\sum\\_j w\\_{ij}(x\\_i - x\\_j)^2}{2S\\_0}<img src=\"resources/w09-img/geary_c_local_equation.png\" width=\"80%\">\n\nUnlike the global Geary’s C, the local version provides .red[location-specific information about spatial autocorrelation], allowing for the identification of spatial clusters and outliers. .bold.red[Low values] of the Local Geary’s C indicate .red[positive] spatial autocorrelation (.red[similar values cluster together]), while .bold.red[high values] indicate .red[negative] spatial autocorrelation (.red[dissimilar values are close to each other]).\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-05-gearys-c-and-local-c#local-gearys-c","position":7},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Comparing Global vs. Local"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#comparing-global-vs-local","position":8},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Comparing Global vs. Local"},"content":"\\text{global} = a . [\\sum_i \\text{component}(i)]\n\n.split-50[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#comparing-global-vs-local","position":9},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Global","lvl2":"Comparing Global vs. Local"},"type":"lvl3","url":"/sec-06-05-gearys-c-and-local-c#global","position":10},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Global","lvl2":"Comparing Global vs. Local"},"content":"C = \\frac{(N-1)\\sum\\_i\\sum\\_j w\\_{ij}(x\\_i-x\\_j)^{2}}{2S\\_0\\sum\\_i(x\\_i-\\bar{x})^{2}}C = \\frac{(N-1)}{2S\\_0\\sum\\_i(x\\_i-\\bar{x})^{2}} \\times \\sum\\_i\\sum\\_j w\\_{ij}(x\\_i-x\\_j)^{2}C = \\frac{(N-1)}{\\sum\\_i(x\\_i-\\bar{x})^{2}} \\times \\sum\\_i \\frac{1}{2S\\_0}\\times \\sum\\_j w\\_{ij}(x\\_i-x\\_j)^{2}C = \\frac{(N-1)}{\\sum\\_i(x\\_i-\\bar{x})^{2}} \\times \\sum\\_i c\\_i\n\n].column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#global","position":11},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Local","lvl2":"Comparing Global vs. Local"},"type":"lvl3","url":"/sec-06-05-gearys-c-and-local-c#local","position":12},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Local","lvl2":"Comparing Global vs. Local"},"content":"c\\_i = \\frac{\\sum\\_j w\\_{ij}(x\\_i - x\\_j)^2}{2S\\_0}c\\_i = \\frac{1}{2S\\_0} \\times \\sum\\_j w\\_{ij}(x\\_i - x\\_j)^2\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#local","position":13},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#interpretation","position":14},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"content":"].column[\n\n(x_i - x_j)^2\n\nattribute dissimilarity\n\ndistance in attribute space\n\nGeary’s C: weighted average of distances in .red[attribute space] to neighbors in .red[geographic space]\n\npositive: similarity, can be high-high, low-low, .red[middle-middle]\n\nnegative: dissimilarity: no distinction between high-low and low-high\n\nGeary’s C is more sensitive to .red[local patterns of spatial autocorrelation] and can better capture smaller-scale variations in the data.\n.red.bold[spatial non-stationarity]: a sub-region of the study area has a different (e.g., lower) average value, for which the similar-values (could be middle-middle) may be overlooked by Moran’s I (and its local variant).\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#interpretation","position":15},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#interpretation-1","position":16},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-05-gearys-c-and-local-c#interpretation-1","position":17},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"An example (for reference)","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-05-gearys-c-and-local-c#an-example-for-reference","position":18},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"An example (for reference)","lvl2":"Interpretation"},"content":"Take an example: the donations data (Guerry data)\n].column[\n\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#an-example-for-reference","position":19},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#interpretation-2","position":20},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-05-gearys-c-and-local-c#interpretation-2","position":21},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Local Significance Map","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-05-gearys-c-and-local-c#local-significance-map","position":22},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Local Significance Map","lvl2":"Interpretation"},"content":"].column[\n\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#local-significance-map","position":23},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#interpretation-3","position":24},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-05-gearys-c-and-local-c#interpretation-3","position":25},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Local Cluster Map","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-05-gearys-c-and-local-c#local-cluster-map","position":26},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Local Cluster Map","lvl2":"Interpretation"},"content":"].column[\n\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-05-gearys-c-and-local-c#local-cluster-map","position":27},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#interpretation-4","position":28},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Interpretation"},"content":"","type":"content","url":"/sec-06-05-gearys-c-and-local-c#interpretation-4","position":29},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Comparison between p-value","lvl2":"Interpretation"},"type":"lvl3","url":"/sec-06-05-gearys-c-and-local-c#comparison-between-p-value","position":30},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl3":"Comparison between p-value","lvl2":"Interpretation"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-06-05-gearys-c-and-local-c#comparison-between-p-value","position":31},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Local Moran’s I vs. Local Geary’s C"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#local-morans-i-vs-local-gearys-c","position":32},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Local Moran’s I vs. Local Geary’s C"},"content":"\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-05-gearys-c-and-local-c#local-morans-i-vs-local-gearys-c","position":33},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Moran’s I vs. Geary’s C"},"type":"lvl2","url":"/sec-06-05-gearys-c-and-local-c#morans-i-vs-gearys-c","position":34},{"hierarchy":{"lvl1":"Geary’s C and Local Geary","lvl2":"Moran’s I vs. Geary’s C"},"content":"].column[\n\nDifferent type of attribute similarity\n\ncross-product (correlation) vs.\n\nsquared difference (dissimilarity)\n\npower against different alternatives\n\nthe same null hypothesis: spatial randomness\n\nwhat should be the ‘alternative’?\n\nMoran’s I and its local variant: Detect similar values based on their .red[deviation from the mean value].\n\nMoran’s I is more sensitive to global patterns of spatial autocorrelation and overall trends in the data.\n\nGeary’s C and its local variant: Detect similar values based on the .red[absolute differences between pairs of values].\n\nGeary’s C is more sensitive to local patterns of spatial autocorrelation and smaller-scale variations in the data.\n\n]]","type":"content","url":"/sec-06-05-gearys-c-and-local-c#morans-i-vs-gearys-c","position":35},{"hierarchy":{"lvl1":"Getis-Ord G statistics"},"type":"lvl1","url":"/sec-06-06-getis-ord-g","position":0},{"hierarchy":{"lvl1":"Getis-Ord G statistics"},"content":"\n\n.square[General G .dot[] Local Gi]\n\n.headnote.square.bold.x-large[Areal Pattern II]\n\nclass: left, middle\n.split-60[.column[","type":"content","url":"/sec-06-06-getis-ord-g","position":1},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Spatial Autocorrelation metrics and their Local versions"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#spatial-autocorrelation-metrics-and-their-local-versions","position":2},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Spatial Autocorrelation metrics and their Local versions"},"content":"].column[\n\nMoran’s I and Local Moran’s I\n\nGeary’s C and Local Geary’s C\n\n.red[General G statistics and Gi; G and Gi*]\n]]\n\nclass: left, middle","type":"content","url":"/sec-06-06-getis-ord-g#spatial-autocorrelation-metrics-and-their-local-versions","position":3},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Three things to notice in next slide"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#three-things-to-notice-in-next-slide","position":4},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Three things to notice in next slide"},"content":"the difference between ‘stars’: with star means j can equal to i\n\nx\\_i \\times x\\_j\n\nThe lower part (denominator) is a kind of standardizig process to control the range of the resulting values.\n\nclass: left, middle","type":"content","url":"/sec-06-06-getis-ord-g#three-things-to-notice-in-next-slide","position":5},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Getis-Ord General G"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#getis-ord-general-g","position":6},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Getis-Ord General G"},"content":"\\text{global} = a . [\\sum_i \\text{component}(i)]\n\n.split-50[.column[","type":"content","url":"/sec-06-06-getis-ord-g#getis-ord-general-g","position":7},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Global version","lvl3":"Getis-Ord General G"},"type":"lvl4","url":"/sec-06-06-getis-ord-g#global-version","position":8},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Global version","lvl3":"Getis-Ord General G"},"content":"General G:\\text{G} = \\frac{\\sum\\_i \\sum\\_{j\\neq  i} w\\_{ij} x\\_i x\\_j }{\\sum\\_i\\sum\\_{j\\neq  i} x\\_i x\\_j}\n\nGeneral G*:\\text{G}^{\\*} = \\frac{\\sum\\_i \\sum\\_j w\\_{ij} x\\_i x\\_j }{\\sum\\_i\\sum\\_j x\\_i x\\_j}\n\n].column[","type":"content","url":"/sec-06-06-getis-ord-g#global-version","position":9},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Local version","lvl3":"Getis-Ord General G"},"type":"lvl4","url":"/sec-06-06-getis-ord-g#local-version","position":10},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Local version","lvl3":"Getis-Ord General G"},"content":"Gi:\\text{G}\\_i = \\frac{\\sum\\_{j\\neq i}w\\_{ij}x\\_j}{\\sum\\_{j\\neq i}x\\_j}\n\nGi*:\\text{G}\\_{i}^{\\*} = \\frac{\\sum\\_{j}w\\_{ij} x\\_j}{\\sum\\_{j} x\\_j}\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-06-getis-ord-g#local-version","position":11},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"The three measures"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#the-three-measures","position":12},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"The three measures"},"content":"].column[","type":"content","url":"/sec-06-06-getis-ord-g#the-three-measures","position":13},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Moran’s I","lvl3":"The three measures"},"type":"lvl4","url":"/sec-06-06-getis-ord-g#morans-i","position":14},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Moran’s I","lvl3":"The three measures"},"content":"focus on (x\\_i - \\bar{x})(x\\_j - \\bar{x}) (deviation from the mean value)\n\n.red[large positive] value (I>0): spatial clusters (HH or LL)\n\n.red[large negative] value (I<0): spatial outliers (HL or LH)\n\nnear zero (I=0): random","type":"content","url":"/sec-06-06-getis-ord-g#morans-i","position":15},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Geary’s C","lvl3":"The three measures"},"type":"lvl4","url":"/sec-06-06-getis-ord-g#gearys-c","position":16},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Geary’s C","lvl3":"The three measures"},"content":"focus on (x\\_i - x\\_j)^2 (squared differences)\n\n.red[small] value (c<1): spatial clusters (HH or LL)\n\n.red[large] value (c>1): spatial outliers (HL or LH)\n\nnear 1 (c=1): random","type":"content","url":"/sec-06-06-getis-ord-g#gearys-c","position":17},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Getis-Ord G*","lvl3":"The three measures"},"type":"lvl4","url":"/sec-06-06-getis-ord-g#getis-ord-g","position":18},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl4":"Getis-Ord G*","lvl3":"The three measures"},"content":"focus on x\\_i \\times x\\_j (the intensity of values in local neighborhoods to the global average)\n\n.red[large] value (G* > mean(G*)): hot-spot (HH)\n\n.red[small] value (G* < mean(G*)): cold-spot (LL)\n\nnear mean(G*): random\n]]\n\nclass: center, middle","type":"content","url":"/sec-06-06-getis-ord-g#getis-ord-g","position":19},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Significance Maps"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#significance-maps","position":20},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Significance Maps"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-06-06-getis-ord-g#significance-maps","position":21},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Cluster Maps"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#cluster-maps","position":22},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Cluster Maps"},"content":"\n\nclass: center, middle, inverse","type":"content","url":"/sec-06-06-getis-ord-g#cluster-maps","position":23},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl2":"Closing Remarks"},"type":"lvl2","url":"/sec-06-06-getis-ord-g#closing-remarks","position":24},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl2":"Closing Remarks"},"content":"\n\n.square[LISA .dot[] Local Moran’s I .dot[] Geary’s C and Local Geary .dot[] Getis-Ord G and Gi]\n\n.headnote.square.bold.x-large[Areal Pattern II]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-06-06-getis-ord-g#closing-remarks","position":25},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Recap of this lecture","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#recap-of-this-lecture","position":26},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Recap of this lecture","lvl2":"Closing Remarks"},"content":"].column[\n\nLISA\n\nLocal Moran’s I\n\nGeary’s C and Local Geary’s C\n\nGetis-Ord G(*) Statistics and Gi(*)\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-06-06-getis-ord-g#recap-of-this-lecture","position":27},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Choosing the appropriate method(s)","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#choosing-the-appropriate-method-s","position":28},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"Choosing the appropriate method(s)","lvl2":"Closing Remarks"},"content":"There are so many different methods and equations for spatial autocorrelation, which one should I use?\n].column[\n\n.bold[Aim of Visualisation]\n\nIf you only want to detect high and low clustering phenomena, the .red[Getis-Ord G statistics] could be sufficient.\n\nIf your data are expected to have a common middle value (e.g., mean), and you aim to detect hot-spots and cold-spots in relation to this middle value, .red[Moran’s I] is ideal.\n\nIf you want to detect places with similar values (not necessarily compared to the middle value), .red[Geary’s C] is the way to go.\n\n.bold[Scale Sensitivity]\n\n.red[Moran’s I] is more sensitive to larger-scale spatial patterns, as every value is compared to the global mean.\n\n.red[Geary’s C] is better at detecting local, smaller-scale variations, since it calculates the differences rather than similarity between values.\n\n.red[Getis-Ord G] statistic is also more sensitive to large-scale spatial patterns. The range of the product obtained by multiplying a pair of values implies that it focuses on global high and global low value pairs.\n\n.bold[Comparison with Previous Studies]\n\nIf you want to compare your results with other research in your field, choose a method that is commonly used in those studies for consistency and ease of comparison.\n\n]]","type":"content","url":"/sec-06-06-getis-ord-g#choosing-the-appropriate-method-s","position":29},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"What we have learnt so far","lvl2":"Closing Remarks"},"type":"lvl3","url":"/sec-06-06-getis-ord-g#what-we-have-learnt-so-far","position":30},{"hierarchy":{"lvl1":"Getis-Ord G statistics","lvl3":"What we have learnt so far","lvl2":"Closing Remarks"},"content":"","type":"content","url":"/sec-06-06-getis-ord-g#what-we-have-learnt-so-far","position":31},{"hierarchy":{"lvl1":"Chapter 6: Geovisualisation"},"type":"lvl1","url":"/chapter-7-geovisualisation","position":0},{"hierarchy":{"lvl1":"Chapter 6: Geovisualisation"},"content":"Objectives of this lecture","type":"content","url":"/chapter-7-geovisualisation","position":1},{"hierarchy":{"lvl1":"Geospatial Data Storytelling"},"type":"lvl1","url":"/sec-07-01-geospatial-data-storytelling","position":0},{"hierarchy":{"lvl1":"Geospatial Data Storytelling"},"content":"\n\n.square[Definition .dot[] Designing .dot[] Considerations ]\n\n.headnote.square.bold.x-large[Geovisualisation I]\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling","position":1},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"The Data-Driven World"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#the-data-driven-world","position":2},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"The Data-Driven World"},"content":"].column[\nIn today’s world,\n\ndata is everywhere and anytime\n\neveryone is using data\n\nmake informed decisions\n\ndrive innovation\n\nimprove outcomes\n\n.red[the true value of data lies not only in its collection and analysis but also in its effective communication]\n\n.xkcd[This is where data storytelling plays a crucial role.]\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#the-data-driven-world","position":3},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"What is Data Storytelling?"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#what-is-data-storytelling","position":4},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"What is Data Storytelling?"},"content":"","type":"content","url":"/sec-07-01-geospatial-data-storytelling#what-is-data-storytelling","position":5},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Definition","lvl2":"What is Data Storytelling?"},"type":"lvl3","url":"/sec-07-01-geospatial-data-storytelling#definition","position":6},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Definition","lvl2":"What is Data Storytelling?"},"content":"].column[\n\nData storytelling is the process of .red[transforming complex data into engaging and easy-to-understand narratives], allowing audiences to quickly .red[grasp insights and take action].\n\nData storytelling  combines .red[data, visuals, narrative and interactivity] to create compelling stories that resonate with people, regardless of their background or expertise.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#definition","position":7},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Data Storytelling"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#data-storytelling","position":8},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Data Storytelling"},"content":"","type":"content","url":"/sec-07-01-geospatial-data-storytelling#data-storytelling","position":9},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Benefits","lvl2":"Data Storytelling"},"type":"lvl3","url":"/sec-07-01-geospatial-data-storytelling#benefits","position":10},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Benefits","lvl2":"Data Storytelling"},"content":"].column[\nData storytelling can help:\n\n.bold[Improved Decision-Making]: Data storytelling enables decision-makers to comprehend complex information quickly, leading to more informed choices and better outcomes.\n\n.bold[Wider Audience Reach]: By making data more accessible and engaging, data storytelling helps reach a broader audience, fostering collaboration and driving change.\n\n.bold[Greater Engagement]: Stories tap into human emotions and experiences, making data more relatable and memorable. This increased engagement leads to better retention and understanding of key insights.\n\n.bold[Increased Trust and Credibility]: Clear and transparent data storytelling builds trust and credibility, helping stakeholders feel confident in the validity of the insights presented.\n\n.bold[Problem-Solving and Innovation]: By revealing hidden patterns and relationships, data storytelling fosters problem-solving, innovation, and the development of new strategies.\n\n]]\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#benefits","position":11},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Geospatial Data Storytelling"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#geospatial-data-storytelling","position":12},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Geospatial Data Storytelling"},"content":"","type":"content","url":"/sec-07-01-geospatial-data-storytelling#geospatial-data-storytelling","position":13},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Definition","lvl2":"Geospatial Data Storytelling"},"type":"lvl3","url":"/sec-07-01-geospatial-data-storytelling#definition-1","position":14},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Definition","lvl2":"Geospatial Data Storytelling"},"content":"].column[\n\nGeospatial data storytelling is the art of combining .red[geographic data, visualizations, and compelling narratives] to communicate insights and patterns within a spatial context. It involves the use of .red[maps, spatial relationships, and location-based data] to create engaging and informative stories that help audiences understand .red[complex geographic phenomena] and make informed decisions.\n\n]]\n\nlayout: false\nclass: center, middle\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#definition-1","position":15},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Geospatial Data Storytelling"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#geospatial-data-storytelling-1","position":16},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Geospatial Data Storytelling"},"content":"","type":"content","url":"/sec-07-01-geospatial-data-storytelling#geospatial-data-storytelling-1","position":17},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Key characteristics","lvl2":"Geospatial Data Storytelling"},"type":"lvl3","url":"/sec-07-01-geospatial-data-storytelling#key-characteristics","position":18},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Key characteristics","lvl2":"Geospatial Data Storytelling"},"content":"].column[\n\n.bold[Geographic Data]: Geospatial data storytelling relies on geographic data, which includes any information associated with a specific location. This data can be either .red[vector] (e.g., points, lines, and polygons) or .red[raster] (e.g., aerial imagery and satellite data) and often includes attributes that describe the features’ characteristics.\n\n.bold[Locations & Maps]: Maps are a central component of geospatial data storytelling, serving as the canvas on which data is visualized and stories are told. They provide a .red[spatial context for the narrative], helping audiences understand the relative location, distribution, and relationships between various geographic features.\n\n.bold[Spatial Relationships]: A key aspect of geospatial data storytelling is the focus on spatial relationships, such as .red[proximity, connectivity, and overlap between geographic features]. These relationships can reveal patterns and trends that would otherwise be difficult to identify, enabling more informed decision-making.\n]]\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#key-characteristics","position":19},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Geospatial Data Storytelling"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#geospatial-data-storytelling-2","position":20},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Geospatial Data Storytelling"},"content":"","type":"content","url":"/sec-07-01-geospatial-data-storytelling#geospatial-data-storytelling-2","position":21},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Key characteristics","lvl2":"Geospatial Data Storytelling"},"type":"lvl3","url":"/sec-07-01-geospatial-data-storytelling#key-characteristics-1","position":22},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl3":"Key characteristics","lvl2":"Geospatial Data Storytelling"},"content":"].column[\n\n.bold[Temporal Trends]: In addition to spatial relationships, geospatial data storytelling often incorporates temporal analysis, exploring .red[how geographic patterns and relationships change over time]. This can provide valuable insights into past trends and help predict future outcomes.\n\n.bold[Audience Engagement]: Geospatial data storytelling can incorporate .red[multimedia] elements like images, videos, and .red[interactive] features to create a more engaging and immersive experience for the audience. Interactive maps and visualizations encourage exploration and enable users to discover insights tailored to their interests.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#key-characteristics-1","position":23},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Elements of a Successful Data Story"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#key-elements-of-a-successful-data-story","position":24},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Elements of a Successful Data Story"},"content":"A successful data story engages .red[the audience, effectively communicates insights, and drives action].\n\n].column[\n\n.bold[Clear Objective]\nA well-defined objective ensures that the data story stays focused and addresses the intended goals. The objective should be aligned with the audience’s interests and needs.\n\n.bold[Targeted Audience]\nTailor the data story to the audience’s level of expertise, interests, and expectations. Consider their needs and the actions you want them to take after engaging with the story.\n\n.bold[Strong Narrative]\nA strong narrative weaves together data, visuals, and text to create a cohesive and engaging story. Utilize storytelling techniques like conflict, resolution, and character development to make the narrative more compelling.\n\n.bold[Informative and Relevant Data]\nSelect data that is accurate, relevant, and supportive of the narrative. Ensure that the data insights are clearly communicated through appropriate visualizations and context.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#key-elements-of-a-successful-data-story","position":25},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Elements of a Successful Data Story"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#key-elements-of-a-successful-data-story-1","position":26},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Elements of a Successful Data Story"},"content":".grey[A successful data story engages the audience, effectively communicates insights, and drives action.]\n\nA successful data story combines these elements to create a .red[compelling narrative] that informs, engages, and drives change.\nBy focusing on .red[the audience], using strong visuals, and providing clear insights, data storytellers can maximize the impact of their work.\n\n].column[\n\n.bold[Effective Visualizations]\nChoose the most suitable visualizations to represent the data, and ensure they are easy to understand, visually appealing, and consistent in design.\n\n.bold[Context and Perspective]\nProvide context for the data, explaining its relevance, source, and limitations. Incorporate diverse perspectives to create a balanced and comprehensive narrative.\n\n.bold[Interactivity and Exploration]\nEnable the audience to interact with the data and explore it on their terms, enhancing engagement and understanding.\n\n.bold[Clear and Actionable Insights]: Present insights that are easy to grasp and provide clear recommendations for action or further investigation.\n\n.bold[Concluding Remarks and Next Steps]\nWrap up the data story with a summary of key points, implications, and suggested next steps. This helps reinforce the main message and encourages the audience to take action.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#key-elements-of-a-successful-data-story-1","position":27},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Knowing Your Audience"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#knowing-your-audience","position":28},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Knowing Your Audience"},"content":"Understanding the audience and their needs is crucial in data storytelling, as it enables the creation of impactful and engaging narratives that resonate with the intended recipients.\n\n].column[\n\n.bold[Tailored Content]\nBy understanding the audience’s interests, background, and expectations, you can select and .red[prioritize data insights that are most relevant to them]. Tailoring the content to their needs increases engagement and ensures the message is more likely to be heard and acted upon.\n\n.bold[Appropriate Complexity]\nKnowing your audience’s .red[level of expertise] allows you to present data and insights with the appropriate level of complexity. This ensures that .red[the audience can understand and engage with the content] without feeling overwhelmed or bored.\n\n.bold[Effective Communication]\nAdjusting the .red[tone, language, and structure] of your data story to suit the audience’s preferences improves communication and comprehension. This helps establish a connection with the audience and makes the narrative more relatable and engaging.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#knowing-your-audience","position":29},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Knowing Your Audience"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#knowing-your-audience-1","position":30},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Knowing Your Audience"},"content":".grey[Understanding the audience and their needs is crucial in data storytelling, as it enables the creation of impactful and engaging narratives that resonate with the intended recipients.]\n\nUnderstanding your audience and their needs is a fundamental aspect of effective data storytelling. By tailoring content, addressing specific interests, and presenting insights in a relatable manner, you can create powerful narratives that resonate with the audience and inspire action.\n\n].column[\n\n.bold[Addressing Pain Points and Objectives]\nBy understanding .red[the challenges and goals] of your audience, you can frame the data story in a way that demonstrates how the insights can address .red[their specific needs or objectives]. This increases the likelihood that the audience will find the story valuable and act on the information provided.\n\n.bold[Building Trust and Credibility]\nTailoring the data story to the audience’s needs and preferences shows that you understand and care about their interests. This helps build trust and establishes your credibility .red[as a reliable source of information].\n\n.bold[Encouraging Action]\nKnowing your audience’s motivations and barriers to action allows you to create a data story that .red[encourages them to take the desired next steps]. By addressing potential objections or concerns, you increase the chances of your story driving meaningful change.\n]]\n\nlayout: false\nclass: center, middle","type":"content","url":"/sec-07-01-geospatial-data-storytelling#knowing-your-audience-1","position":31},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Components of a Compelling Data Story"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#key-components-of-a-compelling-data-story","position":32},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Components of a Compelling Data Story"},"content":"\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#key-components-of-a-compelling-data-story","position":33},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Components of a Compelling Data Story"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#key-components-of-a-compelling-data-story-1","position":34},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Components of a Compelling Data Story"},"content":"A successful data story engages the audience, communicates insights effectively, and inspires action. Here are the essential elements that contribute to a powerful data story:\n\n].column[\n\n.bold[Clear Structure]\nA well-structured data story has a .red[logical flow], guiding the audience through the narrative. It typically includes an introduction, rising action, climax, and resolution, mirroring the elements of traditional storytelling.\n\n.bold[Compelling Characters]\nCharacters in a data story can be .red[individuals, groups, or entities] that are central to the narrative. By showcasing their experiences, challenges, and transformations, you create a relatable and engaging story that humanizes the data.\n\n.bold[Conflict]\nA compelling data story presents a .red[problem or challenge] that needs to be addressed. This conflict generates .red[tension and curiosity], encouraging the audience to continue exploring the narrative to discover potential solutions or insights.\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#key-components-of-a-compelling-data-story-1","position":35},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Components of a Compelling Data Story"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#key-components-of-a-compelling-data-story-2","position":36},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Key Components of a Compelling Data Story"},"content":"A successful data story engages the audience, communicates insights effectively, and inspires action. Here are the essential elements that contribute to a powerful data story:\n\n].column[\n\n.bold[Resolution] (as in for resolving the conflict)\nThe resolution reveals .red[how the conflict is addressed or resolved], providing a sense of .red[closure and satisfaction] for the audience. This element should highlight the key insights and takeaways from the data story.\n\n.bold[Strong Theme]\nA strong theme ties together the various elements of the data story and communicates the overarching message or lesson. The theme should be relevant to the audience and provide .red[a clear takeaway] that encourages .red[reflection or action].\n\n.bold[Interactivity and Engagement]\nIn the context of data storytelling, incorporating interactive elements and fostering engagement can elevate the overall impact of the story.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#key-components-of-a-compelling-data-story-2","position":37},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Best Practices & Considerations"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#best-practices-considerations","position":38},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Best Practices & Considerations"},"content":".blue[Appropriate Visualization Methods]\n\n.blue[Clear and Consistent Symbolization]\n\n.blue[Avoid Clutter and Complexity]\n\n.blue[Provide Context]\n\nVisual Design Elements\n\nInteractivity\n\nClear Labeling and Legends\n\nUser Experience\n\nAccompany Visualizations with Narrative\n\nBe Transparent\n].column[\n\n.bold[Choose Appropriate Visualization Methods]\nSelect visualization methods that align with the nature of the data and the story you want to tell. Common geospatial visualizations include choropleth maps, heatmaps, dot density maps, and cartograms.\n\n.bold[Use Clear and Consistent Symbolization]\nUse colors, symbols, and patterns that effectively communicate the data without causing confusion. Stick to consistent symbolization throughout the visualization.\n\n.bold[Avoid Clutter and Complexity]\nKeep the visualization clean and uncluttered by avoiding unnecessary labels, icons, or details. Break down complex data into smaller, more manageable visualizations if needed.\n\n.bold[Provide Context]\nInclude relevant contextual information such as scale, orientation, and neighboring geographic features to help the audience understand the spatial relationships and context.\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#best-practices-considerations","position":39},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Best Practices & Considerations"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#best-practices-considerations-1","position":40},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Best Practices & Considerations"},"content":"Appropriate Visualization Methods\n\nClear and Consistent Symbolization\n\nAvoid Clutter and Complexity\n\nProvide Context\n\n.blue[Visual Design Elements]\n\n.blue[Interactivity]\n\n.blue[Clear Labeling and Legends]\n\nUser Experience\n\nAccompany Visualizations with Narrative\n\nBe Transparent\n].column[\n\n.bold[Visual Design Elements]\nChoose color palettes that are visually appealing, accessible, and effectively communicate the data. Other design elements such as size, shapes, weights, styles should also be carefully considered.\n\n.bold[Incorporate Interactivity]\nUtilize interactive elements (e.g., hover-over tooltips, zoom functions, or layer toggles) to enhance the audience’s exploration and understanding of the visualization.\n\n.bold[Provide Clear Labeling and Legends]\nEnsure that all visualizations have clear titles, labels, and legends to help the audience interpret the data and understand the visualization’s purpose.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-01-geospatial-data-storytelling#best-practices-considerations-1","position":41},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Best Practices & Considerations"},"type":"lvl2","url":"/sec-07-01-geospatial-data-storytelling#best-practices-considerations-2","position":42},{"hierarchy":{"lvl1":"Geospatial Data Storytelling","lvl2":"Best Practices & Considerations"},"content":"Appropriate Visualization Methods\n\nClear and Consistent Symbolization\n\nAvoid Clutter and Complexity\n\nProvide Context\n\nVisual Design Elements\n\nInteractivity\n\nClear Labeling and Legends\n\n.blue[User/Reader Experience]\n\n.blue[Accompany Visualizations with Narrative]\n\n.blue[Be Transparent]\n].column[\n\n.bold[Consider User/Reader Experience]:\nDesign the visualization with the user/reader in mind, ensuring it is easy to navigate, understand, and interact with. Test the visualization with users to gather feedback and improve the design.\n\n.bold[Accompany Visualizations with Narrative]\nUse narrative elements to provide context, highlight key insights, and guide the audience through the data story.\n\n.bold[Be Transparent About Data Sources and Limitations]\nClearly communicate the data source, accuracy, and any limitations to maintain transparency and credibility.\n\n]]","type":"content","url":"/sec-07-01-geospatial-data-storytelling#best-practices-considerations-2","position":43},{"hierarchy":{"lvl1":"Key Components of Maps"},"type":"lvl1","url":"/sec-07-02-key-components-of-maps","position":0},{"hierarchy":{"lvl1":"Key Components of Maps"},"content":"Sizes\n\nTypography\n\nColors\n\nCoordinate System\n\nArrangement","type":"content","url":"/sec-07-02-key-components-of-maps","position":1},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Sizes"},"type":"lvl2","url":"/sec-07-02-key-components-of-maps#sizes","position":2},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Sizes"},"content":"The size of the map:\n\na ‘full’ width figure in an A4 paper (e.g., thesis, reports)\n\na ‘half’ width figure in an A4 paper(i.e., to fit in one column of a two columns layout)\n\nas one of the element inside an A1 poster\n\na full A0 poster-size map\n\nin a Powerpoint slide (full-page vs. as an element)\n\nMap details\nHow much detail can be shown in:\n\na small A4-one-column map\n\na full A0 poster-size map\n\nTwo thinking directions:\n\nWhat should be added --- the ‘plus’\n\nWhat should be removed --- the ‘minus’\n\nDPI(dots-per-inch): the number of dots that will be drawn or printed within a one-inch span (in a single dimension).\n\nThink:\n\nWhat happens when you put an A0-size map/image inside an A4 paper?\n\nHow does a 2cm line in the original A0 map look on the A4 paper?\n\nTake home message:Always plan ahead about what size of map to be drawn.\n\n\n\nFigure 1:The same map export with different size, squeezed to the same display size.\n\n\n\nFigure 2:The same 4 maps, zoomed-in.","type":"content","url":"/sec-07-02-key-components-of-maps#sizes","position":3},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Typography"},"type":"lvl2","url":"/sec-07-02-key-components-of-maps#typography","position":4},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Typography"},"content":"Typography most often serves to label cartographic elements.\nIt is a “functional symbol” primarily, and secondarily an aesthetic element​ meaning that it carries cartographic meaning​ and is not simply “window dressing”.\n\nAbout Typography\n\nTypography, from Making Effective Maps: Cartographic Visualization for GIS\n\nFont Family (Serif, Sans-Serif, Decorative, Monospaced)\n\nFont Size (relative to map size)\n\nFont Weight (Bold (700) vs. Regular (400) vs. Light (300))\n\nFont style (italic vs. regular)\n\nUppercase, lowercase, title case\n\nWhat is the differences between Sans Serif fonts and Serif fonts?\n\n\n\nFigure 3:Some example of Sans-Serif fonts (left) and Serif fonts (right).\n\n\n\nFigure 4:Text elements.\n\nThings to be considered:\n\nVisibility: make sure the labels can be viewed without zoom-in.\n\nHierarchy: use different sizes, weights, or styles to show hierarchy of labels.\n\nConsistency: use the same typeface to show labels in the same level.\n\nLicense: make sure the font can be used in your targeted publication or is there any restriction/subscription-needed\n\nPublication requirement: some journal requested that some specific fonts should be used for some of the map elements.\n\nTake home message:\nThe top priority is to ensure that the text is clear and readable. Additionally, make sure the fonts are appropriate for your target venue.","type":"content","url":"/sec-07-02-key-components-of-maps#typography","position":5},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Colours"},"type":"lvl2","url":"/sec-07-02-key-components-of-maps#colours","position":6},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Colours"},"content":"In the realm of cartography and geovisualization, color is an essential tool that serves to delineate different components and highlight their significance, thereby facilitating effective visual communication. In designing geovisualization, the application of color goes beyond aesthetics, as it enables the clear differentiation of features and allows for the accurate representation of data, making it a crucial aspect of geovisualization design.\n\n\n\nTemperature of colors. Source: NASA Earth Observatory: \n\nArctic Chill Sweeps U.S.\n\nThings to considered while selecting color(s):\n\nThe targeted  audiences or venues: color or black and white (and grey)?, colorblind? etc....\n\nTypes of values:\n\nQualitative/Categorical\n\nQuantitative/Sequential:\n\ndiscrete: Q1, Q2, Q3, Q4; levels after ‘breaks’; age groups...\n\ncontinuous: scaled data from 0 to 1, with a min-value and max-value, exact age...\n\nDiverging: with a center value (e.g., 0)\n\n\n\nDiscrete vs. Continuous.\n\nTemperature of colors:\n\ncold colors for low values,\n\nhot colors for high values, etc.\n\n\n\nColor temperature from Wikipedia.\n\nThe meaning of data:\n\ngreen-series colors for greeneries level, or safety level, etc.\n\nred, orange colors for dangerous level, or warning level...\n\n\n\nFigure 6:Some example of colormaps from \n\nMatplotlib.\n\n\n\nFigure 7:Various qualitative colormap from \n\nSeaborn.\n\nTwo basic color models:\n\nCMYK: allows for more precise control over how colors appear on printed materials.\n\nfour integer values ranging from 0 to 100, each value corresponding to the percentage of ink coverage for Cyan, Magenta, Yellow, and blacK components.\n\nRGB: allows for precise control over how colors appear on digital devices.\n\nthree integer values ranging from 0 to 255, each value corresponding to the intensity of the Red, Green, and Blue lights.\n\nHow to use colors in Python (Matplotlib):\n\nnamed colors: 'red', 'blue', 'green', 'white', \n\nfull list here\n\nxkcd colors: 'xkcd:off white', \n\nfull list here\n\nspecifying R, G, & B in the ranging from 0 to 1 (divided by 255): (0.1, 0.2, 0.5)\n\nspecifying R, G, B, & alpha in the ranging from 0 to 1 (alpha as proportion): (0.1, 0.2, 0.5, 0.7)\n\nspecifying RGB hex code: '#0f0f0f'\n\nspecifying RGBA hex code: '#0f0f0fff'","type":"content","url":"/sec-07-02-key-components-of-maps#colours","position":7},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Coordinate System"},"type":"lvl2","url":"/sec-07-02-key-components-of-maps#coordinate-system","position":8},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Coordinate System"},"content":"All maps are drawn with a specific coordinate reference system (CRS), which defines how the geographic coordinates of features on the Earth’s surface are represented in a flat, two-dimensional plane (i.e., map). There are two main types of CRS: unprojected and projected.\n\nUnprojected CRS\n\nUses latitude (N-S) and longitude (E-W) coordinates in degrees.\n\nRepresents Earth’s curved surface.\n\nProjected CRS\n\nTransforms Earth’s curved surface into a flat map (in length, e.g. meters).\n\nDifferent types:\n\nMercator: Preserves angles and directions, used in navigation.\n\nEqual Area: Preserves area, useful for spatial analysis.\n\nConic: Preserves shape and angles, used for mid-latitude regions.\n\nEach map projection serves different purposes and has its own advantages and disadvantages in terms of preserving shape, area, distance, and direction. The choice of projection depends on the specific needs and applications of the map.\n\n\n\nFigure 8:[Try and view the differences of various projections in \n\nThe Morphing Map Project.\n\n\n\nFigure 9:The four countries in three different projections.","type":"content","url":"/sec-07-02-key-components-of-maps#coordinate-system","position":9},{"hierarchy":{"lvl1":"Key Components of Maps","lvl3":"How to use CRS in Python","lvl2":"Coordinate System"},"type":"lvl3","url":"/sec-07-02-key-components-of-maps#how-to-use-crs-in-python","position":10},{"hierarchy":{"lvl1":"Key Components of Maps","lvl3":"How to use CRS in Python","lvl2":"Coordinate System"},"content":"import geopandas as gpd\n# read the file\nsingapore = gpd.read_file('../path_to_file/singapore.shp')\nprint(singapore.crs)  # to show the projection info from the saved file\n\n# use .to_crs() to convert between projections, usually from or to EPSG:4326\n\n# check EPSG.io website, 3414 is the code for SVY21 / Singapore TM,\n# TM means Transverse Mercator, see https://epsg.io/3414 for details\nsg_prjd = singapore.to_crs('epsg:3414')\n# OR\n## find the targeted crs string, something look like this:\ntargeted_crs = '+proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs +type=crs'\nsg_prjd = singapore.to_crs(targeted_crs)\n","type":"content","url":"/sec-07-02-key-components-of-maps#how-to-use-crs-in-python","position":11},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Arrangement"},"type":"lvl2","url":"/sec-07-02-key-components-of-maps#arrangement","position":12},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Arrangement"},"content":"Arrangement is about the position of every element on map.\n\nWhere to put what\n\nWhich area of a map/paper will be seen first by the readers?\n\nThe hierarchy of information\n\nShould we draw North arrow and scale bar?\n\nIf it is a series of maps, the second and later maps could ignore the N-arrow and scale bar, for the sake of simplicity and readability.\n\nCollective/shared legend, or separate legends for every map?\n\nIn a multi-subplots layout setting, the elements in the legend are usually same, so that the colors/sizes could be compared between subplots---in this case, one large shared legend is sufficient.\n\nFigure title\n\nDo we need one for a map that would be placed in a report/thesis?\n\nIt is a common practice that if the map comes with a figure caption (e.g., Fig X. figure title) then the title on top of the map should be removed.\n\nThe external (out-of-studying-scope) area\n\nIt is a better idea to draw these external area with light grey or something less attractive.","type":"content","url":"/sec-07-02-key-components-of-maps#arrangement","position":13},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Summary"},"type":"lvl2","url":"/sec-07-02-key-components-of-maps#summary","position":14},{"hierarchy":{"lvl1":"Key Components of Maps","lvl2":"Summary"},"content":"Basics of mapping\n\nThings to be considered and planned while visualizing spatial patterns:\n\nSizes: The sizes of maps and each individual element (line width, point size, etc.) in a static image affect the visibility and aesthetics of the visualization.\n\nTypography: The visibility of text is the top priority.\n\nColors: Consider the color temperature, relation to the subject, targeted venue, etc.\n\nCoordinate System: Choose a commonly used and suitable projection for the targeted area.\n\nArrangement: Carefully consider the hierarchy of information and the placement of various elements in the map or visualization.","type":"content","url":"/sec-07-02-key-components-of-maps#summary","position":15},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy"},"type":"lvl1","url":"/sec-07-03-visual-hierarchy","position":0},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy"},"content":"\n\n.square[Map elements .dot[] Visual Hierarchy]\n\n.headnote.square.bold.x-large[Geovisualisation I]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy","position":1},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Map Elements"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#map-elements","position":2},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Map Elements"},"content":"\n\n.footnote-right.small.square[\n\nsource: ESRI]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#map-elements","position":3},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Map Elements"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#map-elements-1","position":4},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Map Elements"},"content":"].column[\n\nTitle should be easily identifiable as the map’s title through its size and positioning. Sub-titles are best in a smaller type size.\n\nLegend is a graphic guide that should comprise symbols, including colours, styles and patterns, which are not necessarily familiar to or known by the reader. A well-designed map should involve minimal reference to the legend.\n\nInsets allow the cartographer to show areas at a more detailed scale or to reposition features that would have otherwise ‘fallen’ just off the sheet to make best use of the available page and keep the main mapping at the most appropriate scale. They may also include an overview of where the region is in a wider geographical context, known as a locator map.\n]]\n.footnote-right.small.square[\n\nLayout, balance, and visual hierarchy in map design in “The Routledge Handbook of Mapping and Cartography”]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#map-elements-1","position":5},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Map Elements"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#map-elements-2","position":6},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Map Elements"},"content":"].column[\n\nCharts and figures are common to thematic maps showing geostatistical or geo-numerical data. They should be included only if they add weight to the message of the map.\n\nNorth arrow or any other directional indicator is only required if the orientation is not obvious. Arrows with a clear and suitably long North-South line are easier to use than more decorative ones.\n\nScalebar allows users to make measurements on the map and is a quick reference to size objects. It does not have to represent distance, for example it can represent travel time.\n\nBorder is a line encasing the edges of the mapped area or a line framing the entire map layout. It is sometimes known as a neatline, a term also used for a finer border line that may form the outer part of a grid and may contain graticule intersections.\n]]\n.footnote-right.small.square[\n\nLayout, balance, and visual hierarchy in map design in “The Routledge Handbook of Mapping and Cartography”]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#map-elements-2","position":7},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Bad Map Example"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#bad-map-example","position":8},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Bad Map Example"},"content":".small[\n\nLegend color\n\nLegend range and numbers\n\nLocation of source info\n\nNorth arrow (complicated)\n\nScale bar (complicated and alignment)\n\nInset map too large\n\nInfo about the numbers\n]\n].column[\n\n\n.footnote-right.small.square[\n\nsource: Chapter 7 Good Map Making Tips]\n\n]]\n\nclass: left, middle\n\n.split-20[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#bad-map-example","position":9},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Improved Map Example"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#improved-map-example","position":10},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Improved Map Example"},"content":".small[\n\nReplaced legend title with the description of the data column\n\nSimplified north arrow and scale bar\n\nColours changed to divergent colormap, with the center value to be the median\n\nSmaller inset map, better emphasized of main map\n]\n].column[\n\n\n.footnote-right.small.square[\n\nsource: Chapter 7 Good Map Making Tips]\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#improved-map-example","position":11},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Visual Hierarchy"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#visual-hierarchy","position":12},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Visual Hierarchy"},"content":"\n\nAbout how people ‘look’ for information.\n\nclass: center, middle\n\n.footnote.small.square[\n\nhttps://​clay​.global​/blog​/web​-design​-guide​/visual​-hierarchy​-web​-design]\n\nclass: center, middle\n\n.footnote.small.square[\n\nhttps://​wpdean​.com​/what​-is​-visual​-hierarchy​-in​-web​-design/]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#visual-hierarchy","position":13},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Size / Scale Hierarchy"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#size-scale-hierarchy","position":14},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Size / Scale Hierarchy"},"content":"\n\n.footnote.small.square[\n\nhttps://​admiral​.digital​/what​-is​-visual​-hierarchy​-and​-why​-is​-it​-important/]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#size-scale-hierarchy","position":15},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Size / Scale Hierarchy"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#size-scale-hierarchy-1","position":16},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Size / Scale Hierarchy"},"content":"\n\n.footnote.small.square[\n\nhttps://​visme​.co​/blog​/visual​-hierarchy/]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#size-scale-hierarchy-1","position":17},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Size / Scale Hierarchy"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#size-scale-hierarchy-2","position":18},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Size / Scale Hierarchy"},"content":"\n\n.footnote.small.square[\n\nhttps://​visme​.co​/blog​/visual​-hierarchy/]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#size-scale-hierarchy-2","position":19},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Colour"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#colour","position":20},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Colour"},"content":"].column[\n\n]]\n\n.footnote.small.square[\n\nhttps://​clay​.global​/blog​/web​-design​-guide​/visual​-hierarchy​-web​-design]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#colour","position":21},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Colour"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#colour-1","position":22},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Colour"},"content":"\n\n.footnote.small.square[\n\nhttps://​visme​.co​/blog​/visual​-hierarchy/]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#colour-1","position":23},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Colour"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#colour-2","position":24},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Colour"},"content":".split-50[.column[\n\n].column[\n\n]]\n\n.footnote.small.square[\n\nLayout, balance, and visual hierarchy in map design in “The Routledge Handbook of Mapping and Cartography”]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#colour-2","position":25},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Colour"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#colour-3","position":26},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Colour"},"content":"\n\n.footnote.small.square[\n\nScreenshot from Mapbox Gallery, Community Templates]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#colour-3","position":27},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - How people read"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-how-people-read","position":28},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - How people read"},"content":"\n\n.footnote.small.square[\n\nhttps://​www​.interaction​-design​.org​/literature​/topics​/visual​-hierarchy]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#layout-how-people-read","position":29},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - How people read"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-how-people-read-1","position":30},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - How people read"},"content":"\n\n.footnote-left.small.square[\n\nhttps://​www​.interaction​-design​.org​/literature​/topics​/visual​-hierarchy​?srsltid​=​AfmBOopgpNcuvrThNqPlsGQEKeRgygYpwrRwQ2TpCL0EJ9K2v1OSIOl5]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#layout-how-people-read-1","position":31},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third","position":32},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"content":"\n\n.footnote.small.square[\n\nhttps://​www​.interaction​-design​.org​/literature​/article​/the​-rule​-of​-thirds​-know​-your​-layout​-sweet​-spots]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third","position":33},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-1","position":34},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"content":"\n\n.footnote.small.square[\n\nhttps://​www​.capturelandscapes​.com​/the​-rule​-of​-thirds​-explained/]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-1","position":35},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-2","position":36},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"content":"\n\n.footnote-right.small.square[\n\nhttps://​admiral​.digital​/what​-is​-visual​-hierarchy​-and​-why​-is​-it​-important/]\n\nclass: center, middle\n.split-40[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-2","position":37},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-3","position":38},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"content":".footnote-left.small.square[\n\nhttps://​www​.artworkflowhq​.com​/resources​/the​-rule​-of​-thirds​-in​-graphic​-design]\n\n].column[\n\n\n]]\n\nclass: center, middle\n.split-40[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-3","position":39},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-4","position":40},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"content":".footnote-left.small.square[\n\nhttps://​community​.esri​.com​/t5​/esri​-training​-blog​/using​-artistic​-inspiration​-for​-cartographic​/ba​-p​/903968]\n\n].column[\n\n\n]]\n\nclass: center, middle\n.split-40[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-4","position":41},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-5","position":42},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Rule of Third"},"content":".footnote-left.small.square[\n\nhttps://​community​.esri​.com​/t5​/esri​-training​-blog​/using​-artistic​-inspiration​-for​-cartographic​/ba​-p​/903968]\n\n].column[\n\n]]\n\nclass: center, middle\n\n[\n\nhttps://​onlinephototools​.com​/image​-tools​/image​-rule​-of​-thirds​-grid​-overlay​-tool/]\n\nclass: center, middle\n\nclass: center, middle\n\nclass: center, middle\n\nclass: center, middle\n\nclass: center, middle\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#layout-rule-of-third-5","position":43},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Common Ratio - Landscape"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-common-ratio-landscape","position":44},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Common Ratio - Landscape"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#layout-common-ratio-landscape","position":45},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Common Ratio - Portrait"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#layout-common-ratio-portrait","position":46},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Layout - Common Ratio - Portrait"},"content":"\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#layout-common-ratio-portrait","position":47},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - In Design"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#spacing-in-design","position":48},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - In Design"},"content":"\n\n.footnote.small.square[\n\nhttps://​visme​.co​/blog​/visual​-hierarchy/]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#spacing-in-design","position":49},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - Definition"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#spacing-definition","position":50},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - Definition"},"content":"\n\n.footnote.small.square[\n\nhttps://​clay​.global​/blog​/web​-design​-guide​/visual​-hierarchy​-web​-design]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#spacing-definition","position":51},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - Definition"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#spacing-definition-1","position":52},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - Definition"},"content":"\n\n.footnote.small.square[\n\nhttps://​www​.google​.com/]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-07-03-visual-hierarchy#spacing-definition-1","position":53},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - For Balance"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#spacing-for-balance","position":54},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - For Balance"},"content":"].column[\n\n]]\n\n.footnote-left.small.square[\n\nhttps://​www​.esri​.com​/arcgis​-blog​/products​/arcgis​-pro​/mapping​/design​-principles​-for​-cartography]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#spacing-for-balance","position":55},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - Example"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#spacing-example","position":56},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - Example"},"content":"\n\n.footnote.small.square[\n\nhttps://​earthobservatory​.nasa​.gov​/images​/152333​/arctic​-chill​-sweeps​-us]\n\nclass: center, middle","type":"content","url":"/sec-07-03-visual-hierarchy#spacing-example","position":57},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - Example"},"type":"lvl2","url":"/sec-07-03-visual-hierarchy#spacing-example-1","position":58},{"hierarchy":{"lvl1":"The Map Layout and Visual Hierarchy","lvl2":"Spacing - Example"},"content":"\n\n.footnote-left.small.square[\n\nA spatio-temporal analysis investigating completeness and inequalities of global urban building data in OpenStreetMap]","type":"content","url":"/sec-07-03-visual-hierarchy#spacing-example-1","position":59},{"hierarchy":{"lvl1":"Tools and Resources"},"type":"lvl1","url":"/sec-07-04-tools","position":0},{"hierarchy":{"lvl1":"Tools and Resources"},"content":"\n\n.square[]\n\n.headnote.square.bold.x-large[Geovisualisation I]\n\nclass: left, middle","type":"content","url":"/sec-07-04-tools","position":1},{"hierarchy":{"lvl1":"Tools and Resources","lvl3":"Tools and Resources - Data Visualization Tools"},"type":"lvl3","url":"/sec-07-04-tools#tools-and-resources-data-visualization-tools","position":2},{"hierarchy":{"lvl1":"Tools and Resources","lvl3":"Tools and Resources - Data Visualization Tools"},"content":".split-50[.column[\n\n.bold[Carto]: A location intelligence and data visualization platform for creating interactive maps and geospatial applications.\n\n.bold[Tableau]: A data visualization and storytelling tool that allows you to create interactive and engaging visualizations.\n\n.bold[Power BI]: A business analytics platform from Microsoft for creating data visualizations, reports, and interactive dashboards.\n\n.bold[QGIS]: A free and open-source GIS software that enables geospatial data visualization and analysis.\n\n.bold[ArcGIS Online]: A web-based GIS platform by Esri that enables users to create, share, and analyze geospatial data, maps, and apps.\n\n].column[\n\n.bold[Mapbox]: A platform that offers customizable map designs tools to create interactive maps and location-based applications.\n\n.bold[\n\nKepler.gl]: A geospatial data visualization tool that allows users to create large-scale visualizations for geospatial data exploration.\n\n.bold[\n\nFlowmap.gl]: A web-based tool designed for visualizing and exploring spatial interactions using animated flow maps.\n\n.bold[Plotly]: A versatile data library that can be used with various programming languages, offering a wide range of interactive charts, maps, and plots.\n\n.bold[Bokeh]: An interactive data visualization library for Python, providing elegant, concise construction of versatile graphics and interactive plots.\n\n]]\n\nclass: left, middle\nbackground-image: url(resources/w11-img/carto_webpage.png)","type":"content","url":"/sec-07-04-tools#tools-and-resources-data-visualization-tools","position":3},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Carto"},"type":"lvl2","url":"/sec-07-04-tools#carto","position":4},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Carto"},"content":".footnote-left[\n\nCarto link]\n\nclass: left, middle\nbackground-image: url(resources/w11-img/mapbox_3D.png)","type":"content","url":"/sec-07-04-tools#carto","position":5},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Mapbox 3D buildings"},"type":"lvl2","url":"/sec-07-04-tools#mapbox-3d-buildings","position":6},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Mapbox 3D buildings"},"content":".footnote[\n\nMapbox link]\n\nclass: left, middle\nbackground-image: url(resources/w11-img/kepler-gl.png)","type":"content","url":"/sec-07-04-tools#mapbox-3d-buildings","position":7},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Kepler.gl demo"},"type":"lvl2","url":"/sec-07-04-tools#kepler-gl-demo","position":8},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Kepler.gl demo"},"content":".footnote[\n\nKepler.gl link]\n.footnote-left[\n\nDemo link]\n\nclass: left, top\nbackground-image: url(resources/w11-img/flowmap-gl.png)","type":"content","url":"/sec-07-04-tools#kepler-gl-demo","position":9},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Flowmap.gl demo"},"type":"lvl2","url":"/sec-07-04-tools#flowmap-gl-demo","position":10},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Flowmap.gl demo"},"content":".footnote[\n\nFlowmap.gl link]\n.footnote-left[\n\nDemo link]\n\nclass: right, top\nbackground-image: url(resources/w11-img/plotly_dash-2.png)","type":"content","url":"/sec-07-04-tools#flowmap-gl-demo","position":11},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Plot.ly Dash webpage"},"type":"lvl2","url":"/sec-07-04-tools#plot-ly-dash-webpage","position":12},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Plot.ly Dash webpage"},"content":".footnote[\n\nPlotly - Dash link]\n\nclass: left, middle\nbackground-image: url(resources/w11-img/bokeh_webpage.png)","type":"content","url":"/sec-07-04-tools#plot-ly-dash-webpage","position":13},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Bokeh webpage"},"type":"lvl2","url":"/sec-07-04-tools#bokeh-webpage","position":14},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Bokeh webpage"},"content":".footnote[\n\nBokeh link]\n\nclass: right, top\nbackground-image: url(resources/w11-img/storymap-js_webpage.png)","type":"content","url":"/sec-07-04-tools#bokeh-webpage","position":15},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Storymap.js (Knight-lab) webpage"},"type":"lvl2","url":"/sec-07-04-tools#storymap-js-knight-lab-webpage","position":16},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Storymap.js (Knight-lab) webpage"},"content":".footnote[\n\nStorymap.js link]\n\nclass: left, bottom\nbackground-image: url(resources/w11-img/odyssey-js_webpage.png)","type":"content","url":"/sec-07-04-tools#storymap-js-knight-lab-webpage","position":17},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Odyssey.js (Cartodb) webpage"},"type":"lvl2","url":"/sec-07-04-tools#odyssey-js-cartodb-webpage","position":18},{"hierarchy":{"lvl1":"Tools and Resources","lvl2":"Odyssey.js (Cartodb) webpage"},"content":".footnote[\n\nOdyssey.js link]","type":"content","url":"/sec-07-04-tools#odyssey-js-cartodb-webpage","position":19},{"hierarchy":{"lvl1":"Tools and Resources","lvl3":"Tools and Resources","lvl2":"Odyssey.js (Cartodb) webpage"},"type":"lvl3","url":"/sec-07-04-tools#tools-and-resources","position":20},{"hierarchy":{"lvl1":"Tools and Resources","lvl3":"Tools and Resources","lvl2":"Odyssey.js (Cartodb) webpage"},"content":"","type":"content","url":"/sec-07-04-tools#tools-and-resources","position":21},{"hierarchy":{"lvl1":"Tools and Resources","lvl4":"Programming Languages and Libraries","lvl3":"Tools and Resources","lvl2":"Odyssey.js (Cartodb) webpage"},"type":"lvl4","url":"/sec-07-04-tools#programming-languages-and-libraries","position":22},{"hierarchy":{"lvl1":"Tools and Resources","lvl4":"Programming Languages and Libraries","lvl3":"Tools and Resources","lvl2":"Odyssey.js (Cartodb) webpage"},"content":"Python: A popular programming language with libraries for data analysis, visualization, and mapping, such as Matplotlib, Seaborn, Bokeh, and Folium.\n\nR: A programming language designed for statistical computing and visualization, with packages like ggplot2 and leaflet for mapping and data visualization.\n\nJavaScript: A versatile programming language for building interactive web-based visualizations, with libraries such as D3.js and Leaflet.js.","type":"content","url":"/sec-07-04-tools#programming-languages-and-libraries","position":23},{"hierarchy":{"lvl1":"Tools and Resources","lvl4":"Storytelling Resources","lvl3":"Tools and Resources","lvl2":"Odyssey.js (Cartodb) webpage"},"type":"lvl4","url":"/sec-07-04-tools#storytelling-resources","position":24},{"hierarchy":{"lvl1":"Tools and Resources","lvl4":"Storytelling Resources","lvl3":"Tools and Resources","lvl2":"Odyssey.js (Cartodb) webpage"},"content":"“Storytelling with Data” by Cole Nussbaumer Knaflic: A book that provides practical tips and techniques for creating effective data stories.\n\nThe Pudding: A digital publication that uses data visualization and storytelling to explore a wide range of topics.\n\nThe Data Visualisation Catalogue: A comprehensive online resource showcasing various data visualization examples and use cases, offering guidance and inspiration for creating effective visualizations across diverse industries and applications.","type":"content","url":"/sec-07-04-tools#storytelling-resources","position":25},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility"},"type":"lvl1","url":"/sec-07-05-an-example","position":0},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility"},"content":"\n\n.square[Motivation .dot[] Flow Estimation .dot[] Mobility .dot[] Accessibility .dot[] Reflection ]\n\n.headnote.square.bold.x-large[Geovisualisation I]\n\nclass: right, bottom\nbackground-image: url(resources/w11-img/example-1-link.png)","type":"content","url":"/sec-07-05-an-example","position":1},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl2":"The Demonstration"},"type":"lvl2","url":"/sec-07-05-an-example#the-demonstration","position":2},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl2":"The Demonstration"},"content":".footnote[\n\nthe link]\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-07-05-an-example#the-demonstration","position":3},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Motivation","lvl2":"The Demonstration"},"type":"lvl3","url":"/sec-07-05-an-example#motivation","position":4},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Motivation","lvl2":"The Demonstration"},"content":"","type":"content","url":"/sec-07-05-an-example#motivation","position":5},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Background","lvl3":"Motivation","lvl2":"The Demonstration"},"type":"lvl4","url":"/sec-07-05-an-example#background","position":6},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Background","lvl3":"Motivation","lvl2":"The Demonstration"},"content":"].column[\nAs one of the most densely populated countries in the world, .red[Singapore faces challenges in ensuring equal access to healthcare for all]. The high population density has increased the demand for healthcare services, putting strain on the country’s medical infrastructure.\n\nAlthough clinics are located in every neighborhood, the quality and intensity of healthcare services vary in different parts of the city-state, leading to disparities in access.\n\nAdditionally, healthcare services in different geographic areas may experience varying levels of demand, subsequently affecting their ability to provide high-quality care to patients.\n\nIt is thus critical to assess the spatial distribution of the availability and accessibility of healthcare services.\n]]\n\nclass: left, middle","type":"content","url":"/sec-07-05-an-example#background","position":7},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Motivation","lvl2":"The Demonstration"},"type":"lvl3","url":"/sec-07-05-an-example#motivation-1","position":8},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Motivation","lvl2":"The Demonstration"},"content":".split-50[.column[","type":"content","url":"/sec-07-05-an-example#motivation-1","position":9},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Problem","lvl3":"Motivation","lvl2":"The Demonstration"},"type":"lvl4","url":"/sec-07-05-an-example#problem","position":10},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Problem","lvl3":"Motivation","lvl2":"The Demonstration"},"content":"The spatial distribution of the availability and accessibility of healthcare services requires more exploration and analysis.","type":"content","url":"/sec-07-05-an-example#problem","position":11},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Audience","lvl3":"Motivation","lvl2":"The Demonstration"},"type":"lvl4","url":"/sec-07-05-an-example#audience","position":12},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Audience","lvl3":"Motivation","lvl2":"The Demonstration"},"content":"Urban planners\n\nGeneral Public","type":"content","url":"/sec-07-05-an-example#audience","position":13},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Data","lvl3":"Motivation","lvl2":"The Demonstration"},"type":"lvl4","url":"/sec-07-05-an-example#data","position":14},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Data","lvl3":"Motivation","lvl2":"The Demonstration"},"content":"ISP Clinic locations\n\nPopulation distribution\n\nRoad network\n\nHexagons (800m size)\n\n].column[","type":"content","url":"/sec-07-05-an-example#data","position":15},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Solution","lvl3":"Motivation","lvl2":"The Demonstration"},"type":"lvl4","url":"/sec-07-05-an-example#solution","position":16},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Solution","lvl3":"Motivation","lvl2":"The Demonstration"},"content":"This project presents a framework to measure the healthcare intensity by combining two popular models: radiation models and 2-step floating catchment area (2SFCA).","type":"content","url":"/sec-07-05-an-example#solution","position":17},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Visualization","lvl3":"Motivation","lvl2":"The Demonstration"},"type":"lvl4","url":"/sec-07-05-an-example#visualization","position":18},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl4":"Visualization","lvl3":"Motivation","lvl2":"The Demonstration"},"content":"After the flows were estimated and healthcare intensity were calculated, we show the results below in 4 sections:\n\nFlow Estimation Map\n\nMovements between Planning Area\n\nDistribution of Travel Distances\n\nService Intensity Map\n\n]]\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-07-05-an-example#visualization","position":19},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Flow Estimation Map","lvl2":"The Demonstration"},"type":"lvl3","url":"/sec-07-05-an-example#flow-estimation-map","position":20},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Flow Estimation Map","lvl2":"The Demonstration"},"content":"Estimated flow using \n\nradiation models.\n\nStatic, simple, map using arrows to show directions and colors to show above or below median.\n].column[\n\n]]\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-07-05-an-example#flow-estimation-map","position":21},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Flow Estimation Map","lvl2":"The Demonstration"},"type":"lvl3","url":"/sec-07-05-an-example#flow-estimation-map-1","position":22},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Flow Estimation Map","lvl2":"The Demonstration"},"content":"Interactive map with the same data, using \n\nFlowmap.gl: \n\nLink\n].column[\n\n]]\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-07-05-an-example#flow-estimation-map-1","position":23},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Flow Estimation Map","lvl2":"The Demonstration"},"type":"lvl3","url":"/sec-07-05-an-example#flow-estimation-map-2","position":24},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Flow Estimation Map","lvl2":"The Demonstration"},"content":"Aggregated flows by planning areas, visualize using Sankey graph (or Alluvial graph): \n\nInteractive Link\n].column[\n\n]]\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-07-05-an-example#flow-estimation-map-2","position":25},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Mobility","lvl2":"The Demonstration"},"type":"lvl3","url":"/sec-07-05-an-example#mobility","position":26},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Mobility","lvl2":"The Demonstration"},"content":"The frequency distribution of travel distance, grouped by regions: \n\nInteractive Link\n].column[\n\n]]\n\nclass: left, middle\n.split-20[.column[","type":"content","url":"/sec-07-05-an-example#mobility","position":27},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Accessibility Map","lvl2":"The Demonstration"},"type":"lvl3","url":"/sec-07-05-an-example#accessibility-map","position":28},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Accessibility Map","lvl2":"The Demonstration"},"content":"Accessibility to ISP Clinics estimated using \n\n2SFCA.\nHexagon shows the service provider intensity. Circle shows the accessibility.\n\nInteractive map: \n\nLink\n].column[\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-05-an-example#accessibility-map","position":29},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Reflection","lvl2":"The Demonstration"},"type":"lvl3","url":"/sec-07-05-an-example#reflection","position":30},{"hierarchy":{"lvl1":"An Example - The Healthcare Resource Accessibility","lvl3":"Reflection","lvl2":"The Demonstration"},"content":"].column[\n\n.bold[What was done]: The visualizations show some maps and graphs to display the population mobility for accessing healthcare service (ISP Clinic).\n\n.bold[Resolution]: For visualization purpose, the spatial units were set to 800m hexagon size, which could be too large for analyzing walkable neighborhoods (400m).\n\n.bold[Lack of spatial]: How spatial autocorelation, heterogeneity, or other spatial interactions effects may exists are not discussed.\n\n.bold[Far from pratical]: The analysis remains conceptual, and thus, further development is required before it can effectively inform practical policy-making.\n\n.bold[Other level of resource]: The visualization did not present the other level of healthcare resources, e.g., polyclinics and hospitals. Visualization for Comparison can be challenging.\n]]","type":"content","url":"/sec-07-05-an-example#reflection","position":31},{"hierarchy":{"lvl1":"Geospatial Ethics"},"type":"lvl1","url":"/sec-07-06-geospatial-ethics","position":0},{"hierarchy":{"lvl1":"Geospatial Ethics"},"content":"\n\n.square[Ethics .dot[] Code and Rules of Conduct .dot[] Geospatial Privacy]\n\n.headnote.square.bold.x-large[Geovisualisation II]\n\nclass: left, middle","type":"content","url":"/sec-07-06-geospatial-ethics","position":1},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"What is Ethics"},"type":"lvl2","url":"/sec-07-06-geospatial-ethics#what-is-ethics","position":2},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"What is Ethics"},"content":"“Ethics, also known as moral philosophy, involves systematic intellectual reflection on morality in general ... or specific moral concerns in particular. The former can be called .red[theoretical ethics], and the latter .red[applied ethics], though the two are closely related. One realm of applied ethics that ahs garnered considerable attention outside philosophy focuses on professional conduct; thus, .red[the moral questions asked by scientists], as well as those in, for instance, the fields of law, medicine, and business, are legitimate components of ethical inquiry.”\n\nIn \n\nProctor, James D (1998). Ethics in geography: giving moral form tot he geographical imagination. Area 30.1, p. 9.\n\n.red.bold[Ethics is not what you do, but .underline[why] you do it.]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-07-06-geospatial-ethics#what-is-ethics","position":3},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Ethics in geospatial data analysis"},"type":"lvl2","url":"/sec-07-06-geospatial-ethics#ethics-in-geospatial-data-analysis","position":4},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Ethics in geospatial data analysis"},"content":"","type":"content","url":"/sec-07-06-geospatial-ethics#ethics-in-geospatial-data-analysis","position":5},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl3":"Definition","lvl2":"Ethics in geospatial data analysis"},"type":"lvl3","url":"/sec-07-06-geospatial-ethics#definition","position":6},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl3":"Definition","lvl2":"Ethics in geospatial data analysis"},"content":"].column[\nEthics in geospatial data analysis refers to the application of moral principles and guidelines to ensure that the collection, analysis, and use of geospatial data are .red[conducted responsibly and with respect for individuals, communities, and the environment].\n\nA GIS Code-of-Ethics\n\nRules of Conduct for Certified GIS Professionals\n\n]]\n\nclass: center, middle\n\n.split-30[.column[","type":"content","url":"/sec-07-06-geospatial-ethics#definition","position":7},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Code of Ethics"},"type":"lvl2","url":"/sec-07-06-geospatial-ethics#code-of-ethics","position":8},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Code of Ethics"},"content":"The link: \n\nCode-of-Ethics\n].column[ ]]\n\nclass: center, middle\n\n.split-30[.column[","type":"content","url":"/sec-07-06-geospatial-ethics#code-of-ethics","position":9},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Rules of Conduct"},"type":"lvl2","url":"/sec-07-06-geospatial-ethics#rules-of-conduct","position":10},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Rules of Conduct"},"content":"The link: \n\nRules of Conduct\n].column[ ]]\n\nclass: center, middle","type":"content","url":"/sec-07-06-geospatial-ethics#rules-of-conduct","position":11},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Ethics is not legality"},"type":"lvl2","url":"/sec-07-06-geospatial-ethics#ethics-is-not-legality","position":12},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Ethics is not legality"},"content":"\n\nEthics is not a front-line of defense against wrong-doing.\n\nEthics is more like a touchstone for professionals to identify and resolve ethical dilemmas that they encounter in their research.\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-07-06-geospatial-ethics#ethics-is-not-legality","position":13},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Geospatial Privacy"},"type":"lvl2","url":"/sec-07-06-geospatial-ethics#geospatial-privacy","position":14},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Geospatial Privacy"},"content":"].column[\n\nIn geospatial research, particularly in people-related topics like health, crime, and disease-related studies, we often encounter privacy concerns.\n\nSometimes, these concerns are the reason we cannot access certain data, such as the COVID-19 distribution data in the early days of the pandemic.\n\nIn the early days of a situation involving small case numbers, the data can be traced back to individual households or persons, potentially creating unnecessary problems for the people involved. As a result, government agencies may be unable to disclose such data.\n\nbias and inequality, privacy\n\nIn other cases, privacy becomes a crucial aspect to consider while writing the results, ensuring that we do not reveal any private information in our reports or manuscripts.\n\nMaking sure the anonyminity or de-identification could not be re-identified.\n]]\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-07-06-geospatial-ethics#geospatial-privacy","position":15},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Geospatial Privacy"},"type":"lvl2","url":"/sec-07-06-geospatial-ethics#geospatial-privacy-1","position":16},{"hierarchy":{"lvl1":"Geospatial Ethics","lvl2":"Geospatial Privacy"},"content":"Protecting geospatial information privacy involves employing various strategies to ensure that individuals’ personal information remains .red[secure] and .red[anonymous].\n].column[\n\n.bold[Data anonymization]:\nRemove or alter personally .red[identifiable information] from geospatial datasets. This can be achieved through techniques such as generalization, perturbation, or differential privacy.\n\n.bold[Geo-masking]:\nGeo-masking involves altering or obscuring the .red[precise location information] in geospatial data to protect individual privacy. This can be achieved by shifting, rotating, or perturbing the coordinates, or by introducing random noise to the location data. Geo-masking allows for the analysis of geospatial patterns and trends while maintaining a degree of anonymity for individuals or sensitive locations.\n\n.bold[Data aggregation]:\n.red[Combine data from multiple individuals or locations] to make it more difficult to trace information back to a specific person or place.\n\n.bold[Privacy-preserving data mining]:\nUtilize .red[data mining techniques] that protect privacy, such as k-anonymity, l-diversity, or t-closeness, to analyze geospatial data without revealing sensitive information.\n\n]]","type":"content","url":"/sec-07-06-geospatial-ethics#geospatial-privacy-1","position":17},{"hierarchy":{"lvl1":"A Final Closing Remark"},"type":"lvl1","url":"/sec-07-07-a-final-closing-remark","position":0},{"hierarchy":{"lvl1":"A Final Closing Remark"},"content":"\n\n.square[Visualisation .dot[] Good Elements .dot[] Some Bad Examples]\n\n.headnote.square.bold.x-large[Geovisualisation II]\n\nclass: left, middle\n\n.split-40[.column[","type":"content","url":"/sec-07-07-a-final-closing-remark","position":1},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Visualization?"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#visualization","position":2},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Visualization?"},"content":"The comic shows a .red[visualization] of the relationship between human proximity to cat and the intelligence of the person.\n\nVisualization is .red[the process of representing data or information] in a graphical or pictorial form .red[to communicate an idea, concept, or pattern] more effectively.\n\n].column[.justify[\n\n\n.footnote[.square[\n\nCat Proximity (xkcd.com/231). ]]\n]]\n]\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#visualization","position":3},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Why visualization?"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#why-visualization","position":4},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Why visualization?"},"content":"\n\nclass: left, middle\n\n.split-30[.column[","type":"content","url":"/sec-07-07-a-final-closing-remark#why-visualization","position":5},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Why visualization?"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#why-visualization-1","position":6},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Why visualization?"},"content":"Geovisualization is a series of explorations and analyses, that includes using various techniques and methods, e.g., thematic mapping, exploratory spatial data analysis, to uncover the underlying patterns, to get better understanding of geographical phenomena.\n].column[\n\n.square[MacEachren’s cartographic cube.]\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-07-a-final-closing-remark#why-visualization-1","position":7},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"What is a good visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#what-is-a-good-visualisation","position":8},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"What is a good visualisation"},"content":"A good data visualization effectively communicates complex information in a clear, concise, and engaging manner, allowing the audience to quickly understand the data’s key insights and messages.\n\n].column[\n\n.bold[Clear Purpose]:\nA well-defined purpose or goal helps guide the creation of the visualization, ensuring that it .red[addresses relevant questions and objectives].\n\n.bold[Appropriate Visual Encoding]:\nThe choice of .red[visual elements (e.g., color, size, position)] should accurately represent the data and facilitate easy comparison, pattern identification, and understanding.\n\n.bold[Clarity and Simplicity]:\nA good visualization should be .red[easy to comprehend], avoiding unnecessary complexity and clutter. Clear labeling, appropriate use of scale, and logical organization contribute to overall clarity.\n\n.bold[Meaningful Context]:\nProviding context through .red[labels, titles, captions, and reference points] helps the audience interpret the data more accurately and effectively.\n\n]]\n\nclass: left, middle\n.split-30[.column[","type":"content","url":"/sec-07-07-a-final-closing-remark#what-is-a-good-visualisation","position":9},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"What is a good visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#what-is-a-good-visualisation-1","position":10},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"What is a good visualisation"},"content":"A good data visualization effectively communicates complex information in a clear, concise, and engaging manner, allowing the audience to quickly understand the data’s key insights and messages.\n\n].column[\n\n.bold[Attention to Detail]:\nA well-crafted visualization pays attention to details such as .red[color palettes, fonts, and visual hierarchy], creating an aesthetically pleasing and professional-looking end product.\n\n.bold[Accessibility]:\nEnsuring that visualizations are .red[accessible to all readers], including those with color vision deficiency or other visual impairments, is an essential aspect of good data visualization.\n\n.bold[Interactivity and Responsiveness]:\nInteractive visualizations allow users to explore and customize the data presentation, .red[enhancing engagement] and understanding.\n\n.bold[Accuracy]:\nA good visualization accurately represents the underlying data, .red[avoiding distortion or misrepresentation].\n\n]]\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-07-07-a-final-closing-remark#what-is-a-good-visualisation-1","position":11},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Some examples and ideas for good visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#some-examples-and-ideas-for-good-visualisation","position":12},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Some examples and ideas for good visualisation"},"content":"","type":"content","url":"/sec-07-07-a-final-closing-remark#some-examples-and-ideas-for-good-visualisation","position":13},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl3":"Get some inspiration here:","lvl2":"Some examples and ideas for good visualisation"},"type":"lvl3","url":"/sec-07-07-a-final-closing-remark#get-some-inspiration-here","position":14},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl3":"Get some inspiration here:","lvl2":"Some examples and ideas for good visualisation"},"content":"Information is Beautiful\n\nData Viz Project\n].column[","type":"content","url":"/sec-07-07-a-final-closing-remark#get-some-inspiration-here","position":15},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl3":"Information is Beautiful","lvl2":"Some examples and ideas for good visualisation"},"type":"lvl3","url":"/sec-07-07-a-final-closing-remark#information-is-beautiful","position":16},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl3":"Information is Beautiful","lvl2":"Some examples and ideas for good visualisation"},"content":" ]]\n\nclass: left, middle\n.split-40[.column[","type":"content","url":"/sec-07-07-a-final-closing-remark#information-is-beautiful","position":17},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Some examples and ideas for good visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#some-examples-and-ideas-for-good-visualisation-1","position":18},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Some examples and ideas for good visualisation"},"content":"","type":"content","url":"/sec-07-07-a-final-closing-remark#some-examples-and-ideas-for-good-visualisation-1","position":19},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl3":"Get some inspiration here:","lvl2":"Some examples and ideas for good visualisation"},"type":"lvl3","url":"/sec-07-07-a-final-closing-remark#get-some-inspiration-here-1","position":20},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl3":"Get some inspiration here:","lvl2":"Some examples and ideas for good visualisation"},"content":"Information is Beautiful\n\nData Viz Project\n].column[","type":"content","url":"/sec-07-07-a-final-closing-remark#get-some-inspiration-here-1","position":21},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl3":"Data Viz Project","lvl2":"Some examples and ideas for good visualisation"},"type":"lvl3","url":"/sec-07-07-a-final-closing-remark#data-viz-project","position":22},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl3":"Data Viz Project","lvl2":"Some examples and ideas for good visualisation"},"content":" ]]\n\nclass: left, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#data-viz-project","position":23},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Statistics for better visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#statistics-for-better-visualisation","position":24},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Statistics for better visualisation"},"content":"Statistical tools play a crucial role in creating meaningful geospatial data visualizations and forming useful insights.\n\n.split-50[.column[\n\n.bold[Descriptive Statistics]:\nBasic descriptive statistics like mean, median, standard deviation and frequency distribution can help .red[summarize and describe] geospatial data.\n\n.bold[Data Classification]:\nMethods for classifying geospatial data, such as equal interval, quantile, natural breaks, and geometrical intervals help .red[organize and group data] for effective visualization and analysis.\n\n.bold[Spatial Autocorrelation]:\nSpatial autocorrelation techniques could measure the similarity between values in a given spatial dataset. This can help .red[identify spatial clusters or outliers] in the data.\n].column[\n\n.bold[Spatial Heterogeneity]:\nHeterogeneity refers to the variability of a variable across a study area. Spatial heterogeneity can be analyzed using techniques like geographically weighted regression (GWR) or spatial error models to better understand .red[regional variations and factors influencing local patterns].\n\n.bold[Spatial Dependence]:\nSpatial dependence occurs when the values of a variable at one location depend on the values of the variables at nearby locations. Analyzing spatial dependence can help model spatial relationships and predict outcomes more accurately.\n\n]]\n\nclass: left, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#statistics-for-better-visualisation","position":25},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Elements for bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#elements-for-bad-visualisation","position":26},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Elements for bad visualisation"},"content":".split-50[.column[\n\n.bold[Clutter and Complexity]:\nExcessive use of colors, fonts, labels, or visual elements can make a visualization .red[difficult to interpret and detract from its main message].\n\n.bold[Misleading Scales or Axes]:\nManipulating or misrepresenting .red[scales or axes] can distort the data and lead to inaccurate conclusions.\n\n.bold[Poor Color Choices]:\nUsing color palettes with .red[low contrast or inappropriate color associations] can make it difficult for viewers to distinguish between different data points or categories.\n\n.bold[Confusing Data Encoding]:\nInconsistent encoding of data (e.g., .red[using different symbols or sizes for the same value]) can make it challenging for the audience to compare and understand the data.\n\n].column[\n\n.bold[Unnecessary 3D Effects]:\nAdding 3D effects .red[without a specific purpose] can add unnecessary complexity and make it harder to interpret the visualization accurately.\n\n.bold[Lack of Context]:\nOmitting important contextual information, such as .red[units, labels, or reference points], can hinder the audience’s ability to understand and interpret the data accurately.\n\n.bold[Unnecessary Visual Elements]:\nIncluding .red[irrelevant visual elements] or “chart junk” can distract from the main message and clutter the visualization.\n\n.bold[Inaccurate Representation of Data]:\nUsing the .red[wrong visualization type] for the data type or purpose can lead to misinterpretation and misunderstanding.\n]]\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#elements-for-bad-visualisation","position":27},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation","position":28},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":".split-50[.column[\n\nUnnecessary 3D view.\n].column[\n\nA bar chart could be clearer.\n]]\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation","position":29},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-1","position":30},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":" Line plot used to show discrete data (not continuous).\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-1","position":31},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-2","position":32},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":" Confusing composition --- what is the main message?\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-2","position":33},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-3","position":34},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":" Unnecessary spiral effect --- what is the main message?\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-3","position":35},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-4","position":36},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":" Negative values going up and/or down?\n\nclass: left, middle\n.split-50[.column[","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-4","position":37},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-5","position":38},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":"Color palette choice & type of chart (bar? or just table).\n].column[\n\n]]\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-5","position":39},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-6","position":40},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":" Generated based on the relative diameters of their circles, not relative areas. It’s subtle but still misleading.\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-6","position":41},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-7","position":42},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":" Inconsistent categories and colors.\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-7","position":43},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-8","position":44},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":" Distracting labels (numbers).\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-8","position":45},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-9","position":46},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"Example of bad visualisation"},"content":" Confusing area effect.\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#example-of-bad-visualisation-9","position":47},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"How about this?"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#how-about-this","position":48},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"How about this?"},"content":" Population (3D) in New York City.\n\nclass: center, middle","type":"content","url":"/sec-07-07-a-final-closing-remark#how-about-this","position":49},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"How about this?"},"type":"lvl2","url":"/sec-07-07-a-final-closing-remark#how-about-this-1","position":50},{"hierarchy":{"lvl1":"A Final Closing Remark","lvl2":"How about this?"},"content":" Tree density in San Francisco.","type":"content","url":"/sec-07-07-a-final-closing-remark#how-about-this-1","position":51},{"hierarchy":{"lvl1":"Geospatial Statistics and Visualization"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Geospatial Statistics and Visualization"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Geospatial Statistics and Visualization","lvl2":"Course description"},"type":"lvl2","url":"/#course-description","position":2},{"hierarchy":{"lvl1":"Geospatial Statistics and Visualization","lvl2":"Course description"},"content":"Data visualization is crucial for understanding geographical phenomena, and statistical thinking is essential for effective visualization. This course offers students a comprehensive understanding of geospatial data visualization and analysis techniques. Students will develop a strong foundation in statistical methods and spatial thinking abilities while learning to create compelling visualizations using Python. Key topics include statistical patterns, point patterns, areal patterns, and geovisualization. Through hands-on experience with Python libraries, students will enhance their spatial data science skills. By the end of the course, students will be well-equipped to analyze, visualize, and communicate geospatial data insights effectively.","type":"content","url":"/#course-description","position":3},{"hierarchy":{"lvl1":"Geospatial Statistics and Visualization","lvl2":"Learning outcomes"},"type":"lvl2","url":"/#learning-outcomes","position":4},{"hierarchy":{"lvl1":"Geospatial Statistics and Visualization","lvl2":"Learning outcomes"},"content":"Master statistical and spatial thinking for geospatial data visualization---thinking statistically while doing geovisualization.\n\nUnderstand and apply key concepts such as statistical, point, and areal patterns.\n\nGain hands-on experience with Python libraries for data visualization and analysis.\n\nLearn to create compelling visualizations to effectively communicate spatial data insights.","type":"content","url":"/#learning-outcomes","position":5},{"hierarchy":{"lvl1":"Geospatial Statistics and Visualization","lvl2":"Licensing"},"type":"lvl2","url":"/#licensing","position":6},{"hierarchy":{"lvl1":"Geospatial Statistics and Visualization","lvl2":"Licensing"},"content":"Course content (text, images, figures, explanations)© 2025 National University of Singapore.Licensed under the Creative Commons\n\nAttribution–NonCommercial–NoDerivatives 4.0 International (CC BY-NC-ND 4.0).You may share the material with attribution, but you may not modify it or use it commercially.\n\nCode cells and example scriptsCode snippets and examples in this book are licensed under \n\nThe MIT License.You are free to reuse, modify, and distribute the code with attribution.","type":"content","url":"/#licensing","position":7}]}