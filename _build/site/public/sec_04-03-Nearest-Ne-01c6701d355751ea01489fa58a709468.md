# Nearest Neighbor Analysis


## The 2 Distance-based Approaches

```{figure} ./resources/w05-img/three_strategies_for_point_pattern_2b.png
:label:
:alt:
:align: center

Everyone look for the nearest neighbor vs. everyone draw a series of search buffer (radius).
```

In this section, we focus on the first approach.


## 4 examples of point distribution: Clustered or Random?

```{figure} ./resources/w05-img/four_demo_points.png
:label:
:alt:
:align: center

4 types of points in North Singapore: Woodlands Regional Centre, Woodlands West, and Woodgrove, with an area of $2 \text{km} \times 2 \text{km}$
```


## Nearest Neighbor Analysis Calculation Process: In A Nut Shell

- Identifying nearest neighbors for every point
- Record the nearest neighbor distances
- Calculate the __mean value__
    - observed average nearest neighbor distance ($D_O$)
- The average nearest neighbor distance:
    - short: the points are close to each other
    - long: the points are far from each other


```{figure} ./resources/w05-img/simulate_nna.gif
:label:
:alt:
:align: center

Searching for the nearest neighbors.
```


**How short is short enough to be considered as "clustered"?**

Let's use the __Monte Carlo Simulation__ approach to test the __difference__ between the __observed__ point pattern and a large number of random patterns generated under the __CSR assumption__.

```{figure} ./resources/w05-img/mean_nearest_negihbor_4cases_b.png
:label:
:alt:
:align: center

Mean nearest neighbor distances for the four examples.
```



## Option 1: Monte Carlo Simulation

- **Area size has to match the study area**.
    - Area size will affect the distance between points.
- **The number of points has to match the dataset**.
    - Within the same area, more points (higher density) will lead to lower nearest neighbor distances.

```{figure} ./resources/w05-img/monte_carlo_point_pattern.gif
:label:
:alt:
:align: center

Monte Carlo Simulation for point pattern.
```

### Statistical Testing

- After simulating random for M times, we will get $M$ measurement of mean nearest neighbor distances.
- The frequency distribution of the N values would form a normal distribution.
- The range where the normal distribution is located represent the "random (CSR)" under the specific area and # point setting.

```{figure} ./resources/w05-img/drawing_normal_testing_0.png
:label:
:alt:
:align: center

Normal distribution pattern for the frequency of the NNA statistics for the simulated pattern.
```



(1) If the observed value is __far from the random__, we found a clear evidence that the observed pattern is different from random.
- either __clustered or dispersed__


```{figure} ./resources/w05-img/drawing_normal_testing_1.png
:label:
:alt:
:align: center

If the oberved value is far from the normal bell shape.
```

(2) If the observed value __fall within the random range__, then, we did not find any evidence to prove that the observed pattern is different from random.
- cannot reject the null hypothesis
- we have no choice but to believe it is random


```{figure} ./resources/w05-img/drawing_normal_testing_2.png
:label:
:alt:
:align: center

If the oberved value fall within the normal bell shape.
```


(3) If the observed fall at the edge of the normal distribution
- check __p-value__ and your confidence level setting.

__p-value: the probability of being wrong to reject null hypothesis__

See [ESRI "What is a z-score? What is a p-value?"(https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/what-is-a-z-score-what-is-a-p-value.htm) for more details]

```{figure} ./resources/w05-img/drawing_normal_testing_3.png
:label:
:alt:
:align: center

If the oberved value fall within or near to the edge of the normal bell shape.
```

Let's say we set the confidence level to 99%, meaning we are willing to accept a 1% risk of being wrong (incorrectly rejecting the null hypothesis, H0).
If the obtained p-value is 3%, which is higher than our acceptable risk, then we cannot reject H0.


```{figure} ./resources/w05-img/nna_compare_hist.png
:label:
:alt:
:align: center

How the observed mean compared with 10k CSR simulations mean results?
```


The grey area indicates the mean nearest neighbor distance of the 10k random pattern.


## Option 2: Z-test approach

Z-test is another option for testing the significant levels of how observed nearest neighbor distance ($\bar{D}_O$) is different from the 'expected' average nearest neighbor distance ($\bar{D}_E$) under CSR.

See [ESRI](https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/h-how-average-nearest-neighbor-distance-spatial-st.htm) for detail.

The nearest neighbor distance ratio:
$$
\text{ANN} = \frac{\bar{D}_O}{\bar{D}_E}
$$
If the index ($\text{ANN}$) is less than 1, the pattern exhibits clustering.
If the index is greater than 1, the trend is toward dispersion.

The expected mean distance could be calculated using the number of point (n) and the study area (A):
$$
\bar{D}_E = \frac{0.5}{\sqrt{n/A}}
$$

The z-score can then be calculated using $\bar{D}_O$ and $\bar{D}_E$:
$$
z = \frac{\bar{D}_O - \bar{D}_E}{SE}
$$

The z-score and p-value for this statistic are sensitive to changes in the study area or changes to the Area parameter. For this reason, only compare z-score and p-value results from this statistic when the study area is fixed.



```{figure} ./resources/w05-img/ztest.png
:label:
:alt:
:align: center

Z-test and z-score. See [ESRI "What is a z-score? What is a p-value?"](https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/what-is-a-z-score-what-is-a-p-value.htm) for more details.
```




## Summary: Nearest Neighbor Analysis (NNA)

- This approach calculates the average distance of the nearest neighbor for every point.

- The observed average nearest neighbor distance can be tested using a Monte Carlo Simulation or z-test approaches against the null hypothesis of CSR.

- The NNA has an assumption that the points being measured are __free to locate anywhere within the study area__ (for example, there are no barriers, and all cases or features are located independently of one another).
