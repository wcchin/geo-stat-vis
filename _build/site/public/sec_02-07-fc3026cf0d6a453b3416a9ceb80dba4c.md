# The Analysis of Variance
------
.square[Assumptions .dot[] Types .dot[] Interpretation .dot[] Posthoc Tests]

.headnote.square.bold.x-large[Statistical Pattern II]

---
class: left, middle

.split-30[.column[
### What is Analysis of Variance
].column[
.bold[Definition]:
Analysis of Variance, aka ANOVA, is a statistical method used to compare the means of .red[more than two groups] to determine whether there is a significant difference between them.

The primary purpose of ANOVA is to test the hypothesis that the means of several populations are equal. It helps determine .red[whether any observed differences between group means are real or occurred by chance].

.bold[When to use ANOVA]:
ANOVA is used when comparing more than two group means. It is particularly useful in experimental settings where a single factor (independent variable, one-way ANOVA) is .red[manipulated at multiple levels] (e.g., low, medium, high), and .red[the researcher wants to investigate the effect of .red[this manipulation] on the outcome] (dependent variable).
]]

---
class: left, middle
.split-30[.column[
### Assumptions of ANOVA
].column[
ANOVA is based on the following assumptions:
- .bold[Numeric Response]: The .red[target (dependent) variable] should be continuous, either ratio or interval.
- .bold[Normality]: The data within each group should be approximately normally distributed.
- .bold[Equal Variances (homoscedasticity)]: The variances of the populations being compared should be roughly equal.
- .bold[Independence]: Observations should be independent of each other. This means that the data from one subject should not influence the data from another subject.
- .bold[Categorical treatment or factor variables]: ANOVA evaluates mean differences between one or more categorical variables (such as treatment groups), which are referred to as factors or “ways.”

Note: It is essential to verify that these assumptions are met before conducting ANOVA. If assumptions are not satisfied, the validity of the F-test may be compromised. In such cases, alternative methods such as .underline[repeated measure ANOVA, Welch's ANOVA, non-parametric tests] or more robust techniques may be considered.
]]

---
class: center, middle

### Analysis process for ANOVA
<img src="resources/w03-img/anova_ttest.drawio.png" width="90%" align="center">
.square[The analysis process for t-test, ANOVA, and post-hoc test. ]


---
class: left, middle

.split-40[.column[
### Types of ANOVA
Here only some commonly used types are introduced. Other types, e.g,. two-ways, three-ways, nested, Welch's ANOVA... are not covered here since those data is less common, and the concept is similar (anyway).
].column[
- One-way ANOVA
    - between groups
    - the simplest and straighforward situation
- Repeated Measures ANOVA
    - within group
    - when the groups are not independent
- Mixed-Design ANOVA
    - when both between and within occurs
]]

---
class: left, middle

.split-40[.column[
### Types of ANOVA
- .red[One-way ANOVA]
- Repeated Measures ANOVA
- Mixed-Design ANOVA
].column[
#### One-way ANOVA
.bold[Concept]
One-way ANOVA is a statistical technique used to compare the target variable's means of .red[three or more independent groups] with .red[a single independent variable] (or factor). It helps determine whether any observed differences between group means are real or occurred by chance.

.bold[Example]
To compare the average test scores of students who received different teaching methods.

.bold[Hypothesis Tested in One-way ANOVA]
- $H_0$: The population means of the groups being compared are equal.
Symbolically: $μ_1 = μ_2 = μ_3 = ... = μ_k$, where μ_i represents the mean of the ith group, and k is the total number of groups.
- $H_1$: At least one of the group means is different from the others.
]]

---
class: center, middle
#### One-way ANOVA
<img src="resources/w03-img/measures_spread_4vars.png" width="90%" align="center">
.square[The One-way ANOVA comparing the four target variables between the three species. ]

---
class: left, middle
.split-30[.column[
#### One-way ANOVA
].column[
Table 1. The ANOVA result for the four target variables. Each row display the result from a single ANOVA.  All were significant.

| variety      |   ddof1 |   ddof2 |        F |   p-unc |   np2 |
|:-------------|--------:|--------:|---------:|--------:|------:|
| petal.length |       2 |     147 | 1180.16  |   0.000 | 0.941 |
| petal.width  |       2 |     147 |  960.007 |   0.000 | 0.929 |
| sepal.length |       2 |     147 |  119.265 |   0.000 | 0.619 |
| sepal.width  |       2 |     147 |   49.16  |   0.000 | 0.401 |
]]

---
class: left, middle

.split-40[.column[
### Types of ANOVA
- One-way ANOVA
- .red[Repeated Measures ANOVA]
- Mixed-Design ANOVA
].column[
#### Repeated Measures ANOVA
.bold[Concept]
Repeated measures ANOVA, also known as .red[within-subjects] ANOVA, is a statistical technique used to compare means of .red[three or more dependent groups] when the same subjects are .red[observed under various conditions or at different points in time.]

.bold[Example]
To compare the reaction times of a group of participants before, during, and after receiving a treatment.

.bold[Hypothesis Tested in Repeated Measures ANOVA]
- $H_0$: The population means of the different conditions or time points are equal.
Symbolically: $μ_1 = μ_2 = μ_3 = ... = μ_k$, where μi represents the mean of the ith condition or time point, and k is the total number of conditions or time points.
- $H_1$: At least one of the population means is different from the others.
Symbolically: There exists at least one i and j such that $μ_i ≠ μ_j$.
]]

---
class: center, middle
#### Repeated Measures ANOVA
<img src="resources/w03-img/physiology_data_lineplot-b.png" width="90%" align="center">
.square[The physiological responses before, during and after two types of VR treatments. ]

---
class: center, middle
#### Repeated Measures ANOVA
<img src="resources/w03-img/physiology_data_lineplot-b-tables.png" width="90%" align="center">
.square[The tables about the repeated measures and post-hoc results: (left) low decibel, (right) high decibel. ]

---
class: left, middle

.split-40[.column[
### Types of ANOVA
- One-way ANOVA
- Repeated Measures ANOVA
- .bold[Mixed-Design ANOVA]
].column[
#### Mixed-Design ANOVA

.bold[Concept]
Mixed-design ANOVA, also known as split-plot ANOVA, is a statistical method used for analyzing data from studies with both between-subjects factors and within-subjects factors. It .red[combines features of one-way ANOVA and repeated measures ANOVA], allowing researchers to examine the effects of multiple independent variables on a dependent variable.

.bold[Key Points]
- .red[Between-subjects factors] involve comparisons between different groups of participants, similar to one-way ANOVA.
- .red[Within-subjects factors] involve comparisons within the same group of participants at different time points or under various conditions, similar to repeated measures ANOVA.
- Mixed-design ANOVA enables researchers to assess the main effects of each factor and the potential interaction effects between factors.
]]

---
class: left, middle

.split-40[.column[
### Types of ANOVA
- One-way ANOVA
- Repeated Measures ANOVA
- .bold[Mixed-Design ANOVA]
].column[
#### Mixed-Design ANOVA

.bold[Assumptions]
The assumptions of mixed-design ANOVA are similar to those of one-way and repeated measures ANOVA, including normality, homogeneity of variances, and independence. Additionally, the assumption of .underline[sphericity] must be met for the .underline[within-subjects factor].

.bold[Use case]
By using mixed-design ANOVA, researchers can gain a deeper understanding of the complex relationships between multiple factors and their effects on the dependent variable. It's a powerful tool for analyzing data from various experimental designs, particularly in fields such as psychology, medicine, and education.

]]

---
class: center, middle

#### Mixed-Design ANOVA
<img src="resources/w03-img/mixed-anova.png" width="70%" align="center">
.square[The mixed ANOVA result between classes, time (pre-test vs. post-test), and the interaction between class and time. ]

---
class: center, middle

#### Mixed-Design ANOVA
<img src="resources/w03-img/mixed-anova_posthoc.png" width="60%" align="center">
.square[The post-hoc test after mixed ANOVA, to observe the time effects in different condition. ]

---
class: left, middle

.split-40[.column[
### F-test and F-distribution
#### F-test and F-statistic
].column[

The F-test is a statistical test used in ANOVA to compare variances and determine whether there is a significant difference between group means. The F-statistic (or F-ratio) is calculated as .red[the ratio of the between-group variance to the within-group variance]:
$$
F = (\text{Between-group variance}) / (\text{Within-group variance})
$$

The F-statistic reflects the extent to which .red[the variation between groups exceeds the variation within groups].
A higher F-value indicates a greater difference between group means relative to the variability within each group.
]]

---
class: left, middle

.split-40[.column[
### F-test and F-distribution
#### F-distribution and its relationship with the F-test
].column[
Under the null hypothesis that all group means are equal, the F-statistic follows an F-distribution, which is a family of continuous probability distributions characterized by two parameters: .red[degrees of freedom for the .bold[numerator] ($\text{ddof}_1$) and degrees of freedom for the .bold[denominator] ($\text{ddof}_2$)].

The F-distribution is used to determine the .red[critical F-value] for a given significance level ($\alpha$) and degrees of freedom ($\text{ddof}_1$ and $\text{ddof}_2$). This critical value is compared with the calculated F-statistic .red[to make a decision] about the null hypothesis.
]]

---
class: left, middle

.split-40[.column[
### F-test and F-distribution
#### Making decisions in ANOVA using the F-value
].column[
- To make decisions in ANOVA, the calculated F-statistic is compared to the critical F-value obtained from the F-distribution.

- If the F-statistic is .red.bold[larger] than the critical F-value, we .red[.bold[reject]] the null hypothesis, concluding that .red[at least one group mean is significantly] different from the others.

- If the F-statistic is .red.bold[smaller] than the critical F-value, we .red[.bold[fail to reject]] the null hypothesis, concluding that there is .red[insufficient evidence to claim a significant] difference between group means.

- In practice, a p-value is often computed and compared to a predetermined significance level ($\alpha$) to make this decision. .red[If the p-value is smaller than $\alpha$, the null hypothesis is rejected.]
]]

---
class: left, middle

.split-40[.column[
### Post-hoc Tests
].column[

#### Purpose of Post-hoc Tests
Post-hoc tests are follow-up analyses conducted .red[.bold[after] a significant overall F-test in ANOVA]. Their purpose is to determine .red[which specific group means] are significantly different from one another. Since ANOVA only tells us that at least two means are different, .red[post-hoc tests help pinpoint where those differences lie].
]]

---
class: left, middle

.split-30[.column[
### Post-hoc Tests
].column[
#### Common post-hoc tests

.bold[Tukey's HSD Test]:
- Simultaneously compares all possible pairs of means.
- Controls the family-wise error rate, ensuring the overall probability of making at least one Type I error across all comparisons remains at the desired significance level.
- Generally more appropriate when making multiple comparisons in an ANOVA context, as it has greater power to detect significant differences while controlling for multiple comparisons.

.bold[Pairwise t-tests]:
- Compares two means at a time.
- Performing multiple pairwise t-tests inflates the Type I error rate, as each test uses a fixed significance level (e.g., 0.05) without considering the number of comparisons made.
- While adjustments such as the Bonferroni correction can control for multiple comparisons, using individual t-tests becomes less powerful and more complex as the number of comparisons increases.
]]

---
class: center, middle

### Roadmap for choosing ANOVA and post-hoc tests

<img src="resources/w03-img/pingouin_anova_guide.png" width="80%" align="center">
.square[The roadmap for choosing ANOVA and post-hoc tests approaches. by [Pingouin](https://pingouin-stats.org/build/html/guidelines.html) ]
